<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lab 04: Fraud Detection and Imbalanced Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="Lab 04_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lab 04_files/libs/quarto-html/quarto.js"></script>
<script src="Lab 04_files/libs/quarto-html/popper.min.js"></script>
<script src="Lab 04_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Lab 04_files/libs/quarto-html/anchor.min.js"></script>
<link href="Lab 04_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lab 04_files/libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Lab 04_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Lab 04_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Lab 04_files/libs/bootstrap/bootstrap-2cdb6c447a9b70e5e1f1f0acec0d17a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">1</span> Overview</a></li>
  <li><a href="#import-code" id="toc-import-code" class="nav-link" data-scroll-target="#import-code"><span class="header-section-number">2</span> Import Code</a></li>
  <li><a href="#credit-card-fraud-detection" id="toc-credit-card-fraud-detection" class="nav-link" data-scroll-target="#credit-card-fraud-detection"><span class="header-section-number">3</span> Credit Card Fraud Detection</a>
  <ul class="collapse">
  <li><a href="#card-present-frauds" id="toc-card-present-frauds" class="nav-link" data-scroll-target="#card-present-frauds"><span class="header-section-number">3.1</span> Card-present frauds</a></li>
  <li><a href="#card-not-present-frauds" id="toc-card-not-present-frauds" class="nav-link" data-scroll-target="#card-not-present-frauds"><span class="header-section-number">3.2</span> Card-not-present frauds</a></li>
  <li><a href="#credit-card-fraud-detection-systems-ccfds" id="toc-credit-card-fraud-detection-systems-ccfds" class="nav-link" data-scroll-target="#credit-card-fraud-detection-systems-ccfds"><span class="header-section-number">3.3</span> Credit Card Fraud Detection Systems (CCFDS)</a></li>
  <li><a href="#class-imbalance-in-fraud-detection" id="toc-class-imbalance-in-fraud-detection" class="nav-link" data-scroll-target="#class-imbalance-in-fraud-detection"><span class="header-section-number">3.4</span> Class Imbalance in Fraud Detection</a></li>
  </ul></li>
  <li><a href="#dealing-with-class-imbalance" id="toc-dealing-with-class-imbalance" class="nav-link" data-scroll-target="#dealing-with-class-imbalance"><span class="header-section-number">4</span> Dealing with Class Imbalance</a>
  <ul class="collapse">
  <li><a href="#do-nothing-approach" id="toc-do-nothing-approach" class="nav-link" data-scroll-target="#do-nothing-approach"><span class="header-section-number">4.1</span> Do-Nothing Approach</a></li>
  <li><a href="#class-sensitive-evaluation-approach" id="toc-class-sensitive-evaluation-approach" class="nav-link" data-scroll-target="#class-sensitive-evaluation-approach"><span class="header-section-number">4.2</span> Class-Sensitive Evaluation Approach</a></li>
  <li><a href="#cost-sensitive-learning-approach" id="toc-cost-sensitive-learning-approach" class="nav-link" data-scroll-target="#cost-sensitive-learning-approach"><span class="header-section-number">4.3</span> Cost-Sensitive Learning Approach</a></li>
  <li><a href="#resampling-approach" id="toc-resampling-approach" class="nav-link" data-scroll-target="#resampling-approach"><span class="header-section-number">4.4</span> Resampling Approach</a></li>
  </ul></li>
  <li><a href="#data-prep-for-big-data" id="toc-data-prep-for-big-data" class="nav-link" data-scroll-target="#data-prep-for-big-data"><span class="header-section-number">5</span> Data Prep for Big Data</a>
  <ul class="collapse">
  <li><a href="#data-loading" id="toc-data-loading" class="nav-link" data-scroll-target="#data-loading"><span class="header-section-number">5.1</span> Data Loading</a></li>
  <li><a href="#data-frame-benchmarks" id="toc-data-frame-benchmarks" class="nav-link" data-scroll-target="#data-frame-benchmarks"><span class="header-section-number">5.2</span> Data Frame Benchmarks</a></li>
  <li><a href="#prequential-data-splitting-using-polars" id="toc-prequential-data-splitting-using-polars" class="nav-link" data-scroll-target="#prequential-data-splitting-using-polars"><span class="header-section-number">5.3</span> Prequential Data Splitting (using Polars)</a></li>
  </ul></li>
  <li><a href="#eda-compare-df_train-and-df_tuning" id="toc-eda-compare-df_train-and-df_tuning" class="nav-link" data-scroll-target="#eda-compare-df_train-and-df_tuning"><span class="header-section-number">6</span> EDA: Compare <code>df_train</code> and <code>df_tuning</code></a></li>
  <li><a href="#feature-engineering" id="toc-feature-engineering" class="nav-link" data-scroll-target="#feature-engineering"><span class="header-section-number">7</span> Feature Engineering</a>
  <ul class="collapse">
  <li><a href="#polars-feature-functions" id="toc-polars-feature-functions" class="nav-link" data-scroll-target="#polars-feature-functions"><span class="header-section-number">7.1</span> Polars Feature Functions</a>
  <ul class="collapse">
  <li><a href="#weekend-flag" id="toc-weekend-flag" class="nav-link" data-scroll-target="#weekend-flag"><span class="header-section-number">7.1.1</span> Weekend Flag</a></li>
  <li><a href="#night-flag" id="toc-night-flag" class="nav-link" data-scroll-target="#night-flag"><span class="header-section-number">7.1.2</span> Night Flag</a></li>
  <li><a href="#customer-features" id="toc-customer-features" class="nav-link" data-scroll-target="#customer-features"><span class="header-section-number">7.1.3</span> Customer Features</a></li>
  <li><a href="#terminal-features" id="toc-terminal-features" class="nav-link" data-scroll-target="#terminal-features"><span class="header-section-number">7.1.4</span> Terminal Features</a></li>
  </ul></li>
  <li><a href="#data-pipeline" id="toc-data-pipeline" class="nav-link" data-scroll-target="#data-pipeline"><span class="header-section-number">7.2</span> Data Pipeline</a></li>
  </ul></li>
  <li><a href="#eda-compare-df_train_ft-and-df_tuning_ft" id="toc-eda-compare-df_train_ft-and-df_tuning_ft" class="nav-link" data-scroll-target="#eda-compare-df_train_ft-and-df_tuning_ft"><span class="header-section-number">8</span> EDA: Compare <code>df_train_ft</code> and <code>df_tuning_ft</code></a></li>
  <li><a href="#modeling-and-evaluation" id="toc-modeling-and-evaluation" class="nav-link" data-scroll-target="#modeling-and-evaluation"><span class="header-section-number">9</span> Modeling and Evaluation</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data"><span class="header-section-number">9.1</span> Data</a></li>
  <li><a href="#do-nothing-approach-1" id="toc-do-nothing-approach-1" class="nav-link" data-scroll-target="#do-nothing-approach-1"><span class="header-section-number">9.2</span> Do-Nothing Approach</a></li>
  <li><a href="#class-sensitive-evaluation-approach-1" id="toc-class-sensitive-evaluation-approach-1" class="nav-link" data-scroll-target="#class-sensitive-evaluation-approach-1"><span class="header-section-number">9.3</span> Class-Sensitive Evaluation Approach</a></li>
  <li><a href="#cost-sensitive-learning-approach-1" id="toc-cost-sensitive-learning-approach-1" class="nav-link" data-scroll-target="#cost-sensitive-learning-approach-1"><span class="header-section-number">9.4</span> Cost-Sensitive Learning Approach</a></li>
  <li><a href="#resampling-approach-1" id="toc-resampling-approach-1" class="nav-link" data-scroll-target="#resampling-approach-1"><span class="header-section-number">9.5</span> Resampling Approach</a>
  <ul class="collapse">
  <li><a href="#random-undersampling-of-majority-class-rus" id="toc-random-undersampling-of-majority-class-rus" class="nav-link" data-scroll-target="#random-undersampling-of-majority-class-rus"><span class="header-section-number">9.5.1</span> Random Undersampling of Majority Class (RUS)</a></li>
  <li><a href="#random-oversampling-of-minority-class-ros" id="toc-random-oversampling-of-minority-class-ros" class="nav-link" data-scroll-target="#random-oversampling-of-minority-class-ros"><span class="header-section-number">9.5.2</span> Random Oversampling of Minority Class (ROS)</a></li>
  <li><a href="#synthetic-minority-over-sampling-technique-smote" id="toc-synthetic-minority-over-sampling-technique-smote" class="nav-link" data-scroll-target="#synthetic-minority-over-sampling-technique-smote"><span class="header-section-number">9.5.3</span> Synthetic Minority Over-sampling Technique (SMOTE)</a></li>
  <li><a href="#hybrid-smote-rus" id="toc-hybrid-smote-rus" class="nav-link" data-scroll-target="#hybrid-smote-rus"><span class="header-section-number">9.5.4</span> Hybrid: SMOTE + RUS</a></li>
  <li><a href="#comparison-of-resampling-strategies" id="toc-comparison-of-resampling-strategies" class="nav-link" data-scroll-target="#comparison-of-resampling-strategies"><span class="header-section-number">9.5.5</span> Comparison of Resampling Strategies</a></li>
  <li><a href="#interpreting-the-best-model" id="toc-interpreting-the-best-model" class="nav-link" data-scroll-target="#interpreting-the-best-model"><span class="header-section-number">9.5.6</span> Interpreting the Best Model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#key-conclusions-and-recommendations" id="toc-key-conclusions-and-recommendations" class="nav-link" data-scroll-target="#key-conclusions-and-recommendations"><span class="header-section-number">10</span> Key Conclusions and Recommendations</a></li>
  </ul>
</nav>
</div>
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Lab 04: Fraud Detection and Imbalanced Learning</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<section id="overview" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Overview</h1>
<p>The lab explores Python libraries for handling large datasets, feature engineering, and strategies for addressing imbalanced data in fraud detection.</p>
</section>
<section id="import-code" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Import Code</h1>
<p>The chunks below include all necessary Python libraries and helper functions/classes that will be used in the lab. The helpers are adapted from previous labs.</p>
<div id="setup-imports" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># System utilities</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> shutil</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> random</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> warnings</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> time</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">import</span> gc</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">import</span> psutil</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">import</span> glob <span class="co"># For finding files</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">import</span> time</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co"># Data manipulation and visualization</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="im">import</span> polars <span class="im">as</span> pl <span class="co"># Polars is a fast DataFrame library</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="im">from</span> IPython.display <span class="im">import</span> display <span class="co"># Explicit import for display</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="im">import</span> re</span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="im">import</span> duckdb</span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="co"># Machine learning - scikit-learn</span></span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression, LogisticRegressionCV</span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, average_precision_score, f1_score, classification_report</span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> PartialDependenceDisplay</span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> CalibratedClassifierCV, CalibrationDisplay <span class="co"># Added for probability calibration</span></span>
<span id="cb1-28"><a href="#cb1-28"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, ClassifierMixin, TransformerMixin</span>
<span id="cb1-29"><a href="#cb1-29"></a><span class="im">from</span> sklearn.utils.validation <span class="im">import</span> check_is_fitted</span>
<span id="cb1-30"><a href="#cb1-30"></a><span class="im">from</span> sklearn <span class="im">import</span> set_config</span>
<span id="cb1-31"><a href="#cb1-31"></a></span>
<span id="cb1-32"><a href="#cb1-32"></a><span class="co"># Imbalanced-learn for resampling</span></span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="im">from</span> imblearn.pipeline <span class="im">import</span> Pipeline <span class="im">as</span> ImbPipeline</span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="im">from</span> imblearn.under_sampling <span class="im">import</span> RandomUnderSampler</span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> RandomOverSampler, SMOTE</span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a><span class="co"># Specialized ML libraries</span></span>
<span id="cb1-38"><a href="#cb1-38"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor, TabularDataset</span>
<span id="cb1-39"><a href="#cb1-39"></a><span class="im">from</span> ydata_profiling <span class="im">import</span> ProfileReport</span>
<span id="cb1-40"><a href="#cb1-40"></a><span class="im">import</span> shap</span>
<span id="cb1-41"><a href="#cb1-41"></a><span class="im">import</span> dice_ml</span>
<span id="cb1-42"><a href="#cb1-42"></a><span class="im">from</span> dice_ml.utils <span class="im">import</span> helpers </span>
<span id="cb1-43"><a href="#cb1-43"></a><span class="im">import</span> torch</span>
<span id="cb1-44"><a href="#cb1-44"></a></span>
<span id="cb1-45"><a href="#cb1-45"></a><span class="co"># Settings</span></span>
<span id="cb1-46"><a href="#cb1-46"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="dv">50</span>)</span>
<span id="cb1-47"><a href="#cb1-47"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="dv">100</span>)</span>
<span id="cb1-48"><a href="#cb1-48"></a>warnings.filterwarnings(<span class="st">'ignore'</span>, category<span class="op">=</span><span class="pp">FutureWarning</span>) <span class="co"># Suppress specific FutureWarnings</span></span>
<span id="cb1-49"><a href="#cb1-49"></a>warnings.filterwarnings(<span class="st">'ignore'</span>, category<span class="op">=</span><span class="pp">UserWarning</span>) <span class="co"># Suppress some UserWarnings from libraries</span></span>
<span id="cb1-50"><a href="#cb1-50"></a>set_config(transform_output<span class="op">=</span><span class="st">"pandas"</span>) <span class="co"># Set sklearn output to pandas</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="setup-helpers" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Helper Functions and Classes</span></span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="kw">def</span> global_set_seed(seed_value<span class="op">=</span><span class="dv">2025</span>):</span>
<span id="cb2-4"><a href="#cb2-4"></a>    <span class="co">"""Sets random seeds for reproducibility."""</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>    random.seed(seed_value)</span>
<span id="cb2-6"><a href="#cb2-6"></a>    np.random.seed(seed_value)</span>
<span id="cb2-7"><a href="#cb2-7"></a>    torch.manual_seed(seed_value)</span>
<span id="cb2-8"><a href="#cb2-8"></a>    <span class="cf">if</span> dice_ml: <span class="co"># If dice_ml is imported, try to set its seed</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>        <span class="cf">try</span>:</span>
<span id="cb2-10"><a href="#cb2-10"></a>            dice_ml.utils.helpers.set_random_seed(seed_value)</span>
<span id="cb2-11"><a href="#cb2-11"></a>        <span class="cf">except</span> <span class="pp">AttributeError</span>: <span class="co"># In case the function path changes</span></span>
<span id="cb2-12"><a href="#cb2-12"></a>            <span class="cf">pass</span></span>
<span id="cb2-13"><a href="#cb2-13"></a></span>
<span id="cb2-14"><a href="#cb2-14"></a></span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="kw">def</span> remove_ag_folder(mdl_folder: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb2-16"><a href="#cb2-16"></a>    <span class="co">"""Removes the AutoGluon model folder if it exists."""</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>    <span class="cf">if</span> os.path.exists(mdl_folder):</span>
<span id="cb2-18"><a href="#cb2-18"></a>        shutil.rmtree(mdl_folder)</span>
<span id="cb2-19"><a href="#cb2-19"></a>        <span class="bu">print</span>(<span class="ss">f"Removed existing AutoGluon folder: </span><span class="sc">{</span>mdl_folder<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-20"><a href="#cb2-20"></a></span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="kw">class</span> AutoGluonSklearnWrapper(BaseEstimator, ClassifierMixin):</span>
<span id="cb2-22"><a href="#cb2-22"></a>    <span class="co">"""</span></span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="co">    Scikit-learn compatible wrapper for AutoGluon TabularPredictor</span></span>
<span id="cb2-24"><a href="#cb2-24"></a><span class="co">    </span></span>
<span id="cb2-25"><a href="#cb2-25"></a><span class="co">    Inherits from scikit-learn's BaseEstimator and ClassifierMixin to provide</span></span>
<span id="cb2-26"><a href="#cb2-26"></a><span class="co">    full compatibility with scikit-learn tools like PartialDependenceDisplay().</span></span>
<span id="cb2-27"><a href="#cb2-27"></a><span class="co">    </span></span>
<span id="cb2-28"><a href="#cb2-28"></a><span class="co">    Parameters</span></span>
<span id="cb2-29"><a href="#cb2-29"></a><span class="co">    ----------</span></span>
<span id="cb2-30"><a href="#cb2-30"></a><span class="co">    label : str</span></span>
<span id="cb2-31"><a href="#cb2-31"></a><span class="co">        Name of the target column</span></span>
<span id="cb2-32"><a href="#cb2-32"></a></span>
<span id="cb2-33"><a href="#cb2-33"></a><span class="co">    **predictor_args : dict</span></span>
<span id="cb2-34"><a href="#cb2-34"></a><span class="co">        Additional arguments passed to TabularPredictor()</span></span>
<span id="cb2-35"><a href="#cb2-35"></a><span class="co">        (e.g., problem_type, eval_metric, path, sample_weight)</span></span>
<span id="cb2-36"><a href="#cb2-36"></a></span>
<span id="cb2-37"><a href="#cb2-37"></a><span class="co">    **fit_args : dict</span></span>
<span id="cb2-38"><a href="#cb2-38"></a><span class="co">        Additional arguments passed to TabularPredictor.fit() method</span></span>
<span id="cb2-39"><a href="#cb2-39"></a><span class="co">        (e.g., holdout_frac, presets, time_limit, excluded_model_types, hyperparameters)</span></span>
<span id="cb2-40"><a href="#cb2-40"></a></span>
<span id="cb2-41"><a href="#cb2-41"></a></span>
<span id="cb2-42"><a href="#cb2-42"></a><span class="co">    Attributes</span></span>
<span id="cb2-43"><a href="#cb2-43"></a><span class="co">    ----------</span></span>
<span id="cb2-44"><a href="#cb2-44"></a><span class="co">    predictor : TabularPredictor</span></span>
<span id="cb2-45"><a href="#cb2-45"></a><span class="co">        The trained AutoGluon predictor</span></span>
<span id="cb2-46"><a href="#cb2-46"></a></span>
<span id="cb2-47"><a href="#cb2-47"></a><span class="co">    classes_ : ndarray</span></span>
<span id="cb2-48"><a href="#cb2-48"></a><span class="co">        Class labels (for classification tasks)</span></span>
<span id="cb2-49"><a href="#cb2-49"></a></span>
<span id="cb2-50"><a href="#cb2-50"></a><span class="co">    n_features_in_ : int</span></span>
<span id="cb2-51"><a href="#cb2-51"></a><span class="co">        Number of features seen during fit</span></span>
<span id="cb2-52"><a href="#cb2-52"></a></span>
<span id="cb2-53"><a href="#cb2-53"></a><span class="co">    feature_names_ : list</span></span>
<span id="cb2-54"><a href="#cb2-54"></a><span class="co">        Feature names inferred during fitting</span></span>
<span id="cb2-55"><a href="#cb2-55"></a></span>
<span id="cb2-56"><a href="#cb2-56"></a><span class="co">    is_fitted_ : bool</span></span>
<span id="cb2-57"><a href="#cb2-57"></a><span class="co">        Whether the estimator has been fitted</span></span>
<span id="cb2-58"><a href="#cb2-58"></a><span class="co">    """</span></span>
<span id="cb2-59"><a href="#cb2-59"></a>    </span>
<span id="cb2-60"><a href="#cb2-60"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, label, predictor_args<span class="op">=</span><span class="va">None</span>, fit_args<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-61"><a href="#cb2-61"></a>        <span class="va">self</span>.label <span class="op">=</span> label</span>
<span id="cb2-62"><a href="#cb2-62"></a>        <span class="va">self</span>.predictor_args <span class="op">=</span> predictor_args <span class="cf">if</span> predictor_args <span class="cf">else</span> {}</span>
<span id="cb2-63"><a href="#cb2-63"></a>        <span class="va">self</span>.fit_args <span class="op">=</span> fit_args <span class="cf">if</span> fit_args <span class="cf">else</span> {}</span>
<span id="cb2-64"><a href="#cb2-64"></a>        <span class="va">self</span>.predictor <span class="op">=</span> <span class="va">None</span></span>
<span id="cb2-65"><a href="#cb2-65"></a>        <span class="va">self</span>.classes_ <span class="op">=</span> <span class="va">None</span></span>
<span id="cb2-66"><a href="#cb2-66"></a>        <span class="va">self</span>.n_features_in_ <span class="op">=</span> <span class="va">None</span></span>
<span id="cb2-67"><a href="#cb2-67"></a>        <span class="va">self</span>.feature_names_ <span class="op">=</span> <span class="va">None</span></span>
<span id="cb2-68"><a href="#cb2-68"></a>        <span class="va">self</span>.is_fitted_ <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-69"><a href="#cb2-69"></a></span>
<span id="cb2-70"><a href="#cb2-70"></a>    <span class="kw">def</span> __sklearn_is_fitted__(<span class="va">self</span>):</span>
<span id="cb2-71"><a href="#cb2-71"></a>        <span class="co">"""Official scikit-learn API for checking fitted status"""</span></span>
<span id="cb2-72"><a href="#cb2-72"></a>        <span class="cf">return</span> <span class="va">self</span>.is_fitted_</span>
<span id="cb2-73"><a href="#cb2-73"></a></span>
<span id="cb2-74"><a href="#cb2-74"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y, sample_weight<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-75"><a href="#cb2-75"></a>        <span class="co">"""</span></span>
<span id="cb2-76"><a href="#cb2-76"></a><span class="co">        Fit AutoGluon model using scikit-learn interface.</span></span>
<span id="cb2-77"><a href="#cb2-77"></a><span class="co">        If sample_weight is provided directly to fit, it's used if 'sample_weight' </span></span>
<span id="cb2-78"><a href="#cb2-78"></a><span class="co">        is also specified in predictor_args.</span></span>
<span id="cb2-79"><a href="#cb2-79"></a><span class="co">        """</span></span>
<span id="cb2-80"><a href="#cb2-80"></a>        <span class="va">self</span>._check_feature_names(X, reset<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-81"><a href="#cb2-81"></a>        <span class="va">self</span>._check_n_features(X, reset<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-82"><a href="#cb2-82"></a></span>
<span id="cb2-83"><a href="#cb2-83"></a>        train_data_df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span><span class="va">self</span>.feature_names_)</span>
<span id="cb2-84"><a href="#cb2-84"></a>        train_data_df[<span class="va">self</span>.label] <span class="op">=</span> y</span>
<span id="cb2-85"><a href="#cb2-85"></a></span>
<span id="cb2-86"><a href="#cb2-86"></a>        ag_weight_col_name <span class="op">=</span> <span class="va">self</span>.predictor_args.get(<span class="st">'sample_weight'</span>, <span class="va">None</span>)</span>
<span id="cb2-87"><a href="#cb2-87"></a></span>
<span id="cb2-88"><a href="#cb2-88"></a>        <span class="cf">if</span> sample_weight <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-89"><a href="#cb2-89"></a>            <span class="cf">if</span> ag_weight_col_name:</span>
<span id="cb2-90"><a href="#cb2-90"></a>                train_data_df[ag_weight_col_name] <span class="op">=</span> sample_weight</span>
<span id="cb2-91"><a href="#cb2-91"></a>            <span class="cf">else</span>:</span>
<span id="cb2-92"><a href="#cb2-92"></a>                default_sw_col <span class="op">=</span> <span class="st">'autogluon_sample_weight_fit'</span></span>
<span id="cb2-93"><a href="#cb2-93"></a>                train_data_df[default_sw_col] <span class="op">=</span> sample_weight</span>
<span id="cb2-94"><a href="#cb2-94"></a>                <span class="va">self</span>.predictor_args[<span class="st">'sample_weight'</span>] <span class="op">=</span> default_sw_col</span>
<span id="cb2-95"><a href="#cb2-95"></a>                <span class="bu">print</span>(<span class="ss">f"Warning: sample_weight passed to fit() but 'sample_weight' not in predictor_args. "</span></span>
<span id="cb2-96"><a href="#cb2-96"></a>                      <span class="ss">f"Using '</span><span class="sc">{</span>default_sw_col<span class="sc">}</span><span class="ss">' as weight column for AutoGluon."</span>)</span>
<span id="cb2-97"><a href="#cb2-97"></a>        <span class="cf">elif</span> ag_weight_col_name <span class="kw">and</span> ag_weight_col_name <span class="kw">not</span> <span class="kw">in</span> train_data_df.columns <span class="kw">and</span> ag_weight_col_name <span class="op">!=</span> <span class="st">"balance_weight"</span>:</span>
<span id="cb2-98"><a href="#cb2-98"></a>            <span class="co"># If predictor_args has a specific column name for weights, and it's not in X, and not 'balance_weight'</span></span>
<span id="cb2-99"><a href="#cb2-99"></a>             <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"sample_weight column '</span><span class="sc">{</span>ag_weight_col_name<span class="sc">}</span><span class="ss">' specified in predictor_args but not found in X."</span>)</span>
<span id="cb2-100"><a href="#cb2-100"></a></span>
<span id="cb2-101"><a href="#cb2-101"></a>        train_data <span class="op">=</span> TabularDataset(train_data_df)</span>
<span id="cb2-102"><a href="#cb2-102"></a>        </span>
<span id="cb2-103"><a href="#cb2-103"></a>        current_fit_args <span class="op">=</span> <span class="va">self</span>.fit_args.copy()</span>
<span id="cb2-104"><a href="#cb2-104"></a>        <span class="co"># AutoGluon's .fit() doesn't take sample_weight as a direct argument.</span></span>
<span id="cb2-105"><a href="#cb2-105"></a>        <span class="co"># It's handled if 'sample_weight' (column name or 'balance_weight') is in predictor_args (passed to TabularPredictor constructor)</span></span>
<span id="cb2-106"><a href="#cb2-106"></a>        <span class="co"># or if a column with that name exists in the training data.</span></span>
<span id="cb2-107"><a href="#cb2-107"></a>        <span class="cf">if</span> <span class="st">'sample_weight'</span> <span class="kw">in</span> current_fit_args:</span>
<span id="cb2-108"><a href="#cb2-108"></a>            <span class="kw">del</span> current_fit_args[<span class="st">'sample_weight'</span>] </span>
<span id="cb2-109"><a href="#cb2-109"></a></span>
<span id="cb2-110"><a href="#cb2-110"></a>        <span class="va">self</span>.predictor <span class="op">=</span> TabularPredictor(</span>
<span id="cb2-111"><a href="#cb2-111"></a>            label<span class="op">=</span><span class="va">self</span>.label, </span>
<span id="cb2-112"><a href="#cb2-112"></a>            <span class="op">**</span><span class="va">self</span>.predictor_args</span>
<span id="cb2-113"><a href="#cb2-113"></a>        ).fit(train_data, <span class="op">**</span>current_fit_args)</span>
<span id="cb2-114"><a href="#cb2-114"></a>        </span>
<span id="cb2-115"><a href="#cb2-115"></a>        <span class="cf">if</span> <span class="va">self</span>.predictor.problem_type <span class="kw">in</span> [<span class="st">'binary'</span>, <span class="st">'multiclass'</span>]:</span>
<span id="cb2-116"><a href="#cb2-116"></a>            <span class="va">self</span>.classes_ <span class="op">=</span> np.array(<span class="va">self</span>.predictor.class_labels)</span>
<span id="cb2-117"><a href="#cb2-117"></a>            </span>
<span id="cb2-118"><a href="#cb2-118"></a>        <span class="va">self</span>.is_fitted_ <span class="op">=</span> <span class="va">True</span></span>
<span id="cb2-119"><a href="#cb2-119"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb2-120"><a href="#cb2-120"></a></span>
<span id="cb2-121"><a href="#cb2-121"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb2-122"><a href="#cb2-122"></a>        check_is_fitted(<span class="va">self</span>)</span>
<span id="cb2-123"><a href="#cb2-123"></a>        <span class="co"># Convert X to pandas DataFrame if it's Polars, as AG expects pandas for predict</span></span>
<span id="cb2-124"><a href="#cb2-124"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb2-125"><a href="#cb2-125"></a>            X_pd <span class="op">=</span> X.to_pandas()</span>
<span id="cb2-126"><a href="#cb2-126"></a>        <span class="cf">else</span>:</span>
<span id="cb2-127"><a href="#cb2-127"></a>            X_pd <span class="op">=</span> X</span>
<span id="cb2-128"><a href="#cb2-128"></a>        <span class="va">self</span>._check_feature_names(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-129"><a href="#cb2-129"></a>        <span class="va">self</span>._check_n_features(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-130"><a href="#cb2-130"></a></span>
<span id="cb2-131"><a href="#cb2-131"></a>        df <span class="op">=</span> pd.DataFrame(X_pd, columns<span class="op">=</span><span class="va">self</span>.feature_names_)</span>
<span id="cb2-132"><a href="#cb2-132"></a>        df <span class="op">=</span> TabularDataset(df)</span>
<span id="cb2-133"><a href="#cb2-133"></a>        <span class="cf">return</span> <span class="va">self</span>.predictor.predict(df).values</span>
<span id="cb2-134"><a href="#cb2-134"></a></span>
<span id="cb2-135"><a href="#cb2-135"></a>    <span class="kw">def</span> predict_proba(<span class="va">self</span>, X):</span>
<span id="cb2-136"><a href="#cb2-136"></a>        check_is_fitted(<span class="va">self</span>)</span>
<span id="cb2-137"><a href="#cb2-137"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb2-138"><a href="#cb2-138"></a>            X_pd <span class="op">=</span> X.to_pandas()</span>
<span id="cb2-139"><a href="#cb2-139"></a>        <span class="cf">else</span>:</span>
<span id="cb2-140"><a href="#cb2-140"></a>            X_pd <span class="op">=</span> X</span>
<span id="cb2-141"><a href="#cb2-141"></a>        <span class="va">self</span>._check_feature_names(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-142"><a href="#cb2-142"></a>        <span class="va">self</span>._check_n_features(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-143"><a href="#cb2-143"></a>        </span>
<span id="cb2-144"><a href="#cb2-144"></a>        df <span class="op">=</span> pd.DataFrame(X_pd, columns<span class="op">=</span><span class="va">self</span>.feature_names_)</span>
<span id="cb2-145"><a href="#cb2-145"></a>        df <span class="op">=</span> TabularDataset(df)</span>
<span id="cb2-146"><a href="#cb2-146"></a>        <span class="cf">return</span> <span class="va">self</span>.predictor.predict_proba(df).values</span>
<span id="cb2-147"><a href="#cb2-147"></a></span>
<span id="cb2-148"><a href="#cb2-148"></a>    <span class="kw">def</span> get_params(<span class="va">self</span>, deep<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb2-149"><a href="#cb2-149"></a>        <span class="cf">return</span> {</span>
<span id="cb2-150"><a href="#cb2-150"></a>            <span class="st">'label'</span>: <span class="va">self</span>.label,</span>
<span id="cb2-151"><a href="#cb2-151"></a>            <span class="st">'predictor_args'</span>: <span class="va">self</span>.predictor_args,</span>
<span id="cb2-152"><a href="#cb2-152"></a>            <span class="st">'fit_args'</span>: <span class="va">self</span>.fit_args</span>
<span id="cb2-153"><a href="#cb2-153"></a>        }</span>
<span id="cb2-154"><a href="#cb2-154"></a></span>
<span id="cb2-155"><a href="#cb2-155"></a>    <span class="kw">def</span> set_params(<span class="va">self</span>, <span class="op">**</span>params):</span>
<span id="cb2-156"><a href="#cb2-156"></a>        <span class="cf">for</span> param, value <span class="kw">in</span> params.items():</span>
<span id="cb2-157"><a href="#cb2-157"></a>            <span class="cf">if</span> param <span class="op">==</span> <span class="st">'label'</span>:</span>
<span id="cb2-158"><a href="#cb2-158"></a>                <span class="va">self</span>.label <span class="op">=</span> value</span>
<span id="cb2-159"><a href="#cb2-159"></a>            <span class="cf">elif</span> param <span class="op">==</span> <span class="st">'predictor_args'</span>:</span>
<span id="cb2-160"><a href="#cb2-160"></a>                <span class="va">self</span>.predictor_args <span class="op">=</span> value</span>
<span id="cb2-161"><a href="#cb2-161"></a>            <span class="cf">elif</span> param <span class="op">==</span> <span class="st">'fit_args'</span>:</span>
<span id="cb2-162"><a href="#cb2-162"></a>                <span class="va">self</span>.fit_args <span class="op">=</span> value</span>
<span id="cb2-163"><a href="#cb2-163"></a>            <span class="cf">else</span>:</span>
<span id="cb2-164"><a href="#cb2-164"></a>                <span class="cf">if</span> <span class="st">'.'</span> <span class="kw">in</span> param:</span>
<span id="cb2-165"><a href="#cb2-165"></a>                    <span class="co"># Handle nested params like predictor_args.eval_metric</span></span>
<span id="cb2-166"><a href="#cb2-166"></a>                    main_key, sub_key <span class="op">=</span> param.split(<span class="st">'.'</span>, <span class="dv">1</span>)</span>
<span id="cb2-167"><a href="#cb2-167"></a>                    <span class="cf">if</span> main_key <span class="op">==</span> <span class="st">'predictor_args'</span> <span class="kw">and</span> <span class="bu">isinstance</span>(<span class="va">self</span>.predictor_args, <span class="bu">dict</span>):</span>
<span id="cb2-168"><a href="#cb2-168"></a>                        <span class="va">self</span>.predictor_args[sub_key] <span class="op">=</span> value</span>
<span id="cb2-169"><a href="#cb2-169"></a>                    <span class="cf">elif</span> main_key <span class="op">==</span> <span class="st">'fit_args'</span> <span class="kw">and</span> <span class="bu">isinstance</span>(<span class="va">self</span>.fit_args, <span class="bu">dict</span>):</span>
<span id="cb2-170"><a href="#cb2-170"></a>                        <span class="va">self</span>.fit_args[sub_key] <span class="op">=</span> value</span>
<span id="cb2-171"><a href="#cb2-171"></a>                    <span class="cf">else</span>:</span>
<span id="cb2-172"><a href="#cb2-172"></a>                        <span class="bu">setattr</span>(<span class="va">self</span>, param, value)</span>
<span id="cb2-173"><a href="#cb2-173"></a>                <span class="cf">else</span>:</span>
<span id="cb2-174"><a href="#cb2-174"></a>                    <span class="bu">setattr</span>(<span class="va">self</span>, param, value)</span>
<span id="cb2-175"><a href="#cb2-175"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb2-176"><a href="#cb2-176"></a>        </span>
<span id="cb2-177"><a href="#cb2-177"></a>    <span class="kw">def</span> _check_n_features(<span class="va">self</span>, X, reset<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb2-178"><a href="#cb2-178"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pd.DataFrame):</span>
<span id="cb2-179"><a href="#cb2-179"></a>            n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb2-180"><a href="#cb2-180"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, np.ndarray):</span>
<span id="cb2-181"><a href="#cb2-181"></a>            n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb2-182"><a href="#cb2-182"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb2-183"><a href="#cb2-183"></a>            n_features <span class="op">=</span> X.width </span>
<span id="cb2-184"><a href="#cb2-184"></a>        <span class="cf">else</span>:</span>
<span id="cb2-185"><a href="#cb2-185"></a>            <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="ss">f"Input X type </span><span class="sc">{</span><span class="bu">type</span>(X)<span class="sc">}</span><span class="ss"> not supported for _check_n_features."</span>)</span>
<span id="cb2-186"><a href="#cb2-186"></a>            </span>
<span id="cb2-187"><a href="#cb2-187"></a>        <span class="cf">if</span> reset:</span>
<span id="cb2-188"><a href="#cb2-188"></a>            <span class="va">self</span>.n_features_in_ <span class="op">=</span> n_features</span>
<span id="cb2-189"><a href="#cb2-189"></a>        <span class="cf">elif</span> n_features <span class="op">!=</span> <span class="va">self</span>.n_features_in_:</span>
<span id="cb2-190"><a href="#cb2-190"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Expected </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>n_features_in_<span class="sc">}</span><span class="ss"> features, got </span><span class="sc">{</span>n_features<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-191"><a href="#cb2-191"></a></span>
<span id="cb2-192"><a href="#cb2-192"></a>    <span class="kw">def</span> _check_feature_names(<span class="va">self</span>, X, reset<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb2-193"><a href="#cb2-193"></a>        current_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb2-194"><a href="#cb2-194"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pd.DataFrame):</span>
<span id="cb2-195"><a href="#cb2-195"></a>            current_feature_names <span class="op">=</span> X.columns.tolist()</span>
<span id="cb2-196"><a href="#cb2-196"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb2-197"><a href="#cb2-197"></a>            current_feature_names <span class="op">=</span> X.columns <span class="co"># Polars columns are already a list of strings</span></span>
<span id="cb2-198"><a href="#cb2-198"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, np.ndarray) <span class="kw">and</span> reset: <span class="co"># Only generate for np.ndarray if resetting names</span></span>
<span id="cb2-199"><a href="#cb2-199"></a>            current_feature_names <span class="op">=</span> [<span class="ss">f'feat_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb2-200"><a href="#cb2-200"></a>        <span class="cf">elif</span> <span class="kw">not</span> reset <span class="kw">and</span> <span class="bu">isinstance</span>(X, np.ndarray):</span>
<span id="cb2-201"><a href="#cb2-201"></a>             <span class="co"># If not resetting and X is numpy, assume feature order matches self.feature_names_</span></span>
<span id="cb2-202"><a href="#cb2-202"></a>            <span class="co"># No explicit name check possible here other than count (done in _check_n_features)</span></span>
<span id="cb2-203"><a href="#cb2-203"></a>            <span class="cf">return</span> </span>
<span id="cb2-204"><a href="#cb2-204"></a>        <span class="cf">else</span>:</span>
<span id="cb2-205"><a href="#cb2-205"></a>            <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="ss">f"Input X type </span><span class="sc">{</span><span class="bu">type</span>(X)<span class="sc">}</span><span class="ss"> not supported for _check_feature_names."</span>)</span>
<span id="cb2-206"><a href="#cb2-206"></a></span>
<span id="cb2-207"><a href="#cb2-207"></a>        <span class="cf">if</span> reset:</span>
<span id="cb2-208"><a href="#cb2-208"></a>            <span class="va">self</span>.feature_names_ <span class="op">=</span> current_feature_names</span>
<span id="cb2-209"><a href="#cb2-209"></a>        <span class="cf">elif</span> current_feature_names <span class="op">!=</span> <span class="va">self</span>.feature_names_:</span>
<span id="cb2-210"><a href="#cb2-210"></a>            <span class="co"># More informative error message for mismatch</span></span>
<span id="cb2-211"><a href="#cb2-211"></a>            msg <span class="op">=</span> <span class="ss">f"Feature names mismatch. Expected: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>feature_names_<span class="sc">}</span><span class="ss">. Got: </span><span class="sc">{</span>current_feature_names<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb2-212"><a href="#cb2-212"></a>            <span class="co"># Find differences for clarity</span></span>
<span id="cb2-213"><a href="#cb2-213"></a>            expected_set <span class="op">=</span> <span class="bu">set</span>(<span class="va">self</span>.feature_names_)</span>
<span id="cb2-214"><a href="#cb2-214"></a>            got_set <span class="op">=</span> <span class="bu">set</span>(current_feature_names)</span>
<span id="cb2-215"><a href="#cb2-215"></a>            <span class="cf">if</span> <span class="bu">len</span>(expected_set) <span class="op">!=</span> <span class="bu">len</span>(<span class="va">self</span>.feature_names_) <span class="kw">or</span> <span class="bu">len</span>(got_set) <span class="op">!=</span> <span class="bu">len</span>(current_feature_names):</span>
<span id="cb2-216"><a href="#cb2-216"></a>                msg <span class="op">+=</span> <span class="st">" (Note: Duplicate feature names might be an issue)"</span></span>
<span id="cb2-217"><a href="#cb2-217"></a>            <span class="cf">if</span> expected_set <span class="op">-</span> got_set:</span>
<span id="cb2-218"><a href="#cb2-218"></a>                msg <span class="op">+=</span> <span class="ss">f" Missing expected features: </span><span class="sc">{</span>expected_set <span class="op">-</span> got_set<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb2-219"><a href="#cb2-219"></a>            <span class="cf">if</span> got_set <span class="op">-</span> expected_set:</span>
<span id="cb2-220"><a href="#cb2-220"></a>                msg <span class="op">+=</span> <span class="ss">f" Unexpected features provided: </span><span class="sc">{</span>got_set <span class="op">-</span> expected_set<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb2-221"><a href="#cb2-221"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(msg)</span>
<span id="cb2-222"><a href="#cb2-222"></a></span>
<span id="cb2-223"><a href="#cb2-223"></a></span>
<span id="cb2-224"><a href="#cb2-224"></a><span class="co"># Initialize global seed</span></span>
<span id="cb2-225"><a href="#cb2-225"></a>global_set_seed(<span class="dv">2025</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="credit-card-fraud-detection" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Credit Card Fraud Detection</h1>
<p>Credit card fraud is a significant concern for financial institutions, merchants, and consumers. Understanding the types of fraud and how detection systems operate is crucial for developing effective machine learning models.</p>
<section id="card-present-frauds" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="card-present-frauds"><span class="header-section-number">3.1</span> Card-present frauds</h2>
<ul>
<li>Card-present (CP) fraud occurs when a transaction is made using a <strong>physical credit card</strong> that has been lost, stolen, counterfeited, or intercepted.</li>
<li>The legitimate cardholder is typically unaware of the fraudulent use until they notice unauthorized transactions on their statement or are alerted by their bank.</li>
<li>The key characteristic of CP fraud is that the <strong>physical card</strong> is used at the point of sale (e.g., a retail store, restaurant).</li>
</ul>
</section>
<section id="card-not-present-frauds" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="card-not-present-frauds"><span class="header-section-number">3.2</span> Card-not-present frauds</h2>
<ul>
<li>Card-not-present (CNP) fraud occurs when credit card information (such as card number, expiry date, CVV) is used <strong>without</strong> the physical card being present.</li>
<li>This type of fraud is common in online purchases.</li>
<li>Fraudsters may obtain card details through data breaches, phishing scams, or malware.</li>
<li>CNP fraud has become increasingly prevalent with the growth of e-commerce.</li>
</ul>
</section>
<section id="credit-card-fraud-detection-systems-ccfds" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="credit-card-fraud-detection-systems-ccfds"><span class="header-section-number">3.3</span> Credit Card Fraud Detection Systems (CCFDS)</h2>
<ul>
<li><strong>Credit Card Fraud Detection Systems (CCFDS)</strong> are designed to identify and prevent fraudulent transactions in real-time or near real-time by analyzing transaction data (e.g., amount, location, time, customer behavior, terminal ID) using rules and machine learning models.</li>
<li>If a transaction is flagged as potentially fraudulent, the system may block the transaction, alert the cardholder (e.g., via SMS or app notification), or refer the case to human fraud analysts for review.</li>
<li>The primary goal of a CCFDS is to minimize financial losses from fraud while also reducing false positives (legitimate transactions incorrectly blocked), which can negatively impact customer experience.</li>
<li>CCFDS must balance detection accuracy, speed, and customer convenience, often operating under strict latency requirements to avoid disrupting normal transaction flows.</li>
</ul>
</section>
<section id="class-imbalance-in-fraud-detection" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="class-imbalance-in-fraud-detection"><span class="header-section-number">3.4</span> Class Imbalance in Fraud Detection</h2>
<p>Class imbalance occurs when one class (e.g., fraudulent transactions) is significantly smaller compared to another class (e.g., legitimate transactions).</p>
<p><strong>Characteristics in Fraud Data</strong></p>
<ul>
<li><p>Rarity of Fraud: Fraudulent transactions are typically a small fraction (often <span class="math inline">\(&lt; 1\%\)</span>, sometimes <span class="math inline">\(&lt; 0.1\%\)</span>) of total transactions.</p></li>
<li><p>Standard accuracy can be misleading; a naive model predicting no fraud for all transactions might appear highly accurate.</p></li>
</ul>
<p><strong>Impact of Sample Size</strong></p>
<p>The difficulty of modeling depends on both the imbalance ratio (IR) and the absolute number of samples in the minority class (fraud) .</p>
<p>A higher imbalance ratio (IR) indicates greater class imbalance: <span class="math display">\[IR = \frac{\text{Number of samples in majority class}}{\text{Number of samples in minority class}}\]</span></p>
<p>The absolute number of samples in the minority class (fraud) also matters:</p>
<ul>
<li><p><strong>Large Datasets:</strong> A low fraud rate (e.g., 0.1%) in a large dataset (e.g., 100 million transactions) can still yield enough fraud examples (e.g., 100,000) for effective modeling training and testing.</p></li>
<li><p><strong>Small Datasets:</strong> The same low fraud rate in a small dataset (e.g., 1,000 transactions) results in too few fraud examples (e.g., 1) for reliable model training and testing.</p></li>
</ul>
<p>The lab assumes large imbalanced data sets.</p>
</section>
</section>
<section id="dealing-with-class-imbalance" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Dealing with Class Imbalance</h1>
<p>Several strategies can be employed to mitigate the effects of class imbalance when training fraud detection models. The choice of strategy can significantly impact model performance and its real-world effectiveness.</p>
<section id="do-nothing-approach" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="do-nothing-approach"><span class="header-section-number">4.1</span> Do-Nothing Approach</h2>
<p><strong>Rationale:</strong></p>
<ul>
<li>Class imbalance is an inherent characteristic of the data that reflects the true state of the world</li>
<li>Modifying the data (e.g., through resampling) distorts reality</li>
<li>Many modern machine learning estimators are relatively insensitive to class imbalance if configured and evaluated appropriately, including:
<ul>
<li>Tree-based ensembles (LightGBM, XGBoost, CatBoost)</li>
<li>Neural networks</li>
</ul></li>
<li>Under the do-nothing approach, class imbalance is a key feature of the data rather than a bug/defect that needs to be fixed.</li>
</ul>
<p><strong>Process:</strong></p>
<ol type="1">
<li><p>Train multiple estimators on the original, imbalanced dataset.</p></li>
<li><p>Select the best model with the lowest <strong>log loss</strong> on the test set.</p></li>
<li><p>Check for proper probability calibration (i.e., how well aligned are the predicted probabilities to the observed frequencies of fraud). Calibrate the predicted probabilities if needed.</p></li>
<li><p>Select the optimal decision threshold.</p></li>
<li><p>Evaluate the performance of the calibrated model and the optimal threshold on the test set.</p></li>
</ol>
</section>
<section id="class-sensitive-evaluation-approach" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="class-sensitive-evaluation-approach"><span class="header-section-number">4.2</span> Class-Sensitive Evaluation Approach</h2>
<p><strong>Rationale:</strong></p>
<ul>
<li>In fraud detection, the positive class (fraud) is much rarer than the negative class (legitimate transactions).</li>
<li><strong>ROC-AUC</strong> is a very common binary classification metric (the gold standard), but it can be misleading when classes are highly imbalanced:
<ul>
<li>ROC plots the True Positive Rate (also known as TPR, recall, sensitivity, or gain) against the False Positive Rate (FPR) at different decision thresholds.</li>
<li>The FPR denominator is huge (all legitimate transactions), so even many false positives may not increase the FPR much, making the ROC-AUC look artificially good.</li>
<li>Because there are so many legitimate transactions, even a model that misses many frauds (low recall) can still achieve a decent ROC-AUC if the model correctly classifies most legitimate transactions (true negatives).</li>
</ul></li>
<li><strong>Precision-Recall (PR) curves</strong> are more informative for imbalanced data:
<ul>
<li>The PR curve plots Precision (the proportion of predicted frauds that are actually fraud) against Recall (the proportion of actual frauds that are detected).</li>
<li>A model with high precision is desirable to minimize false alarms (which flag legitimate transactions as fraud).</li>
</ul></li>
<li><strong>PR-AUC</strong> (Area Under the PR Curve, also called Average Precision or AP) summarizes the PR curve in a single number.
<ul>
<li>A high PR-AUC means the model can achieve both high precision and high recall for fraud.</li>
<li>PR-AUC removes the effect of true negatives and focuses on the positive class (fraud).</li>
</ul></li>
</ul>
<p><strong>Process:</strong></p>
<ol type="1">
<li><p>Train multiple estimators on the original, imbalanced dataset.</p></li>
<li><p>Select the best model with the highest <strong>average precision</strong> on the test set.</p></li>
<li><p>Check for proper probability calibration. Calibrate the predicted probabilities if needed.</p></li>
<li><p>Select the optimal decision threshold.</p></li>
<li><p>Evaluate the performance of the calibrated model and the optimal threshold on the test set.</p></li>
</ol>
</section>
<section id="cost-sensitive-learning-approach" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="cost-sensitive-learning-approach"><span class="header-section-number">4.3</span> Cost-Sensitive Learning Approach</h2>
<p><strong>Rationale:</strong></p>
<ul>
<li>Cost-sensitive learning assigns different costs to classification errors.</li>
<li>In fraud detection, failing to detect a fraudulent transaction (a false negative) is typically much more costly than incorrectly flagging a legitimate transaction as fraudulent (a false positive).</li>
<li>By incorporating these costs, the model is encouraged to pay more attention to the minority (fraud) class.</li>
</ul>
<p><strong>Implementation Detail:</strong></p>
<ul>
<li>One common way to implement cost-sensitive learning is by using sample weights:
<ul>
<li>Instances from the minority class are given higher weights.</li>
<li>Instances from the majority class are given lower weights.</li>
<li>The weights are inversely proportional to class frequencies.</li>
</ul></li>
<li>AutoGluon provides a convenient way to do this:
<ul>
<li>Set the <code>sample_weight</code> argument in <code>predictor_args</code> to the special string <code>"balance_weight"</code>.</li>
<li>This automatically calculates and applies appropriate weights to balance the classes during training.</li>
</ul></li>
<li>Sample weights are not needed for the test set evaluation.</li>
</ul>
<p><strong>Process:</strong></p>
<ol type="1">
<li><p>Specify sample weights for each observation in the training set. This can be done by setting the <code>sample_weight</code> argument in <code>predictor_args</code> to <code>"balance_weight"</code>.</p></li>
<li><p>Train multiple estimators on the original, imbalanced dataset.</p></li>
<li><p>Select the best model with the highest <strong>average precision</strong> on the test set.</p></li>
<li><p>Check for proper probability calibration. Calibrate the predicted probabilities if needed.</p></li>
<li><p>Select the optimal decision threshold.</p></li>
<li><p>Evaluate the performance of the calibrated model and the optimal threshold on the test set.</p></li>
</ol>
</section>
<section id="resampling-approach" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="resampling-approach"><span class="header-section-number">4.4</span> Resampling Approach</h2>
<p><strong>Rationale:</strong></p>
<ul>
<li>Class-based resampling techniques modify the training datas class distribution to create a more balanced dataset.</li>
<li>Resampling is performed <strong>only</strong> on the training data</li>
<li>The calibration and test sets remain in their original, imbalanced form to reflect reality (i.e., fraud is rare).</li>
</ul>
<p><strong>Common Resampling Schemes:</strong></p>
<ul>
<li><p><strong>Random Undersampling (RUS):</strong> Randomly remove instances from the majority class until the dataset is more balanced. This can lead to loss of information from the majority class. However, the scheme substantially reduces the dataset size, which can be beneficial for training speed and memory usage.</p></li>
<li><p><strong>Random Oversampling (ROS):</strong> Randomly duplicate instances from the minority class. This can lead to overfitting on the minority class examples.</p></li>
<li><p><strong>SMOTE (Synthetic Minority Over-sampling Technique):</strong> Creates synthetic samples for the minority class by interpolating between actual minority instances. This can help to create a more diverse set of minority examples than simple oversampling.</p></li>
<li><p><strong>Hybrid Methods:</strong> Combine oversampling and undersampling. For example:</p>
<ul>
<li>First, apply SMOTE to generate synthetic samples for the minority class.</li>
<li>Then, apply random undersampling to the majority class.</li>
</ul></li>
</ul>
<p><strong>Process:</strong></p>
<ol type="1">
<li><p>Use RUS, ROS, SMOTE, or hybrid to create a <strong>balanced</strong> training set.</p></li>
<li><p>Train multiple estimators on the <strong>balanced</strong> training set.</p></li>
<li><p>Select the best model with the highest <strong>average precision</strong> on the test set (which is imbalanced).</p></li>
<li><p>Check for proper probability calibration. Calibrate the predicted probabilities if needed.</p></li>
<li><p>Select the optimal decision threshold.</p></li>
<li><p>Evaluate the performance of the calibrated model and the optimal threshold on the test set (which is imbalanced).</p></li>
</ol>
</section>
</section>
<section id="data-prep-for-big-data" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Data Prep for Big Data</h1>
<ul>
<li>Credit card transaction data involves a huge number of records, often millions or even billions, and new data arrives quickly.</li>
<li>Handling such large datasets efficiently is essential for fast analysis and model building.</li>
<li>Traditional tools like <code>pandas</code> can be slow and use a lot of memory with big data.</li>
<li>Modern libraries like <code>polars</code> and databases like <code>DuckDB</code> are designed to work faster and use memory more efficiently, making them better choices for large-scale data tasks.</li>
</ul>
<section id="data-loading" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="data-loading"><span class="header-section-number">5.1</span> Data Loading</h2>
<p>We will load all the parquet files found in the <code>Data/credit-card-fraud/simulated-data/</code> folder. Each parquet file contains credit card transactions for a single day.</p>
<p>Some notes about the parquet file format:</p>
<ul>
<li>The parquet file format is widely used for tabular data.</li>
<li>Parquet is designed for efficient storage (small file sizes) and fast processing (quick reads).</li>
<li>Data frame libraries such as <code>pandas</code>, <code>polars</code>, and <code>DuckDB</code> support reading from and writing to parquet files.</li>
<li>One drawback of parquet files is the lack of human readability, unlike CSV files.</li>
<li>Writing a parquet file to disk is also slower than writing a CSV file.</li>
</ul>
<p>Read all the parquet files into a <code>polars</code> data frame and a <code>DuckDB</code> table.</p>
<div id="read-parquet-polars" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>data_dir <span class="op">=</span> <span class="st">"../Data/credit-card-fraud/simulated-data/"</span></span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a>path_parquet_files <span class="op">=</span> glob.glob(os.path.join(data_dir, <span class="st">"*.parquet"</span>))</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a>df_fraud <span class="op">=</span> pl.read_parquet(path_parquet_files)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="read-parquet-duckdb" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>tbl_fraud <span class="op">=</span> duckdb.query(<span class="ss">f"""</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="ss">    SELECT * </span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="ss">    FROM read_parquet(</span><span class="sc">{</span>path_parquet_files<span class="sc">}</span><span class="ss">)</span></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="ss">    """</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="num-parquet-files" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="bu">print</span>(<span class="bu">len</span>(path_parquet_files)) <span class="co"># Display the number of parquet files found</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>183</code></pre>
</div>
</div>
<p>Take a peek at the data.</p>
<div id="cell-peek-polars" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>display(df_fraud.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="peek-polars" class="cell-output cell-output-display">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (10, 10)</small>
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">TRANSACTION_ID</th>
<th data-quarto-table-cell-role="th">TX_DATETIME</th>
<th data-quarto-table-cell-role="th">CUSTOMER_ID</th>
<th data-quarto-table-cell-role="th">TERMINAL_ID</th>
<th data-quarto-table-cell-role="th">TX_AMOUNT</th>
<th data-quarto-table-cell-role="th">TX_TIME_SECONDS</th>
<th data-quarto-table-cell-role="th">TX_TIME_DAYS</th>
<th data-quarto-table-cell-role="th">TX_FRAUD</th>
<th data-quarto-table-cell-role="th">TX_FRAUD_SCENARIO</th>
<th data-quarto-table-cell-role="th">__index_level_0__</th>
</tr>
<tr class="even">
<th>i64</th>
<th>datetime[ns]</th>
<th>i64</th>
<th>i64</th>
<th>f64</th>
<th>i64</th>
<th>i64</th>
<th>i64</th>
<th>i64</th>
<th>i64</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2018-04-01 00:00:31</td>
<td>596</td>
<td>3156</td>
<td>57.16</td>
<td>31</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>1</td>
<td>2018-04-01 00:02:10</td>
<td>4961</td>
<td>3412</td>
<td>81.51</td>
<td>130</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>2</td>
<td>2018-04-01 00:07:56</td>
<td>2</td>
<td>1365</td>
<td>146.0</td>
<td>476</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>2</td>
</tr>
<tr class="even">
<td>3</td>
<td>2018-04-01 00:09:29</td>
<td>4128</td>
<td>8737</td>
<td>64.49</td>
<td>569</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>3</td>
</tr>
<tr class="odd">
<td>4</td>
<td>2018-04-01 00:10:34</td>
<td>927</td>
<td>9906</td>
<td>50.99</td>
<td>634</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>4</td>
</tr>
<tr class="even">
<td>5</td>
<td>2018-04-01 00:10:45</td>
<td>568</td>
<td>8803</td>
<td>44.71</td>
<td>645</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>5</td>
</tr>
<tr class="odd">
<td>6</td>
<td>2018-04-01 00:11:30</td>
<td>2803</td>
<td>5490</td>
<td>96.03</td>
<td>690</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>6</td>
</tr>
<tr class="even">
<td>7</td>
<td>2018-04-01 00:11:44</td>
<td>4684</td>
<td>2486</td>
<td>24.36</td>
<td>704</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>7</td>
</tr>
<tr class="odd">
<td>8</td>
<td>2018-04-01 00:11:53</td>
<td>4128</td>
<td>8354</td>
<td>26.34</td>
<td>713</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>8</td>
</tr>
<tr class="even">
<td>9</td>
<td>2018-04-01 00:13:44</td>
<td>541</td>
<td>6212</td>
<td>59.07</td>
<td>824</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>9</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="cell-peek-duckdb" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>display(tbl_fraud.limit(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="peek-duckdb" class="cell-output cell-output-display">
<pre><code>
 TRANSACTION_ID      TX_DATETIME      CUSTOMER_ID  TERMINAL_ID  TX_AMOUNT  TX_TIME_SECONDS  TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  __index_level_0__ 
     int64          timestamp_ns         int64        int64      double         int64          int64       int64          int64              int64       

              0  2018-04-01 00:00:31          596         3156      57.16               31             0         0                  0                  0 
              1  2018-04-01 00:02:10         4961         3412      81.51              130             0         0                  0                  1 
              2  2018-04-01 00:07:56            2         1365      146.0              476             0         0                  0                  2 
              3  2018-04-01 00:09:29         4128         8737      64.49              569             0         0                  0                  3 
              4  2018-04-01 00:10:34          927         9906      50.99              634             0         0                  0                  4 
              5  2018-04-01 00:10:45          568         8803      44.71              645             0         0                  0                  5 
              6  2018-04-01 00:11:30         2803         5490      96.03              690             0         0                  0                  6 
              7  2018-04-01 00:11:44         4684         2486      24.36              704             0         0                  0                  7 
              8  2018-04-01 00:11:53         4128         8354      26.34              713             0         0                  0                  8 
              9  2018-04-01 00:13:44          541         6212      59.07              824             0         0                  0                  9 

 10 rows                                                                                                                                               10 columns 
</code></pre>
</div>
</div>
<p>Get column names and data types for both <code>polars</code> and <code>DuckDB</code>.</p>
<div id="cell-column-info-polars" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Get schema as a dictionary</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>summary_df <span class="op">=</span> pl.DataFrame({</span>
<span id="cb10-3"><a href="#cb10-3"></a>    <span class="st">"Column Name"</span>: df_fraud.columns,</span>
<span id="cb10-4"><a href="#cb10-4"></a>    <span class="st">"Data Type"</span>: [<span class="bu">str</span>(dtype) <span class="cf">for</span> dtype <span class="kw">in</span> df_fraud.dtypes]</span>
<span id="cb10-5"><a href="#cb10-5"></a>})</span>
<span id="cb10-6"><a href="#cb10-6"></a></span>
<span id="cb10-7"><a href="#cb10-7"></a>display(summary_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="column-info-polars" class="cell-output cell-output-display">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (10, 2)</small>
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Column Name</th>
<th data-quarto-table-cell-role="th">Data Type</th>
</tr>
<tr class="even">
<th>str</th>
<th>str</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>"TRANSACTION_ID"</td>
<td>"Int64"</td>
</tr>
<tr class="even">
<td>"TX_DATETIME"</td>
<td>"Datetime(time_unit='ns', time_</td>
</tr>
<tr class="odd">
<td>"CUSTOMER_ID"</td>
<td>"Int64"</td>
</tr>
<tr class="even">
<td>"TERMINAL_ID"</td>
<td>"Int64"</td>
</tr>
<tr class="odd">
<td>"TX_AMOUNT"</td>
<td>"Float64"</td>
</tr>
<tr class="even">
<td>"TX_TIME_SECONDS"</td>
<td>"Int64"</td>
</tr>
<tr class="odd">
<td>"TX_TIME_DAYS"</td>
<td>"Int64"</td>
</tr>
<tr class="even">
<td>"TX_FRAUD"</td>
<td>"Int64"</td>
</tr>
<tr class="odd">
<td>"TX_FRAUD_SCENARIO"</td>
<td>"Int64"</td>
</tr>
<tr class="even">
<td>"__index_level_0__"</td>
<td>"Int64"</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="column-info-duckdb" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>duckdb.sql(<span class="st">"""</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="st">    SELECT column_name, column_type</span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="st">    FROM</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="st">    (DESCRIBE SELECT * FROM tbl_fraud)</span></span>
<span id="cb11-5"><a href="#cb11-5"></a><span class="st">    """</span>).show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
    column_name     column_type  
      varchar         varchar    

 TRANSACTION_ID     BIGINT       
 TX_DATETIME        TIMESTAMP_NS 
 CUSTOMER_ID        BIGINT       
 TERMINAL_ID        BIGINT       
 TX_AMOUNT          DOUBLE       
 TX_TIME_SECONDS    BIGINT       
 TX_TIME_DAYS       BIGINT       
 TX_FRAUD           BIGINT       
 TX_FRAUD_SCENARIO  BIGINT       
 __index_level_0__  BIGINT       

 10 rows                2 columns 

</code></pre>
</div>
</div>
<p>Read the same parquet files with <code>pandas</code> for comparison.</p>
<div id="e148d020" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Read all parquet files into a pandas DataFrame (only .parquet files)</span></span>
<span id="cb13-2"><a href="#cb13-2"></a></span>
<span id="cb13-3"><a href="#cb13-3"></a>df_fraud_pd <span class="op">=</span> pd.read_parquet(path_parquet_files)</span>
<span id="cb13-4"><a href="#cb13-4"></a></span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="co"># Display the first few rows</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>display(df_fraud_pd.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">TRANSACTION_ID</th>
<th data-quarto-table-cell-role="th">TX_DATETIME</th>
<th data-quarto-table-cell-role="th">CUSTOMER_ID</th>
<th data-quarto-table-cell-role="th">TERMINAL_ID</th>
<th data-quarto-table-cell-role="th">TX_AMOUNT</th>
<th data-quarto-table-cell-role="th">TX_TIME_SECONDS</th>
<th data-quarto-table-cell-role="th">TX_TIME_DAYS</th>
<th data-quarto-table-cell-role="th">TX_FRAUD</th>
<th data-quarto-table-cell-role="th">TX_FRAUD_SCENARIO</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>2018-04-01 00:00:31</td>
<td>596</td>
<td>3156</td>
<td>57.16</td>
<td>31</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>2018-04-01 00:02:10</td>
<td>4961</td>
<td>3412</td>
<td>81.51</td>
<td>130</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>2018-04-01 00:07:56</td>
<td>2</td>
<td>1365</td>
<td>146.00</td>
<td>476</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>2018-04-01 00:09:29</td>
<td>4128</td>
<td>8737</td>
<td>64.49</td>
<td>569</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>2018-04-01 00:10:34</td>
<td>927</td>
<td>9906</td>
<td>50.99</td>
<td>634</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="data-frame-benchmarks" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="data-frame-benchmarks"><span class="header-section-number">5.2</span> Data Frame Benchmarks</h2>
<p>Calculate the fraud rate per CUSTOMER_ID using <code>polars</code>, <code>DuckDB</code>, and <code>pandas</code>. Show the fraud rate only for customers with more than 10 transactions. This will help us compare the performance of these libraries on a common task.</p>
<div id="fraud-rate-polars-complex" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb14-2"><a href="#cb14-2"></a></span>
<span id="cb14-3"><a href="#cb14-3"></a>fraud_analysis_polars <span class="op">=</span> (</span>
<span id="cb14-4"><a href="#cb14-4"></a>    df_fraud</span>
<span id="cb14-5"><a href="#cb14-5"></a>    .group_by(pl.col(<span class="st">"CUSTOMER_ID"</span>))</span>
<span id="cb14-6"><a href="#cb14-6"></a>    .agg(</span>
<span id="cb14-7"><a href="#cb14-7"></a>        FRAUD_RATE <span class="op">=</span> pl.col(<span class="st">"TX_FRAUD"</span>).mean(),  <span class="co"># FRAUD_RATE by CUSTOMER_ID</span></span>
<span id="cb14-8"><a href="#cb14-8"></a>        TOTAL_FRAUDS <span class="op">=</span> pl.col(<span class="st">"TX_FRAUD"</span>).<span class="bu">sum</span>(),</span>
<span id="cb14-9"><a href="#cb14-9"></a>        AVG_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).mean(),</span>
<span id="cb14-10"><a href="#cb14-10"></a>        STD_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).std(),</span>
<span id="cb14-11"><a href="#cb14-11"></a>        P95_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).quantile(<span class="fl">0.95</span>),</span>
<span id="cb14-12"><a href="#cb14-12"></a>        MIN_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).<span class="bu">min</span>(),</span>
<span id="cb14-13"><a href="#cb14-13"></a>        MAX_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).<span class="bu">max</span>(),</span>
<span id="cb14-14"><a href="#cb14-14"></a>        TX_COUNT <span class="op">=</span> pl.<span class="bu">len</span>(),</span>
<span id="cb14-15"><a href="#cb14-15"></a>        FRAUD_VALUE <span class="op">=</span> (pl.col(<span class="st">"TX_AMOUNT"</span>) <span class="op">*</span> pl.col(<span class="st">"TX_FRAUD"</span>)).<span class="bu">sum</span>(),</span>
<span id="cb14-16"><a href="#cb14-16"></a>        FIRST_TX <span class="op">=</span> pl.col(<span class="st">"TX_DATETIME"</span>).<span class="bu">min</span>(),</span>
<span id="cb14-17"><a href="#cb14-17"></a>        LAST_TX <span class="op">=</span> pl.col(<span class="st">"TX_DATETIME"</span>).<span class="bu">max</span>()</span>
<span id="cb14-18"><a href="#cb14-18"></a>    )</span>
<span id="cb14-19"><a href="#cb14-19"></a>    .with_columns(</span>
<span id="cb14-20"><a href="#cb14-20"></a>        AVG_FRAUD_AMOUNT <span class="op">=</span> (pl.col(<span class="st">"FRAUD_VALUE"</span>) <span class="op">/</span> pl.col(<span class="st">"TX_COUNT"</span>)),</span>
<span id="cb14-21"><a href="#cb14-21"></a>        CUSTOMER_TENURE_DAYS <span class="op">=</span> (pl.col(<span class="st">"LAST_TX"</span>) <span class="op">-</span> pl.col(<span class="st">"FIRST_TX"</span>)).dt.total_days()</span>
<span id="cb14-22"><a href="#cb14-22"></a>    )</span>
<span id="cb14-23"><a href="#cb14-23"></a>    .<span class="bu">filter</span>(pl.col(<span class="st">"TX_COUNT"</span>) <span class="op">&gt;</span> <span class="dv">10</span>)</span>
<span id="cb14-24"><a href="#cb14-24"></a>    .sort(<span class="st">"FRAUD_RATE"</span>, descending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-25"><a href="#cb14-25"></a>)</span>
<span id="cb14-26"><a href="#cb14-26"></a></span>
<span id="cb14-27"><a href="#cb14-27"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb14-28"><a href="#cb14-28"></a><span class="bu">print</span>(<span class="ss">f"Polars fraud analysis completed in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Polars fraud analysis completed in 0.06 seconds.</code></pre>
</div>
</div>
<div id="cell-print-polars-fraud-rate" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>display(fraud_analysis_polars.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="print-polars-fraud-rate" class="cell-output cell-output-display">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (10, 14)</small>
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">CUSTOMER_ID</th>
<th data-quarto-table-cell-role="th">FRAUD_RATE</th>
<th data-quarto-table-cell-role="th">TOTAL_FRAUDS</th>
<th data-quarto-table-cell-role="th">AVG_AMOUNT</th>
<th data-quarto-table-cell-role="th">STD_AMOUNT</th>
<th data-quarto-table-cell-role="th">P95_AMOUNT</th>
<th data-quarto-table-cell-role="th">MIN_AMOUNT</th>
<th data-quarto-table-cell-role="th">MAX_AMOUNT</th>
<th data-quarto-table-cell-role="th">TX_COUNT</th>
<th data-quarto-table-cell-role="th">FRAUD_VALUE</th>
<th data-quarto-table-cell-role="th">FIRST_TX</th>
<th data-quarto-table-cell-role="th">LAST_TX</th>
<th data-quarto-table-cell-role="th">AVG_FRAUD_AMOUNT</th>
<th data-quarto-table-cell-role="th">CUSTOMER_TENURE_DAYS</th>
</tr>
<tr class="even">
<th>i64</th>
<th>f64</th>
<th>i64</th>
<th>f64</th>
<th>f64</th>
<th>f64</th>
<th>f64</th>
<th>f64</th>
<th>u32</th>
<th>f64</th>
<th>datetime[ns]</th>
<th>datetime[ns]</th>
<th>f64</th>
<th>i64</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2871</td>
<td>0.2</td>
<td>5</td>
<td>102.952</td>
<td>83.660168</td>
<td>138.55</td>
<td>18.5</td>
<td>472.4</td>
<td>25</td>
<td>814.94</td>
<td>2018-04-01 15:36:36</td>
<td>2018-09-22 05:59:17</td>
<td>32.5976</td>
<td>173</td>
</tr>
<tr class="even">
<td>4609</td>
<td>0.12</td>
<td>3</td>
<td>33.306</td>
<td>31.049254</td>
<td>109.7</td>
<td>5.14</td>
<td>145.0</td>
<td>25</td>
<td>271.09</td>
<td>2018-04-01 07:06:34</td>
<td>2018-09-28 14:36:02</td>
<td>10.8436</td>
<td>180</td>
</tr>
<tr class="odd">
<td>2947</td>
<td>0.114286</td>
<td>4</td>
<td>68.208286</td>
<td>85.505047</td>
<td>265.6</td>
<td>11.24</td>
<td>370.95</td>
<td>35</td>
<td>1038.03</td>
<td>2018-04-05 09:13:23</td>
<td>2018-09-30 08:25:09</td>
<td>29.658</td>
<td>177</td>
</tr>
<tr class="even">
<td>305</td>
<td>0.093333</td>
<td>7</td>
<td>136.922</td>
<td>117.051828</td>
<td>257.7</td>
<td>1.25</td>
<td>781.55</td>
<td>75</td>
<td>2919.4</td>
<td>2018-04-02 08:28:47</td>
<td>2018-09-30 05:58:23</td>
<td>38.925333</td>
<td>180</td>
</tr>
<tr class="odd">
<td>2051</td>
<td>0.090909</td>
<td>1</td>
<td>109.950909</td>
<td>52.492328</td>
<td>236.19</td>
<td>39.4</td>
<td>236.19</td>
<td>11</td>
<td>236.19</td>
<td>2018-04-13 14:55:23</td>
<td>2018-09-27 16:48:55</td>
<td>21.471818</td>
<td>167</td>
</tr>
<tr class="even">
<td>3160</td>
<td>0.083333</td>
<td>1</td>
<td>13.410833</td>
<td>5.06018</td>
<td>18.58</td>
<td>5.09</td>
<td>22.84</td>
<td>12</td>
<td>10.16</td>
<td>2018-04-21 09:46:34</td>
<td>2018-09-21 12:04:30</td>
<td>0.846667</td>
<td>153</td>
</tr>
<tr class="odd">
<td>2944</td>
<td>0.083333</td>
<td>1</td>
<td>56.741667</td>
<td>39.956073</td>
<td>71.15</td>
<td>18.27</td>
<td>170.65</td>
<td>12</td>
<td>170.65</td>
<td>2018-05-16 17:33:50</td>
<td>2018-09-17 10:37:49</td>
<td>14.220833</td>
<td>123</td>
</tr>
<tr class="even">
<td>4650</td>
<td>0.083333</td>
<td>1</td>
<td>111.155833</td>
<td>101.400208</td>
<td>181.98</td>
<td>29.83</td>
<td>400.2</td>
<td>12</td>
<td>400.2</td>
<td>2018-04-11 16:49:44</td>
<td>2018-09-28 13:46:55</td>
<td>33.35</td>
<td>169</td>
</tr>
<tr class="odd">
<td>1449</td>
<td>0.079646</td>
<td>9</td>
<td>48.573451</td>
<td>51.496639</td>
<td>78.49</td>
<td>1.56</td>
<td>354.4</td>
<td>113</td>
<td>1672.65</td>
<td>2018-04-01 03:53:28</td>
<td>2018-09-29 08:59:12</td>
<td>14.802212</td>
<td>181</td>
</tr>
<tr class="even">
<td>1817</td>
<td>0.078864</td>
<td>25</td>
<td>113.971293</td>
<td>102.522073</td>
<td>217.49</td>
<td>1.71</td>
<td>786.15</td>
<td>317</td>
<td>9119.76</td>
<td>2018-04-01 11:51:02</td>
<td>2018-09-30 22:13:24</td>
<td>28.768959</td>
<td>182</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="fraud-rate-duckdb-complex" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb17-2"><a href="#cb17-2"></a></span>
<span id="cb17-3"><a href="#cb17-3"></a>fraud_analysis_duckdb <span class="op">=</span> duckdb.query(<span class="st">"""</span></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="st">    WITH customer_stats AS (</span></span>
<span id="cb17-5"><a href="#cb17-5"></a><span class="st">        SELECT </span></span>
<span id="cb17-6"><a href="#cb17-6"></a><span class="st">            CUSTOMER_ID,</span></span>
<span id="cb17-7"><a href="#cb17-7"></a><span class="st">            AVG(TX_FRAUD) AS FRAUD_RATE,  -- FRAUD_RATE by CUSTOMER_ID</span></span>
<span id="cb17-8"><a href="#cb17-8"></a><span class="st">            SUM(TX_FRAUD) AS TOTAL_FRAUDS,</span></span>
<span id="cb17-9"><a href="#cb17-9"></a><span class="st">            AVG(TX_AMOUNT) AS AVG_AMOUNT,</span></span>
<span id="cb17-10"><a href="#cb17-10"></a><span class="st">            STDDEV(TX_AMOUNT) AS STD_AMOUNT,</span></span>
<span id="cb17-11"><a href="#cb17-11"></a><span class="st">            PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY TX_AMOUNT) AS P95_AMOUNT,</span></span>
<span id="cb17-12"><a href="#cb17-12"></a><span class="st">            MIN(TX_AMOUNT) AS MIN_AMOUNT,</span></span>
<span id="cb17-13"><a href="#cb17-13"></a><span class="st">            MAX(TX_AMOUNT) AS MAX_AMOUNT,</span></span>
<span id="cb17-14"><a href="#cb17-14"></a><span class="st">            COUNT(*) AS TX_COUNT,</span></span>
<span id="cb17-15"><a href="#cb17-15"></a><span class="st">            SUM(TX_AMOUNT * TX_FRAUD) AS FRAUD_VALUE,</span></span>
<span id="cb17-16"><a href="#cb17-16"></a><span class="st">            MIN(TX_DATETIME) AS FIRST_TX,</span></span>
<span id="cb17-17"><a href="#cb17-17"></a><span class="st">            MAX(TX_DATETIME) AS LAST_TX</span></span>
<span id="cb17-18"><a href="#cb17-18"></a><span class="st">        FROM tbl_fraud</span></span>
<span id="cb17-19"><a href="#cb17-19"></a><span class="st">        GROUP BY CUSTOMER_ID</span></span>
<span id="cb17-20"><a href="#cb17-20"></a><span class="st">        HAVING COUNT(*) &gt; 10</span></span>
<span id="cb17-21"><a href="#cb17-21"></a><span class="st">    )</span></span>
<span id="cb17-22"><a href="#cb17-22"></a><span class="st">    SELECT *,</span></span>
<span id="cb17-23"><a href="#cb17-23"></a><span class="st">        FRAUD_VALUE / TX_COUNT AS AVG_FRAUD_AMOUNT,</span></span>
<span id="cb17-24"><a href="#cb17-24"></a><span class="st">        DATE_DIFF('day', FIRST_TX, LAST_TX) AS CUSTOMER_TENURE_DAYS</span></span>
<span id="cb17-25"><a href="#cb17-25"></a><span class="st">    FROM customer_stats</span></span>
<span id="cb17-26"><a href="#cb17-26"></a><span class="st">    ORDER BY FRAUD_RATE DESC</span></span>
<span id="cb17-27"><a href="#cb17-27"></a><span class="st">"""</span>)</span>
<span id="cb17-28"><a href="#cb17-28"></a></span>
<span id="cb17-29"><a href="#cb17-29"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb17-30"><a href="#cb17-30"></a><span class="bu">print</span>(<span class="ss">f"DuckDB fraud analysis completed in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>DuckDB fraud analysis completed in 0.01 seconds.</code></pre>
</div>
</div>
<div id="cell-print-duckdb-fraud-rate" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>display(fraud_analysis_duckdb.limit(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="print-duckdb-fraud-rate" class="cell-output cell-output-display">
<pre><code>
 CUSTOMER_ID      FRAUD_RATE       TOTAL_FRAUDS      AVG_AMOUNT          STD_AMOUNT          P95_AMOUNT      MIN_AMOUNT      MAX_AMOUNT      TX_COUNT     FRAUD_VALUE           FIRST_TX              LAST_TX         AVG_FRAUD_AMOUNT   CUSTOMER_TENURE_DAYS 
    int64           double            int128           double              double              double          double          double         int64          double           timestamp_ns         timestamp_ns            double               int64         

        2871                  0.2             5  102.95199999999997   83.66016754306276             137.352        18.5  472.40000000000003        25   814.9399999999999  2018-04-01 15:36:36  2018-09-22 05:59:17             32.5976                   174 
        4609                 0.12             3              33.306  31.049254016803687   97.62599999999983        5.14               145.0        25              271.09  2018-04-01 07:06:34  2018-09-28 14:36:02  10.843599999999999                   180 
        2947  0.11428571428571428             4    68.2082857142857   85.50504716735988   292.5099999999997       11.24              370.95        35             1038.03  2018-04-05 09:13:23  2018-09-30 08:25:09  29.657999999999998                   178 
         305  0.09333333333333334             7  136.92199999999997   117.0518284258637  290.17499999999967        1.25              781.55        75  2919.3999999999996  2018-04-02 08:28:47  2018-09-30 05:58:23   38.92533333333333                   181 
        2051  0.09090909090909091             1   109.9509090909091   52.49232771644737              189.59        39.4              236.19        11              236.19  2018-04-13 14:55:23  2018-09-27 16:48:55  21.471818181818183                   167 
        4650  0.08333333333333333             1  111.15583333333332  101.40020812766281  280.17899999999986       29.83  400.20000000000005        12  400.20000000000005  2018-04-11 16:49:44  2018-09-28 13:46:55               33.35                   170 
        3160  0.08333333333333333             1  13.410833333333334   5.060180482468142  20.496999999999996        5.09               22.84        12               10.16  2018-04-21 09:46:34  2018-09-21 12:04:30  0.8466666666666667                   153 
        2944  0.08333333333333333             1   56.74166666666667   39.95607266016321  115.92499999999993       18.27              170.65        12              170.65  2018-05-16 17:33:50  2018-09-17 10:37:49  14.220833333333333                   124 
        1449  0.07964601769911504             9  48.573451327433624   51.49663889465283  109.41399999999935        1.56               354.4       113  1672.6499999999999  2018-04-01 03:53:28  2018-09-29 08:59:12   14.80221238938053                   181 
        1817  0.07886435331230283            25  113.97129337539432  102.52207291463773  222.58199999999974        1.71              786.15       317             9119.76  2018-04-01 11:51:02  2018-09-30 22:13:24  28.768958990536277                   182 

 10 rows                                                                                                                                                                                                                                                        14 columns 
</code></pre>
</div>
</div>
<div id="fraud-rate-pandas-complex" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb21-2"><a href="#cb21-2"></a></span>
<span id="cb21-3"><a href="#cb21-3"></a>df_fraud_pd[<span class="st">'FRAUD_VALUE'</span>] <span class="op">=</span> df_fraud_pd[<span class="st">'TX_AMOUNT'</span>] <span class="op">*</span> df_fraud_pd[<span class="st">'TX_FRAUD'</span>]</span>
<span id="cb21-4"><a href="#cb21-4"></a></span>
<span id="cb21-5"><a href="#cb21-5"></a>fraud_analysis_pandas <span class="op">=</span> (</span>
<span id="cb21-6"><a href="#cb21-6"></a>    df_fraud_pd</span>
<span id="cb21-7"><a href="#cb21-7"></a>    .groupby(<span class="st">"CUSTOMER_ID"</span>, sort<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-8"><a href="#cb21-8"></a>    .agg(</span>
<span id="cb21-9"><a href="#cb21-9"></a>        FRAUD_RATE<span class="op">=</span>(<span class="st">'TX_FRAUD'</span>, <span class="st">'mean'</span>),  <span class="co"># FRAUD_RATE by CUSTOMER_ID</span></span>
<span id="cb21-10"><a href="#cb21-10"></a>        TOTAL_FRAUDS<span class="op">=</span>(<span class="st">'TX_FRAUD'</span>, <span class="st">'sum'</span>),</span>
<span id="cb21-11"><a href="#cb21-11"></a>        AVG_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'mean'</span>),</span>
<span id="cb21-12"><a href="#cb21-12"></a>        STD_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'std'</span>),</span>
<span id="cb21-13"><a href="#cb21-13"></a>        P95_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="kw">lambda</span> x: x.quantile(<span class="fl">0.95</span>)),</span>
<span id="cb21-14"><a href="#cb21-14"></a>        MIN_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'min'</span>),</span>
<span id="cb21-15"><a href="#cb21-15"></a>        MAX_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'max'</span>),</span>
<span id="cb21-16"><a href="#cb21-16"></a>        TX_COUNT<span class="op">=</span>(<span class="st">'TX_FRAUD'</span>, <span class="st">'size'</span>),</span>
<span id="cb21-17"><a href="#cb21-17"></a>        FRAUD_VALUE<span class="op">=</span>(<span class="st">'FRAUD_VALUE'</span>, <span class="st">'sum'</span>),</span>
<span id="cb21-18"><a href="#cb21-18"></a>        FIRST_TX<span class="op">=</span>(<span class="st">'TX_DATETIME'</span>, <span class="st">'min'</span>),</span>
<span id="cb21-19"><a href="#cb21-19"></a>        LAST_TX<span class="op">=</span>(<span class="st">'TX_DATETIME'</span>, <span class="st">'max'</span>)</span>
<span id="cb21-20"><a href="#cb21-20"></a>    )</span>
<span id="cb21-21"><a href="#cb21-21"></a>    .reset_index()</span>
<span id="cb21-22"><a href="#cb21-22"></a>    .query(<span class="st">"TX_COUNT &gt; 10"</span>)</span>
<span id="cb21-23"><a href="#cb21-23"></a>    .assign(</span>
<span id="cb21-24"><a href="#cb21-24"></a>        AVG_FRAUD_AMOUNT<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'FRAUD_VALUE'</span>] <span class="op">/</span> x[<span class="st">'TX_COUNT'</span>],</span>
<span id="cb21-25"><a href="#cb21-25"></a>        CUSTOMER_TENURE_DAYS<span class="op">=</span><span class="kw">lambda</span> x: (x[<span class="st">'LAST_TX'</span>] <span class="op">-</span> x[<span class="st">'FIRST_TX'</span>]).dt.days</span>
<span id="cb21-26"><a href="#cb21-26"></a>    )</span>
<span id="cb21-27"><a href="#cb21-27"></a>    .sort_values(<span class="st">"FRAUD_RATE"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-28"><a href="#cb21-28"></a>)</span>
<span id="cb21-29"><a href="#cb21-29"></a></span>
<span id="cb21-30"><a href="#cb21-30"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb21-31"><a href="#cb21-31"></a><span class="bu">print</span>(<span class="ss">f"Pandas fraud analysis completed in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Pandas fraud analysis completed in 0.99 seconds.</code></pre>
</div>
</div>
<div id="cell-print-pandas-fraud-rate" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>display(fraud_analysis_pandas.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="print-pandas-fraud-rate" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CUSTOMER_ID</th>
<th data-quarto-table-cell-role="th">FRAUD_RATE</th>
<th data-quarto-table-cell-role="th">TOTAL_FRAUDS</th>
<th data-quarto-table-cell-role="th">AVG_AMOUNT</th>
<th data-quarto-table-cell-role="th">STD_AMOUNT</th>
<th data-quarto-table-cell-role="th">P95_AMOUNT</th>
<th data-quarto-table-cell-role="th">MIN_AMOUNT</th>
<th data-quarto-table-cell-role="th">MAX_AMOUNT</th>
<th data-quarto-table-cell-role="th">TX_COUNT</th>
<th data-quarto-table-cell-role="th">FRAUD_VALUE</th>
<th data-quarto-table-cell-role="th">FIRST_TX</th>
<th data-quarto-table-cell-role="th">LAST_TX</th>
<th data-quarto-table-cell-role="th">AVG_FRAUD_AMOUNT</th>
<th data-quarto-table-cell-role="th">CUSTOMER_TENURE_DAYS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">3308</td>
<td>2871</td>
<td>0.200000</td>
<td>5</td>
<td>102.952000</td>
<td>83.660168</td>
<td>137.352</td>
<td>18.50</td>
<td>472.40</td>
<td>25</td>
<td>814.94</td>
<td>2018-04-01 15:36:36</td>
<td>2018-09-22 05:59:17</td>
<td>32.597600</td>
<td>173</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1333</td>
<td>4609</td>
<td>0.120000</td>
<td>3</td>
<td>33.306000</td>
<td>31.049254</td>
<td>97.626</td>
<td>5.14</td>
<td>145.00</td>
<td>25</td>
<td>271.09</td>
<td>2018-04-01 07:06:34</td>
<td>2018-09-28 14:36:02</td>
<td>10.843600</td>
<td>180</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4689</td>
<td>2947</td>
<td>0.114286</td>
<td>4</td>
<td>68.208286</td>
<td>85.505047</td>
<td>292.510</td>
<td>11.24</td>
<td>370.95</td>
<td>35</td>
<td>1038.03</td>
<td>2018-04-05 09:13:23</td>
<td>2018-09-30 08:25:09</td>
<td>29.658000</td>
<td>177</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3949</td>
<td>305</td>
<td>0.093333</td>
<td>7</td>
<td>136.922000</td>
<td>117.051828</td>
<td>290.175</td>
<td>1.25</td>
<td>781.55</td>
<td>75</td>
<td>2919.40</td>
<td>2018-04-02 08:28:47</td>
<td>2018-09-30 05:58:23</td>
<td>38.925333</td>
<td>180</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4906</td>
<td>2051</td>
<td>0.090909</td>
<td>1</td>
<td>109.950909</td>
<td>52.492328</td>
<td>189.590</td>
<td>39.40</td>
<td>236.19</td>
<td>11</td>
<td>236.19</td>
<td>2018-04-13 14:55:23</td>
<td>2018-09-27 16:48:55</td>
<td>21.471818</td>
<td>167</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4973</td>
<td>2944</td>
<td>0.083333</td>
<td>1</td>
<td>56.741667</td>
<td>39.956073</td>
<td>115.925</td>
<td>18.27</td>
<td>170.65</td>
<td>12</td>
<td>170.65</td>
<td>2018-05-16 17:33:50</td>
<td>2018-09-17 10:37:49</td>
<td>14.220833</td>
<td>123</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4939</td>
<td>3160</td>
<td>0.083333</td>
<td>1</td>
<td>13.410833</td>
<td>5.060180</td>
<td>20.497</td>
<td>5.09</td>
<td>22.84</td>
<td>12</td>
<td>10.16</td>
<td>2018-04-21 09:46:34</td>
<td>2018-09-21 12:04:30</td>
<td>0.846667</td>
<td>153</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4879</td>
<td>4650</td>
<td>0.083333</td>
<td>1</td>
<td>111.155833</td>
<td>101.400208</td>
<td>280.179</td>
<td>29.83</td>
<td>400.20</td>
<td>12</td>
<td>400.20</td>
<td>2018-04-11 16:49:44</td>
<td>2018-09-28 13:46:55</td>
<td>33.350000</td>
<td>169</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">505</td>
<td>1449</td>
<td>0.079646</td>
<td>9</td>
<td>48.573451</td>
<td>51.496639</td>
<td>109.414</td>
<td>1.56</td>
<td>354.40</td>
<td>113</td>
<td>1672.65</td>
<td>2018-04-01 03:53:28</td>
<td>2018-09-29 08:59:12</td>
<td>14.802212</td>
<td>181</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2688</td>
<td>1817</td>
<td>0.078864</td>
<td>25</td>
<td>113.971293</td>
<td>102.522073</td>
<td>222.582</td>
<td>1.71</td>
<td>786.15</td>
<td>317</td>
<td>9119.76</td>
<td>2018-04-01 11:51:02</td>
<td>2018-09-30 22:13:24</td>
<td>28.768959</td>
<td>182</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="prequential-data-splitting-using-polars" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="prequential-data-splitting-using-polars"><span class="header-section-number">5.3</span> Prequential Data Splitting (using Polars)</h2>
<p>To properly evaluate fraud detection models, we split the data <strong>chronologically</strong> into training, tuning (calibration), and test sets based on the <code>TX_DATETIME</code> column.</p>
<p>Also known as out-of-time validation, prequential data splitting ensures that future transactions do not influence model training or validation.</p>
<p>The lab splits the data into three sets:</p>
<ul>
<li><code>df_train</code>: Transactions before <code>2018-07-31</code> (inclusive).</li>
<li><code>df_tuning</code>: Transactions between <code>2018-08-01</code> (inclusive) and <code>2018-08-31</code> (inclusive).</li>
<li><code>df_test</code>: Transactions after <code>2018-09-01</code> (inclusive).</li>
</ul>
<div id="data-splitting-polars" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># Prequential data splitting using Polars</span></span>
<span id="cb24-2"><a href="#cb24-2"></a></span>
<span id="cb24-3"><a href="#cb24-3"></a><span class="kw">def</span> split_data(df: pl.DataFrame</span>
<span id="cb24-4"><a href="#cb24-4"></a>            , <span class="bu">type</span>: <span class="bu">str</span> <span class="op">=</span> <span class="st">"train"</span>) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb24-5"><a href="#cb24-5"></a>    <span class="co">"""</span></span>
<span id="cb24-6"><a href="#cb24-6"></a><span class="co">    Splits the data into train, tuning, and test sets based on TX_DATETIME.</span></span>
<span id="cb24-7"><a href="#cb24-7"></a><span class="co">    """</span></span>
<span id="cb24-8"><a href="#cb24-8"></a>    <span class="cf">if</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"train"</span>:</span>
<span id="cb24-9"><a href="#cb24-9"></a>        <span class="cf">return</span> df.<span class="bu">filter</span>(pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&lt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">7</span>, <span class="dv">31</span>))</span>
<span id="cb24-10"><a href="#cb24-10"></a>    <span class="cf">elif</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"tuning"</span>:</span>
<span id="cb24-11"><a href="#cb24-11"></a>        <span class="cf">return</span> df.<span class="bu">filter</span>((pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&gt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">8</span>, <span class="dv">1</span>)) </span>
<span id="cb24-12"><a href="#cb24-12"></a>                        <span class="op">&amp;</span> (pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&lt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">8</span>, <span class="dv">31</span>)))</span>
<span id="cb24-13"><a href="#cb24-13"></a>    <span class="cf">elif</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"test"</span>:</span>
<span id="cb24-14"><a href="#cb24-14"></a>        <span class="cf">return</span> df.<span class="bu">filter</span>(pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&gt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">9</span>, <span class="dv">1</span>))</span>
<span id="cb24-15"><a href="#cb24-15"></a>    <span class="cf">else</span>:</span>
<span id="cb24-16"><a href="#cb24-16"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown split type: </span><span class="sc">{</span><span class="bu">type</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-17"><a href="#cb24-17"></a></span>
<span id="cb24-18"><a href="#cb24-18"></a><span class="co"># Split the data into train, tuning, and test sets</span></span>
<span id="cb24-19"><a href="#cb24-19"></a></span>
<span id="cb24-20"><a href="#cb24-20"></a><span class="co"># df_train: Transactions before 2018-07-31 (inclusive)</span></span>
<span id="cb24-21"><a href="#cb24-21"></a>df_train <span class="op">=</span> split_data(df_fraud, <span class="bu">type</span><span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb24-22"><a href="#cb24-22"></a></span>
<span id="cb24-23"><a href="#cb24-23"></a><span class="co"># df_tuning: Transactions between 2018-08-01 (inclusive) and 2018-08-31 (inclusive)</span></span>
<span id="cb24-24"><a href="#cb24-24"></a>df_tuning <span class="op">=</span> split_data(df_fraud, <span class="bu">type</span><span class="op">=</span><span class="st">"tuning"</span>)</span>
<span id="cb24-25"><a href="#cb24-25"></a></span>
<span id="cb24-26"><a href="#cb24-26"></a><span class="co"># df_test: Transactions after 2018-09-01 (inclusive)</span></span>
<span id="cb24-27"><a href="#cb24-27"></a>df_test <span class="op">=</span> split_data(df_fraud, <span class="bu">type</span><span class="op">=</span><span class="st">"test"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-sample-sizes" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>df_train.shape, df_tuning.shape, df_test.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="sample-sizes" class="cell-output cell-output-display" data-execution_count="216">
<pre><code>((1160018, 10), (287055, 10), (287873, 10))</code></pre>
</div>
</div>
</section>
</section>
<section id="eda-compare-df_train-and-df_tuning" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> EDA: Compare <code>df_train</code> and <code>df_tuning</code></h1>
<p>Unfortunately, the <code>ydata_profiling</code> library does not support polars data frames. The lab will randomly sample 10% of each data frame and then convert to pandas data frames for profiling. This is a workaround to allow us to compare the two datasets using the <code>ydata_profiling</code> library.</p>
<p>For the data dictionary, please refer to Chapter 3 of <span class="citation" data-cites="leborgne2022fraud">Le Borgne et al. (<a href="#ref-leborgne2022fraud" role="doc-biblioref">2022</a>)</span>.</p>
<div id="eda-train-tuning-comparison" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a>p_frac <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb27-2"><a href="#cb27-2"></a></span>
<span id="cb27-3"><a href="#cb27-3"></a>train_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb27-4"><a href="#cb27-4"></a>            df_train.sample(fraction<span class="op">=</span>p_frac, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb27-5"><a href="#cb27-5"></a>            title<span class="op">=</span><span class="st">"Train"</span>,</span>
<span id="cb27-6"><a href="#cb27-6"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb27-7"><a href="#cb27-7"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb27-8"><a href="#cb27-8"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb27-9"><a href="#cb27-9"></a>            )</span>
<span id="cb27-10"><a href="#cb27-10"></a></span>
<span id="cb27-11"><a href="#cb27-11"></a>tuning_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb27-12"><a href="#cb27-12"></a>            df_tuning.sample(fraction<span class="op">=</span>p_frac<span class="op">*</span><span class="dv">2</span>, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb27-13"><a href="#cb27-13"></a>            title<span class="op">=</span><span class="st">"Tuning"</span>,</span>
<span id="cb27-14"><a href="#cb27-14"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb27-15"><a href="#cb27-15"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb27-16"><a href="#cb27-16"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb27-17"><a href="#cb27-17"></a>            )</span>
<span id="cb27-18"><a href="#cb27-18"></a></span>
<span id="cb27-19"><a href="#cb27-19"></a>compare_profile <span class="op">=</span> train_data_profile.compare(tuning_data_profile)</span>
<span id="cb27-20"><a href="#cb27-20"></a></span>
<span id="cb27-21"><a href="#cb27-21"></a>compare_profile.to_file(<span class="st">"Lab04_eda_compare_train_tuning.html"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="feature-engineering" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Feature Engineering</h1>
<p>The section creates new features that enhance the effectiveness of fraud detection models.</p>
<p>The feature engineering logic is based on Chapter 3 of <span class="citation" data-cites="leborgne2022fraud">Le Borgne et al. (<a href="#ref-leborgne2022fraud" role="doc-biblioref">2022</a>)</span>, but has been adapted to use Polars expressions for improved speed and efficiency.</p>
<section id="polars-feature-functions" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="polars-feature-functions"><span class="header-section-number">7.1</span> Polars Feature Functions</h2>
<p>We will create functions to generate the following features. Each function will take a Polars DataFrame as input and return a Polars DataFrame with the new feature(s) added.</p>
<p>Date-related features:</p>
<ol type="1">
<li><p>TX_DURING_WEEKEND: whether the transaction occurred on a weekend (1 if weekend, 0 if weekday).</p></li>
<li><p>TX_DURING_NIGHT: whether the transaction occurred during the night (1 if night, 0 if day).</p></li>
</ol>
<p>Customer features:</p>
<ol start="3" type="1">
<li><p>CUSTOMER_ID_NB_TX_1DAY_WINDOW: number of transactions for the customer in the last 1 day.</p></li>
<li><p>CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW: average transaction amount for the customer in the last 1 day.</p></li>
<li><p>CUSTOMER_ID_NB_TX_7DAY_WINDOW: number of transactions for the customer in the last 7 days.</p></li>
<li><p>CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW: average transaction amount for the customer in the last 7 days.</p></li>
<li><p>CUSTOMER_ID_NB_TX_30DAY_WINDOW: number of transactions for the customer in the last 30 days.</p></li>
<li><p>CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW: average transaction amount for the customer in the last 30 days.</p></li>
</ol>
<p>Terminal features:</p>
<ol start="9" type="1">
<li><p>TERMINAL_ID_NB_TX_1DAY_WINDOW: number of transactions for the terminal in the last 1 day. Lagged 7 days to account for a lag in fraud labeling.</p></li>
<li><p>TERMINAL_ID_RISK_1DAY_WINDOW: proportion of <strong>fraudulent</strong> transactions for the terminal in the last 1 day. Lagged 7 days to account for a lag in fraud labeling.</p></li>
<li><p>TERMINAL_ID_NB_TX_7DAY_WINDOW: number of transactions for the terminal in the last 7 days. Lagged 7 days to account for a lag in fraud labeling.</p></li>
<li><p>TERMINAL_ID_RISK_7DAY_WINDOW: proportion of <strong>fraudulent</strong> transactions for the terminal in the last 7 days. Lagged 7 days to account for a lag in fraud labeling.</p></li>
<li><p>TERMINAL_ID_NB_TX_30DAY_WINDOW: number of transactions for the terminal in the last 30 days. Lagged 7 days to account for a lag in fraud labeling.</p></li>
<li><p>TERMINAL_ID_RISK_30DAY_WINDOW: proportion of <strong>fraudulent</strong> transactions for the terminal in the last 30 days. Lagged 7 days to account for a lag in fraud labeling.</p></li>
</ol>
<section id="weekend-flag" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="weekend-flag"><span class="header-section-number">7.1.1</span> Weekend Flag</h3>
<p>The feature indicates if a transaction occurred on a weekend.</p>
<div id="feature-is-weekend" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="kw">def</span> fe_is_weekend(df: pl.DataFrame) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb28-2"><a href="#cb28-2"></a>    <span class="co">"""Adds IS_WEEKEND feature (1 if weekend, 0 if weekday)."""</span></span>
<span id="cb28-3"><a href="#cb28-3"></a>    <span class="co"># Polars weekday(): Monday=1, Sunday=7. So, Saturday (6) or Sunday (7) are weekends.</span></span>
<span id="cb28-4"><a href="#cb28-4"></a>    <span class="cf">return</span> df.with_columns(</span>
<span id="cb28-5"><a href="#cb28-5"></a>        TX_DURING_WEEKEND <span class="op">=</span> (pl.col(<span class="st">"TX_DATETIME"</span>).dt.weekday()</span>
<span id="cb28-6"><a href="#cb28-6"></a>                                .is_in([<span class="dv">6</span>, <span class="dv">7</span>])</span>
<span id="cb28-7"><a href="#cb28-7"></a>                                .cast(pl.UInt8))</span>
<span id="cb28-8"><a href="#cb28-8"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="night-flag" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="night-flag"><span class="header-section-number">7.1.2</span> Night Flag</h3>
<p>The feature indicates if a transaction occurred during the night (defined as between midnight and 6:00 AM).</p>
<div id="feature-is-night" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="kw">def</span> fe_is_night(df: pl.DataFrame) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb29-2"><a href="#cb29-2"></a>    <span class="co">"""Adds IS_NIGHT feature (1 if hour &lt; 6, 0 otherwise)."""</span></span>
<span id="cb29-3"><a href="#cb29-3"></a>    <span class="cf">return</span> df.with_columns(</span>
<span id="cb29-4"><a href="#cb29-4"></a>        TX_DURING_NIGHT <span class="op">=</span> pl.when(pl.col(<span class="st">"TX_DATETIME"</span>).dt.hour() <span class="op">&lt;</span> <span class="dv">6</span>)</span>
<span id="cb29-5"><a href="#cb29-5"></a>                            .then(<span class="dv">1</span>)</span>
<span id="cb29-6"><a href="#cb29-6"></a>                            .otherwise(<span class="dv">0</span>)</span>
<span id="cb29-7"><a href="#cb29-7"></a>                            .cast(pl.UInt8)</span>
<span id="cb29-8"><a href="#cb29-8"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="customer-features" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="customer-features"><span class="header-section-number">7.1.3</span> Customer Features</h3>
<p>The features describe a customers recent transaction count and average transaction amount over different rolling time windows (1, 7, and 30 days).</p>
<div id="feature-customer-spending" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="kw">def</span> fe_customer_spending(df: pl.DataFrame, window_sizes_in_days<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>]) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb30-2"><a href="#cb30-2"></a>    <span class="co">"""</span></span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="co">    Calculates customer spending features:</span></span>
<span id="cb30-4"><a href="#cb30-4"></a><span class="co">    - Count of transactions per customer over different window_sizes.</span></span>
<span id="cb30-5"><a href="#cb30-5"></a><span class="co">    - Average transaction amount per customer over different window_sizes.</span></span>
<span id="cb30-6"><a href="#cb30-6"></a><span class="co">    """</span></span>
<span id="cb30-7"><a href="#cb30-7"></a></span>
<span id="cb30-8"><a href="#cb30-8"></a>    df_int <span class="op">=</span> (</span>
<span id="cb30-9"><a href="#cb30-9"></a>        df</span>
<span id="cb30-10"><a href="#cb30-10"></a>        .sort(pl.col(<span class="st">"CUSTOMER_ID"</span>), pl.col(<span class="st">"TX_DATETIME"</span>)) <span class="co"># very important to sort</span></span>
<span id="cb30-11"><a href="#cb30-11"></a>        .with_columns(</span>
<span id="cb30-12"><a href="#cb30-12"></a>            pl.col(<span class="st">"CUSTOMER_ID"</span>).cast(pl.UInt64),</span>
<span id="cb30-13"><a href="#cb30-13"></a>            pl.lit(<span class="dv">1</span>).alias(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb30-14"><a href="#cb30-14"></a>        )</span>
<span id="cb30-15"><a href="#cb30-15"></a>    )</span>
<span id="cb30-16"><a href="#cb30-16"></a></span>
<span id="cb30-17"><a href="#cb30-17"></a>    result_df <span class="op">=</span> df_int</span>
<span id="cb30-18"><a href="#cb30-18"></a>    <span class="cf">for</span> window <span class="kw">in</span> window_sizes_in_days:</span>
<span id="cb30-19"><a href="#cb30-19"></a>        result_df <span class="op">=</span> (</span>
<span id="cb30-20"><a href="#cb30-20"></a>            result_df</span>
<span id="cb30-21"><a href="#cb30-21"></a>            .with_columns(</span>
<span id="cb30-22"><a href="#cb30-22"></a>                pl.col(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb30-23"><a href="#cb30-23"></a>                    .rolling_sum_by(by<span class="op">=</span>pl.col(<span class="st">"TX_DATETIME"</span>)</span>
<span id="cb30-24"><a href="#cb30-24"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb30-25"><a href="#cb30-25"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb30-26"><a href="#cb30-26"></a>                        )</span>
<span id="cb30-27"><a href="#cb30-27"></a>                    .over(<span class="st">"CUSTOMER_ID"</span>)</span>
<span id="cb30-28"><a href="#cb30-28"></a>                .alias(<span class="ss">f"CID_NB_TX_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb30-29"><a href="#cb30-29"></a></span>
<span id="cb30-30"><a href="#cb30-30"></a>                pl.col(<span class="st">"TX_AMOUNT"</span>)</span>
<span id="cb30-31"><a href="#cb30-31"></a>                    .rolling_mean_by(by<span class="op">=</span>pl.col(<span class="st">"TX_DATETIME"</span>)</span>
<span id="cb30-32"><a href="#cb30-32"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb30-33"><a href="#cb30-33"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb30-34"><a href="#cb30-34"></a>                        )</span>
<span id="cb30-35"><a href="#cb30-35"></a>                    .over(<span class="st">"CUSTOMER_ID"</span>)</span>
<span id="cb30-36"><a href="#cb30-36"></a>                .alias(<span class="ss">f"CID_AVG_AMOUNT_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>)</span>
<span id="cb30-37"><a href="#cb30-37"></a>            )</span>
<span id="cb30-38"><a href="#cb30-38"></a>        )</span>
<span id="cb30-39"><a href="#cb30-39"></a></span>
<span id="cb30-40"><a href="#cb30-40"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="terminal-features" class="level3" data-number="7.1.4">
<h3 data-number="7.1.4" class="anchored" data-anchor-id="terminal-features"><span class="header-section-number">7.1.4</span> Terminal Features</h3>
<p>The features describe a point-of-sale terminals recent transactions count and the proportion of fraudulent transactions over several rolling time windows (1, 7, 30 days). A 7-day delay period is introduced because fraud labels are not be available immediately.</p>
<div id="feature-terminal-risk" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="kw">def</span> fe_terminal_risk(</span>
<span id="cb31-2"><a href="#cb31-2"></a>    df: pl.DataFrame, </span>
<span id="cb31-3"><a href="#cb31-3"></a>    delay_period_days: <span class="bu">int</span> <span class="op">=</span> <span class="dv">7</span>, </span>
<span id="cb31-4"><a href="#cb31-4"></a>    window_sizes_in_days: <span class="bu">list</span> <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>]</span>
<span id="cb31-5"><a href="#cb31-5"></a>) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb31-6"><a href="#cb31-6"></a>    <span class="co">"""</span></span>
<span id="cb31-7"><a href="#cb31-7"></a><span class="co">    Adds terminal risk features for various window sizes, considering a 7-day delay in fraud labeling.</span></span>
<span id="cb31-8"><a href="#cb31-8"></a><span class="co">    For each window, computes:</span></span>
<span id="cb31-9"><a href="#cb31-9"></a><span class="co">        - Number of transactions at the terminal in the window (lagged by delay_period_days)</span></span>
<span id="cb31-10"><a href="#cb31-10"></a><span class="co">        - Proportion of fraudulent transactions at the terminal in the window (lagged)</span></span>
<span id="cb31-11"><a href="#cb31-11"></a><span class="co">    """</span></span>
<span id="cb31-12"><a href="#cb31-12"></a>    <span class="co"># Sort by TERMINAL_ID and TX_DATETIME for correct rolling calculations</span></span>
<span id="cb31-13"><a href="#cb31-13"></a>    df_int <span class="op">=</span> (</span>
<span id="cb31-14"><a href="#cb31-14"></a>        df</span>
<span id="cb31-15"><a href="#cb31-15"></a>        .sort(pl.col(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb31-16"><a href="#cb31-16"></a>            , pl.col(<span class="st">"TX_DATETIME"</span>)</span>
<span id="cb31-17"><a href="#cb31-17"></a>        )</span>
<span id="cb31-18"><a href="#cb31-18"></a>        .with_columns(</span>
<span id="cb31-19"><a href="#cb31-19"></a>            pl.col(<span class="st">"TERMINAL_ID"</span>).cast(pl.UInt64),</span>
<span id="cb31-20"><a href="#cb31-20"></a>            pl.lit(<span class="dv">1</span>).alias(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb31-21"><a href="#cb31-21"></a>        )</span>
<span id="cb31-22"><a href="#cb31-22"></a>    )</span>
<span id="cb31-23"><a href="#cb31-23"></a></span>
<span id="cb31-24"><a href="#cb31-24"></a>    result_df <span class="op">=</span> df_int</span>
<span id="cb31-25"><a href="#cb31-25"></a>    <span class="cf">for</span> window <span class="kw">in</span> window_sizes_in_days:</span>
<span id="cb31-26"><a href="#cb31-26"></a></span>
<span id="cb31-27"><a href="#cb31-27"></a>        full_offset <span class="op">=</span> window <span class="op">+</span> delay_period_days</span>
<span id="cb31-28"><a href="#cb31-28"></a></span>
<span id="cb31-29"><a href="#cb31-29"></a>        <span class="co"># Rolling window with delay (offset)</span></span>
<span id="cb31-30"><a href="#cb31-30"></a>        result_df <span class="op">=</span> (</span>
<span id="cb31-31"><a href="#cb31-31"></a>            result_df</span>
<span id="cb31-32"><a href="#cb31-32"></a>            .with_columns(</span>
<span id="cb31-33"><a href="#cb31-33"></a>                pl.col(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb31-34"><a href="#cb31-34"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb31-35"><a href="#cb31-35"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb31-36"><a href="#cb31-36"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb31-37"><a href="#cb31-37"></a>                        )</span>
<span id="cb31-38"><a href="#cb31-38"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb31-39"><a href="#cb31-39"></a>                .alias(<span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb31-40"><a href="#cb31-40"></a></span>
<span id="cb31-41"><a href="#cb31-41"></a>                pl.col(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb31-42"><a href="#cb31-42"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb31-43"><a href="#cb31-43"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb31-44"><a href="#cb31-44"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb31-45"><a href="#cb31-45"></a>                        )</span>
<span id="cb31-46"><a href="#cb31-46"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb31-47"><a href="#cb31-47"></a>                .alias(<span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb31-48"><a href="#cb31-48"></a></span>
<span id="cb31-49"><a href="#cb31-49"></a></span>
<span id="cb31-50"><a href="#cb31-50"></a>                pl.col(<span class="st">"TX_FRAUD"</span>)</span>
<span id="cb31-51"><a href="#cb31-51"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb31-52"><a href="#cb31-52"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb31-53"><a href="#cb31-53"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb31-54"><a href="#cb31-54"></a>                        )  </span>
<span id="cb31-55"><a href="#cb31-55"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb31-56"><a href="#cb31-56"></a>                .alias(<span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb31-57"><a href="#cb31-57"></a></span>
<span id="cb31-58"><a href="#cb31-58"></a>                pl.col(<span class="st">"TX_FRAUD"</span>)</span>
<span id="cb31-59"><a href="#cb31-59"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb31-60"><a href="#cb31-60"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb31-61"><a href="#cb31-61"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb31-62"><a href="#cb31-62"></a>                        )  </span>
<span id="cb31-63"><a href="#cb31-63"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb31-64"><a href="#cb31-64"></a>                .alias(<span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>)</span>
<span id="cb31-65"><a href="#cb31-65"></a>            )</span>
<span id="cb31-66"><a href="#cb31-66"></a></span>
<span id="cb31-67"><a href="#cb31-67"></a>        )</span>
<span id="cb31-68"><a href="#cb31-68"></a></span>
<span id="cb31-69"><a href="#cb31-69"></a>        <span class="co"># Compute risk (proportion of frauds)</span></span>
<span id="cb31-70"><a href="#cb31-70"></a>        risk_col <span class="op">=</span> <span class="ss">f"TID_RISK_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb31-71"><a href="#cb31-71"></a></span>
<span id="cb31-72"><a href="#cb31-72"></a>        nb_tx_col <span class="op">=</span> <span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb31-73"><a href="#cb31-73"></a>        nb_fraud_col <span class="op">=</span> <span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb31-74"><a href="#cb31-74"></a></span>
<span id="cb31-75"><a href="#cb31-75"></a>        nb_tx_col_fulloffset <span class="op">=</span> <span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb31-76"><a href="#cb31-76"></a>        nb_fraud_col_fulloffset <span class="op">=</span> <span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb31-77"><a href="#cb31-77"></a></span>
<span id="cb31-78"><a href="#cb31-78"></a>        result_df <span class="op">=</span> (</span>
<span id="cb31-79"><a href="#cb31-79"></a>            result_df</span>
<span id="cb31-80"><a href="#cb31-80"></a>            .with_columns(</span>
<span id="cb31-81"><a href="#cb31-81"></a>                (pl.col(nb_tx_col_fulloffset) <span class="op">-</span> pl.col(nb_tx_col)).alias(nb_tx_col),</span>
<span id="cb31-82"><a href="#cb31-82"></a>                (pl.col(nb_fraud_col_fulloffset) <span class="op">-</span> pl.col(nb_fraud_col)).alias(nb_fraud_col)</span>
<span id="cb31-83"><a href="#cb31-83"></a>            )</span>
<span id="cb31-84"><a href="#cb31-84"></a>            .select(pl.col(<span class="st">"*"</span>)</span>
<span id="cb31-85"><a href="#cb31-85"></a>                .exclude([nb_tx_col_fulloffset, nb_fraud_col_fulloffset])</span>
<span id="cb31-86"><a href="#cb31-86"></a>                )</span>
<span id="cb31-87"><a href="#cb31-87"></a>            .with_columns(</span>
<span id="cb31-88"><a href="#cb31-88"></a>                pl.when(pl.col(nb_tx_col) <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb31-89"><a href="#cb31-89"></a>                    .then(pl.col(nb_fraud_col) <span class="op">/</span> (pl.col(nb_tx_col)))</span>
<span id="cb31-90"><a href="#cb31-90"></a>                    .otherwise(<span class="fl">0.0</span>)</span>
<span id="cb31-91"><a href="#cb31-91"></a>                .alias(risk_col)</span>
<span id="cb31-92"><a href="#cb31-92"></a>            )</span>
<span id="cb31-93"><a href="#cb31-93"></a></span>
<span id="cb31-94"><a href="#cb31-94"></a>        )</span>
<span id="cb31-95"><a href="#cb31-95"></a></span>
<span id="cb31-96"><a href="#cb31-96"></a>        <span class="co"># Drop the intermediate fraud count column</span></span>
<span id="cb31-97"><a href="#cb31-97"></a>        result_df <span class="op">=</span> result_df.drop(nb_fraud_col)</span>
<span id="cb31-98"><a href="#cb31-98"></a></span>
<span id="cb31-99"><a href="#cb31-99"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="data-pipeline" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="data-pipeline"><span class="header-section-number">7.2</span> Data Pipeline</h2>
<p>The function applies each data transformation step in sequence using the <code>pipe</code> method from Polars. This allows for a clean and readable feature engineering pipeline.</p>
<div id="feature-engineering-pipeline-function" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="kw">def</span> polars_feature_pipeline(df: pl.DataFrame) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb32-2"><a href="#cb32-2"></a>    <span class="co">"""</span></span>
<span id="cb32-3"><a href="#cb32-3"></a><span class="co">    Apply all feature engineering steps in sequence using Polars pipe</span></span>
<span id="cb32-4"><a href="#cb32-4"></a><span class="co">    """</span></span>
<span id="cb32-5"><a href="#cb32-5"></a>    <span class="cf">return</span> (df.lazy()</span>
<span id="cb32-6"><a href="#cb32-6"></a>            .pipe(fe_is_weekend)</span>
<span id="cb32-7"><a href="#cb32-7"></a>            .pipe(fe_is_night)</span>
<span id="cb32-8"><a href="#cb32-8"></a>            .pipe(fe_customer_spending</span>
<span id="cb32-9"><a href="#cb32-9"></a>                ,window_sizes_in_days<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>])</span>
<span id="cb32-10"><a href="#cb32-10"></a>            .pipe(fe_terminal_risk</span>
<span id="cb32-11"><a href="#cb32-11"></a>                ,delay_period_days<span class="op">=</span><span class="dv">7</span></span>
<span id="cb32-12"><a href="#cb32-12"></a>                ,window_sizes_in_days<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>])</span>
<span id="cb32-13"><a href="#cb32-13"></a>            ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Apply the data pipeline to <code>df_fraud</code> and then split the data into training and calibration sets.</p>
<div id="apply-feature-engineering" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>df_fraud_ft <span class="op">=</span> polars_feature_pipeline(df_fraud).collect()</span>
<span id="cb33-2"><a href="#cb33-2"></a></span>
<span id="cb33-3"><a href="#cb33-3"></a>df_train_ft <span class="op">=</span> split_data(df_fraud_ft, <span class="bu">type</span><span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb33-4"><a href="#cb33-4"></a>df_tuning_ft <span class="op">=</span> split_data(df_fraud_ft, <span class="bu">type</span><span class="op">=</span><span class="st">"tuning"</span>)</span>
<span id="cb33-5"><a href="#cb33-5"></a>df_test_ft <span class="op">=</span> split_data(df_fraud_ft, <span class="bu">type</span><span class="op">=</span><span class="st">"test"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="eda-compare-df_train_ft-and-df_tuning_ft" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> EDA: Compare <code>df_train_ft</code> and <code>df_tuning_ft</code></h1>
<div id="eda-train-tuning-comparison-ft" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a>p_frac <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb34-2"><a href="#cb34-2"></a></span>
<span id="cb34-3"><a href="#cb34-3"></a>ft_train_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb34-4"><a href="#cb34-4"></a>            df_train_ft.sample(fraction<span class="op">=</span>p_frac, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb34-5"><a href="#cb34-5"></a>            title<span class="op">=</span><span class="st">"Train-FT"</span>,</span>
<span id="cb34-6"><a href="#cb34-6"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb34-7"><a href="#cb34-7"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb34-8"><a href="#cb34-8"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb34-9"><a href="#cb34-9"></a>            )</span>
<span id="cb34-10"><a href="#cb34-10"></a></span>
<span id="cb34-11"><a href="#cb34-11"></a>ft_tuning_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb34-12"><a href="#cb34-12"></a>            df_tuning_ft.sample(fraction<span class="op">=</span>p_frac<span class="op">*</span><span class="dv">2</span>, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb34-13"><a href="#cb34-13"></a>            title<span class="op">=</span><span class="st">"Tuning-FT"</span>,</span>
<span id="cb34-14"><a href="#cb34-14"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb34-15"><a href="#cb34-15"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb34-16"><a href="#cb34-16"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb34-17"><a href="#cb34-17"></a>            )</span>
<span id="cb34-18"><a href="#cb34-18"></a></span>
<span id="cb34-19"><a href="#cb34-19"></a>ft_compare_profile <span class="op">=</span> ft_train_data_profile.compare(ft_tuning_data_profile)</span>
<span id="cb34-20"><a href="#cb34-20"></a></span>
<span id="cb34-21"><a href="#cb34-21"></a>ft_compare_profile.to_file(<span class="st">"Lab04_eda_compare_train_tuning_ft.html"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="modeling-and-evaluation" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Modeling and Evaluation</h1>
<p>The section implements and compares different strategies for handling imbalanced datasets.</p>
<ul>
<li><strong>Do-Nothing Pipeline</strong>: No resampling, just feature engineering and model training.</li>
<li><strong>Class-Sensitive Evaluation Pipeline</strong>: No resampling, but uses PR-AUC (average precision)) to select the best model.</li>
<li><strong>Cost-Sensitive Learning Pipeline</strong>: Uses sample weights to handle class imbalance during model training.</li>
<li><strong>Undersampling Pipeline</strong>: Undersamples the majority class to balance the training set before model training.</li>
<li><strong>Oversampling Pipeline</strong>: Oversamples the minority class to balance the training set before model training.</li>
<li><strong>SMOTE Pipeline</strong>: Applies SMOTE to generate synthetic samples for the minority class before model training.</li>
<li><strong>Hybrid Pipeline</strong>: Combines oversampling and SMOTE to balance the training set before model training.</li>
</ul>
<p>The section evalutes each strategy by using the tuning set and test set.</p>
<p>If the predicted probabilities are not well calibrated, we will calibrate them using isotonic regression.</p>
<p>Finally, we will select the optimal decision threshold based on the tuning set and evaluate the F1-score on the test set.</p>
<section id="data" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="data"><span class="header-section-number">9.1</span> Data</h2>
<ul>
<li><p>The target label is <code>TX_FRAUD</code>, which indicates whether a transaction is fraudulent (1) or not (0).</p></li>
<li><p>The list of final features exclude features that are not relevant for modeling, such as IDs and datetime columns.</p></li>
</ul>
<div id="define-modeling-features" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>target_label <span class="op">=</span> <span class="st">"TX_FRAUD"</span></span>
<span id="cb35-2"><a href="#cb35-2"></a></span>
<span id="cb35-3"><a href="#cb35-3"></a>final_features <span class="op">=</span> [</span>
<span id="cb35-4"><a href="#cb35-4"></a>    <span class="st">'TX_AMOUNT'</span>,</span>
<span id="cb35-5"><a href="#cb35-5"></a>    <span class="st">'TX_DURING_WEEKEND'</span>, </span>
<span id="cb35-6"><a href="#cb35-6"></a>    <span class="st">'TX_DURING_NIGHT'</span>, </span>
<span id="cb35-7"><a href="#cb35-7"></a>    <span class="st">'CID_NB_TX_1DAY_WINDOW'</span>,</span>
<span id="cb35-8"><a href="#cb35-8"></a>    <span class="st">'CID_AVG_AMOUNT_1DAY_WINDOW'</span>, </span>
<span id="cb35-9"><a href="#cb35-9"></a>    <span class="st">'CID_NB_TX_7DAY_WINDOW'</span>,</span>
<span id="cb35-10"><a href="#cb35-10"></a>    <span class="st">'CID_AVG_AMOUNT_7DAY_WINDOW'</span>, </span>
<span id="cb35-11"><a href="#cb35-11"></a>    <span class="st">'CID_NB_TX_30DAY_WINDOW'</span>,</span>
<span id="cb35-12"><a href="#cb35-12"></a>    <span class="st">'CID_AVG_AMOUNT_30DAY_WINDOW'</span>, </span>
<span id="cb35-13"><a href="#cb35-13"></a>    <span class="st">'TID_NB_TX_1DAY_WINDOW'</span>,</span>
<span id="cb35-14"><a href="#cb35-14"></a>    <span class="st">'TID_RISK_1DAY_WINDOW'</span>, </span>
<span id="cb35-15"><a href="#cb35-15"></a>    <span class="st">'TID_NB_TX_7DAY_WINDOW'</span>,</span>
<span id="cb35-16"><a href="#cb35-16"></a>    <span class="st">'TID_RISK_7DAY_WINDOW'</span>, </span>
<span id="cb35-17"><a href="#cb35-17"></a>    <span class="st">'TID_NB_TX_30DAY_WINDOW'</span>,</span>
<span id="cb35-18"><a href="#cb35-18"></a>    <span class="st">'TID_RISK_30DAY_WINDOW'</span></span>
<span id="cb35-19"><a href="#cb35-19"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Setup features data frame and target series for training, tuning, and test sets. The data frames are converted to pandas data frames for compatibility with AutoGluon.</p>
<div id="1412e88d" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a>X_train <span class="op">=</span> df_train_ft[final_features].to_pandas()</span>
<span id="cb36-2"><a href="#cb36-2"></a>y_train <span class="op">=</span> df_train_ft[target_label].to_pandas()</span>
<span id="cb36-3"><a href="#cb36-3"></a></span>
<span id="cb36-4"><a href="#cb36-4"></a>X_tuning <span class="op">=</span> df_tuning_ft[final_features].to_pandas()</span>
<span id="cb36-5"><a href="#cb36-5"></a>y_tuning <span class="op">=</span> df_tuning_ft[target_label].to_pandas()</span>
<span id="cb36-6"><a href="#cb36-6"></a></span>
<span id="cb36-7"><a href="#cb36-7"></a>X_test <span class="op">=</span> df_test_ft[final_features].to_pandas()</span>
<span id="cb36-8"><a href="#cb36-8"></a>y_test <span class="op">=</span> df_test_ft[target_label].to_pandas()</span>
<span id="cb36-9"><a href="#cb36-9"></a></span>
<span id="cb36-10"><a href="#cb36-10"></a>comparison_results <span class="op">=</span> []</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="do-nothing-approach-1" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="do-nothing-approach-1"><span class="header-section-number">9.2</span> Do-Nothing Approach</h2>
<p><strong>Concept Recap:</strong> Train the model on the original, imbalanced training data. We will use <code>log_loss</code> as the <code>eval_metric</code> for AutoGluon to select the best base models.</p>
<p>Setup AutoGluon parameters.</p>
<div id="setup-autogluon-do-nothing" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a>strategy_name_1 <span class="op">=</span> <span class="st">"1. Do Nothing"</span></span>
<span id="cb37-2"><a href="#cb37-2"></a>model_folder_s1 <span class="op">=</span> <span class="st">"Lab04_ag_models_s1_do_nothing"</span></span>
<span id="cb37-3"><a href="#cb37-3"></a>remove_ag_folder(model_folder_s1)</span>
<span id="cb37-4"><a href="#cb37-4"></a></span>
<span id="cb37-5"><a href="#cb37-5"></a>predictor_args_s1 <span class="op">=</span> {</span>
<span id="cb37-6"><a href="#cb37-6"></a>    <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb37-7"><a href="#cb37-7"></a>    <span class="st">'eval_metric'</span>: <span class="st">'log_loss'</span>, </span>
<span id="cb37-8"><a href="#cb37-8"></a>    <span class="st">'path'</span>: model_folder_s1</span>
<span id="cb37-9"><a href="#cb37-9"></a>}</span>
<span id="cb37-10"><a href="#cb37-10"></a></span>
<span id="cb37-11"><a href="#cb37-11"></a>fit_args_s1 <span class="op">=</span> {<span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb37-12"><a href="#cb37-12"></a>            <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb37-13"><a href="#cb37-13"></a>            <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb37-14"><a href="#cb37-14"></a>            <span class="st">'time_limit'</span>: <span class="dv">300</span>}</span>
<span id="cb37-15"><a href="#cb37-15"></a></span>
<span id="cb37-16"><a href="#cb37-16"></a>ag_wrapper_s1 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb37-17"><a href="#cb37-17"></a>    label<span class="op">=</span>target_label,</span>
<span id="cb37-18"><a href="#cb37-18"></a>    predictor_args<span class="op">=</span>predictor_args_s1,</span>
<span id="cb37-19"><a href="#cb37-19"></a>    fit_args<span class="op">=</span>fit_args_s1</span>
<span id="cb37-20"><a href="#cb37-20"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Removed existing AutoGluon folder: Lab04_ag_models_s1_do_nothing</code></pre>
</div>
</div>
<p>Fit the model using AutoGluon.</p>
<div id="10e2d955" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a>ag_model_s1 <span class="op">=</span> ag_wrapper_s1.fit(X_train, y_train)</span>
<span id="cb39-2"><a href="#cb39-2"></a></span>
<span id="cb39-3"><a href="#cb39-3"></a>ag_model_s1.predictor.save()  <span class="co"># Save the predictor for later use</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1000]  valid_set's binary_logloss: 0.0108684</code></pre>
</div>
</div>
<p>Access the AutoGluon predictor object.</p>
<div id="access-autogluon-predictor-s1" class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>ag_model_s1_predictor <span class="op">=</span> ag_model_s1.predictor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check the leaderboard.</p>
<div id="cell-leaderboard-s1" class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>leaderboard_s1 <span class="op">=</span> ag_model_s1_predictor.leaderboard(</span>
<span id="cb42-2"><a href="#cb42-2"></a>    df_tuning_ft.to_pandas()</span>
<span id="cb42-3"><a href="#cb42-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>]</span>
<span id="cb42-4"><a href="#cb42-4"></a>)</span>
<span id="cb42-5"><a href="#cb42-5"></a>display(leaderboard_s1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="leaderboard-s1" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">average_precision</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>-0.010430</td>
<td>0.880632</td>
<td>0.881425</td>
<td>-0.009016</td>
<td>log_loss</td>
<td>2.108871</td>
<td>1.388612</td>
<td>276.839917</td>
<td>0.048105</td>
<td>0.006898</td>
<td>0.768027</td>
<td>2</td>
<td>True</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>CatBoost</td>
<td>-0.011330</td>
<td>0.869380</td>
<td>0.841952</td>
<td>-0.009862</td>
<td>log_loss</td>
<td>0.064108</td>
<td>0.034045</td>
<td>39.844661</td>
<td>0.064108</td>
<td>0.034045</td>
<td>39.844661</td>
<td>1</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>LightGBM</td>
<td>-0.011581</td>
<td>0.862658</td>
<td>0.834027</td>
<td>-0.010007</td>
<td>log_loss</td>
<td>0.163687</td>
<td>0.131139</td>
<td>2.310779</td>
<td>0.163687</td>
<td>0.131139</td>
<td>2.310779</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LightGBMXT</td>
<td>-0.012430</td>
<td>0.845855</td>
<td>0.828464</td>
<td>-0.010833</td>
<td>log_loss</td>
<td>2.576454</td>
<td>2.101967</td>
<td>18.560482</td>
<td>2.576454</td>
<td>2.101967</td>
<td>18.560482</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>RandomForestGini</td>
<td>-0.014090</td>
<td>0.881338</td>
<td>0.870914</td>
<td>-0.011785</td>
<td>log_loss</td>
<td>1.309292</td>
<td>0.899838</td>
<td>173.320902</td>
<td>1.309292</td>
<td>0.899838</td>
<td>173.320902</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>RandomForestEntr</td>
<td>-0.014952</td>
<td>0.878321</td>
<td>0.872187</td>
<td>-0.012692</td>
<td>log_loss</td>
<td>0.523679</td>
<td>0.316692</td>
<td>60.595549</td>
<td>0.523679</td>
<td>0.316692</td>
<td>60.595549</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Set the best model to CatBoost due to inference speed and performance.</p>
<div id="set-best-model-s1" class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a>ag_model_s1_predictor.set_model_best(<span class="st">'CatBoost'</span>)</span>
<span id="cb43-2"><a href="#cb43-2"></a></span>
<span id="cb43-3"><a href="#cb43-3"></a>ag_model_s1.predictor.save()  <span class="co"># Save the predictor for later use</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check feature importance.</p>
<div id="cell-feature-importance-s1" class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a>feature_importance_s1 <span class="op">=</span> ag_model_s1_predictor.feature_importance(</span>
<span id="cb44-2"><a href="#cb44-2"></a>    df_tuning_ft.to_pandas(),</span>
<span id="cb44-3"><a href="#cb44-3"></a>    subsample_size <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb44-4"><a href="#cb44-4"></a>    num_shuffle_sets <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb44-5"><a href="#cb44-5"></a>)</span>
<span id="cb44-6"><a href="#cb44-6"></a></span>
<span id="cb44-7"><a href="#cb44-7"></a>display(feature_importance_s1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="feature-importance-s1" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">importance</th>
<th data-quarto-table-cell-role="th">stddev</th>
<th data-quarto-table-cell-role="th">p_value</th>
<th data-quarto-table-cell-role="th">n</th>
<th data-quarto-table-cell-role="th">p99_high</th>
<th data-quarto-table-cell-role="th">p99_low</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_30DAY_WINDOW</td>
<td>1.968713</td>
<td>0.010351</td>
<td>9.170299e-11</td>
<td>5</td>
<td>1.990026e+00</td>
<td>1.947400e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TX_AMOUNT</td>
<td>0.883292</td>
<td>0.006719</td>
<td>4.016930e-10</td>
<td>5</td>
<td>8.971256e-01</td>
<td>8.694574e-01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_7DAY_WINDOW</td>
<td>0.523234</td>
<td>0.002686</td>
<td>8.329464e-11</td>
<td>5</td>
<td>5.287643e-01</td>
<td>5.177044e-01</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_1DAY_WINDOW</td>
<td>0.073819</td>
<td>0.001349</td>
<td>1.339408e-08</td>
<td>5</td>
<td>7.659775e-02</td>
<td>7.104075e-02</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_1DAY_WINDOW</td>
<td>0.054915</td>
<td>0.000597</td>
<td>1.672527e-09</td>
<td>5</td>
<td>5.614387e-02</td>
<td>5.368663e-02</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_7DAY_WINDOW</td>
<td>0.004719</td>
<td>0.000063</td>
<td>3.755340e-09</td>
<td>5</td>
<td>4.847862e-03</td>
<td>4.589399e-03</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_NB_TX_1DAY_WINDOW</td>
<td>0.001477</td>
<td>0.000069</td>
<td>5.726044e-07</td>
<td>5</td>
<td>1.619564e-03</td>
<td>1.335026e-03</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CID_NB_TX_7DAY_WINDOW</td>
<td>0.000256</td>
<td>0.000040</td>
<td>6.740312e-05</td>
<td>5</td>
<td>3.382865e-04</td>
<td>1.744581e-04</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_NB_TX_1DAY_WINDOW</td>
<td>0.000252</td>
<td>0.000026</td>
<td>1.369387e-05</td>
<td>5</td>
<td>3.058519e-04</td>
<td>1.982000e-04</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_30DAY_WINDOW</td>
<td>0.000043</td>
<td>0.000009</td>
<td>1.748498e-04</td>
<td>5</td>
<td>6.085417e-05</td>
<td>2.561775e-05</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_NB_TX_30DAY_WINDOW</td>
<td>0.000028</td>
<td>0.000013</td>
<td>4.546765e-03</td>
<td>5</td>
<td>5.529212e-05</td>
<td>7.550090e-07</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_NB_TX_30DAY_WINDOW</td>
<td>0.000019</td>
<td>0.000017</td>
<td>3.248069e-02</td>
<td>5</td>
<td>5.382029e-05</td>
<td>-1.568909e-05</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_NB_TX_7DAY_WINDOW</td>
<td>0.000011</td>
<td>0.000009</td>
<td>2.502339e-02</td>
<td>5</td>
<td>2.843378e-05</td>
<td>-7.045476e-06</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TX_DURING_NIGHT</td>
<td>0.000006</td>
<td>0.000013</td>
<td>1.600493e-01</td>
<td>5</td>
<td>3.242982e-05</td>
<td>-1.961063e-05</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TX_DURING_WEEKEND</td>
<td>-0.000005</td>
<td>0.000002</td>
<td>9.954568e-01</td>
<td>5</td>
<td>-1.375261e-07</td>
<td>-9.988515e-06</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Check probability calibration using the tuning set.</p>
<div id="calibration-s1" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb45-2"><a href="#cb45-2"></a></span>
<span id="cb45-3"><a href="#cb45-3"></a>pre_cal_disp_s1 <span class="op">=</span> CalibrationDisplay.from_estimator(</span>
<span id="cb45-4"><a href="#cb45-4"></a>        estimator <span class="op">=</span> ag_model_s1,</span>
<span id="cb45-5"><a href="#cb45-5"></a>        X <span class="op">=</span> X_tuning,</span>
<span id="cb45-6"><a href="#cb45-6"></a>        y <span class="op">=</span> y_tuning,</span>
<span id="cb45-7"><a href="#cb45-7"></a>        n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb45-8"><a href="#cb45-8"></a>        name <span class="op">=</span> <span class="st">'Pre-Calib Curve: Do Nothing Strategy'</span>,</span>
<span id="cb45-9"><a href="#cb45-9"></a>        color <span class="op">=</span> <span class="st">'orange'</span></span>
<span id="cb45-10"><a href="#cb45-10"></a>    )</span>
<span id="cb45-11"><a href="#cb45-11"></a></span>
<span id="cb45-12"><a href="#cb45-12"></a>pre_cal_disp_s1.ax_.set_title(<span class="st">"Calibration Plot (Tuning Set)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="calibration-s1-1" class="cell-output cell-output-display" data-execution_count="233">
<pre><code>Text(0.5, 1.0, 'Calibration Plot (Tuning Set)')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/calibration-s1-output-2.png" id="calibration-s1-2" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Fit a calibration model (isotonic regression) to the predicted probabilities from the tuning set. After fitting, we can no longer use the tuning set for calibration evaluation due to potential overfitting on the tuning set.</p>
<div id="86533688" class="cell" data-execution_count="36">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1"></a>cal_model_s1 <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb47-2"><a href="#cb47-2"></a>    estimator <span class="op">=</span> ag_model_s1,</span>
<span id="cb47-3"><a href="#cb47-3"></a>    method<span class="op">=</span><span class="st">'isotonic'</span>,</span>
<span id="cb47-4"><a href="#cb47-4"></a>    cv<span class="op">=</span><span class="st">"prefit"</span> <span class="co"># Use the fitted model from ag_model</span></span>
<span id="cb47-5"><a href="#cb47-5"></a>)</span>
<span id="cb47-6"><a href="#cb47-6"></a></span>
<span id="cb47-7"><a href="#cb47-7"></a>global_set_seed()</span>
<span id="cb47-8"><a href="#cb47-8"></a></span>
<span id="cb47-9"><a href="#cb47-9"></a>cal_model_s1.fit(X <span class="op">=</span> X_tuning,</span>
<span id="cb47-10"><a href="#cb47-10"></a>            y <span class="op">=</span> y_tuning)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="234">
<style>#sk-container-id-10 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-10 {
  color: var(--sklearn-color-text);
}

#sk-container-id-10 pre {
  padding: 0;
}

#sk-container-id-10 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-10 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-10 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-10 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-10 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-10 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-10 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-10 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-10 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-10 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-10 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-10 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-10 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-10 div.sk-label label.sk-toggleable__label,
#sk-container-id-10 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-10 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-10 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-10 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-10 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-10 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-10 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-10 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-10 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-10" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CalibratedClassifierCV(cv='prefit',
                       estimator=AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                                                   'holdout_frac': 0.2,
                                                                   'presets': 'medium_quality',
                                                                   'time_limit': 300},
                                                         label='TX_FRAUD',
                                                         predictor_args={'eval_metric': 'log_loss',
                                                                         'path': 'Lab04_ag_models_s1_do_nothing',
                                                                         'problem_type': 'binary'}),
                       method='isotonic')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-28" type="checkbox"><label for="sk-estimator-id-28" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;CalibratedClassifierCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.calibration.CalibratedClassifierCV.html">?<span>Documentation for CalibratedClassifierCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>CalibratedClassifierCV(cv='prefit',
                       estimator=AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                                                   'holdout_frac': 0.2,
                                                                   'presets': 'medium_quality',
                                                                   'time_limit': 300},
                                                         label='TX_FRAUD',
                                                         predictor_args={'eval_metric': 'log_loss',
                                                                         'path': 'Lab04_ag_models_s1_do_nothing',
                                                                         'problem_type': 'binary'}),
                       method='isotonic')</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-29" type="checkbox"><label for="sk-estimator-id-29" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">estimator: AutoGluonSklearnWrapper</label><div class="sk-toggleable__content fitted"><pre>AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                  'holdout_frac': 0.2,
                                  'presets': 'medium_quality',
                                  'time_limit': 300},
                        label='TX_FRAUD',
                        predictor_args={'eval_metric': 'log_loss',
                                        'path': 'Lab04_ag_models_s1_do_nothing',
                                        'problem_type': 'binary'})</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-30" type="checkbox"><label for="sk-estimator-id-30" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">AutoGluonSklearnWrapper</label><div class="sk-toggleable__content fitted"><pre>AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                  'holdout_frac': 0.2,
                                  'presets': 'medium_quality',
                                  'time_limit': 300},
                        label='TX_FRAUD',
                        predictor_args={'eval_metric': 'log_loss',
                                        'path': 'Lab04_ag_models_s1_do_nothing',
                                        'problem_type': 'binary'})</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<p>Since the isotonic regression model was fitted on the tuning set, we can no longer use the tuning set for calibration evaluation. We will use the test set for calibration evaluation.</p>
<div id="cell-calibration-s1-test" class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb48-2"><a href="#cb48-2"></a></span>
<span id="cb48-3"><a href="#cb48-3"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb48-4"><a href="#cb48-4"></a></span>
<span id="cb48-5"><a href="#cb48-5"></a><span class="cf">for</span> estimator, name, color <span class="kw">in</span> [(ag_model_s1, <span class="st">'Uncalib_CatBoost'</span>, <span class="st">'orange'</span>),</span>
<span id="cb48-6"><a href="#cb48-6"></a>          (cal_model_s1, <span class="st">'Calib_CatBoost'</span>, <span class="st">'blue'</span>)]:</span>
<span id="cb48-7"><a href="#cb48-7"></a></span>
<span id="cb48-8"><a href="#cb48-8"></a>  CalibrationDisplay.from_estimator(</span>
<span id="cb48-9"><a href="#cb48-9"></a>      estimator <span class="op">=</span> estimator,</span>
<span id="cb48-10"><a href="#cb48-10"></a>      X <span class="op">=</span> X_test,</span>
<span id="cb48-11"><a href="#cb48-11"></a>      y <span class="op">=</span> y_test,</span>
<span id="cb48-12"><a href="#cb48-12"></a>      n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb48-13"><a href="#cb48-13"></a>      name <span class="op">=</span> name,</span>
<span id="cb48-14"><a href="#cb48-14"></a>      color <span class="op">=</span> color,</span>
<span id="cb48-15"><a href="#cb48-15"></a>      ax <span class="op">=</span> ax</span>
<span id="cb48-16"><a href="#cb48-16"></a>    )</span>
<span id="cb48-17"><a href="#cb48-17"></a>    </span>
<span id="cb48-18"><a href="#cb48-18"></a>ax.set_title(<span class="st">"Calibration Plot (Test Set)"</span>)</span>
<span id="cb48-19"><a href="#cb48-19"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/calibration-s1-test-output-1.png" id="calibration-s1-test" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The uncalibrated CatBoost model shows <strong>better</strong> calibration than the calibrated model. This is likely due to the isotonic regression model overfitting to the tuning set. We will use the uncalibrated model to set the optimal decision threshold.</p>
<p>Evalulate the original decision threshold of 0.5 on the test set.</p>
<div id="cell-evaluate-default-threshold-s1" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1"></a>leaderboard_s1_default <span class="op">=</span> ag_model_s1_predictor.leaderboard(</span>
<span id="cb49-2"><a href="#cb49-2"></a>    df_test_ft.to_pandas()</span>
<span id="cb49-3"><a href="#cb49-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb49-4"><a href="#cb49-4"></a>)</span>
<span id="cb49-5"><a href="#cb49-5"></a></span>
<span id="cb49-6"><a href="#cb49-6"></a>display(leaderboard_s1_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="evaluate-default-threshold-s1" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>-0.009853</td>
<td>0.890538</td>
<td>-0.009016</td>
<td>log_loss</td>
<td>2.023908</td>
<td>1.388612</td>
<td>276.839917</td>
<td>0.046064</td>
<td>0.006898</td>
<td>0.768027</td>
<td>2</td>
<td>True</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>CatBoost</td>
<td>-0.010596</td>
<td>0.851922</td>
<td>-0.009862</td>
<td>log_loss</td>
<td>0.071707</td>
<td>0.034045</td>
<td>39.844661</td>
<td>0.071707</td>
<td>0.034045</td>
<td>39.844661</td>
<td>1</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>LightGBM</td>
<td>-0.010889</td>
<td>0.848447</td>
<td>-0.010007</td>
<td>log_loss</td>
<td>0.164192</td>
<td>0.131139</td>
<td>2.310779</td>
<td>0.164192</td>
<td>0.131139</td>
<td>2.310779</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LightGBMXT</td>
<td>-0.011797</td>
<td>0.834984</td>
<td>-0.010833</td>
<td>log_loss</td>
<td>2.650825</td>
<td>2.101967</td>
<td>18.560482</td>
<td>2.650825</td>
<td>2.101967</td>
<td>18.560482</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>RandomForestGini</td>
<td>-0.013570</td>
<td>0.879566</td>
<td>-0.011785</td>
<td>log_loss</td>
<td>1.282990</td>
<td>0.899838</td>
<td>173.320902</td>
<td>1.282990</td>
<td>0.899838</td>
<td>173.320902</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>RandomForestEntr</td>
<td>-0.014303</td>
<td>0.880183</td>
<td>-0.012692</td>
<td>log_loss</td>
<td>0.458956</td>
<td>0.316692</td>
<td>60.595549</td>
<td>0.458956</td>
<td>0.316692</td>
<td>60.595549</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Since the tuning set is no longer being used for probability calibration, we will use it to find the optimal decision threshold that maximizes the F1-score.</p>
<div id="threshold-tuning-s1" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>best_threshold_s1 <span class="op">=</span> (ag_model_s1_predictor</span>
<span id="cb50-2"><a href="#cb50-2"></a>                .calibrate_decision_threshold(</span>
<span id="cb50-3"><a href="#cb50-3"></a>                data <span class="op">=</span> df_tuning_ft.to_pandas(),</span>
<span id="cb50-4"><a href="#cb50-4"></a>                metric <span class="op">=</span> <span class="st">'f1'</span>,</span>
<span id="cb50-5"><a href="#cb50-5"></a>                decision_thresholds <span class="op">=</span> <span class="dv">200</span>)</span>
<span id="cb50-6"><a href="#cb50-6"></a>                )</span>
<span id="cb50-7"><a href="#cb50-7"></a></span>
<span id="cb50-8"><a href="#cb50-8"></a>ag_model_s1_predictor.set_decision_threshold(best_threshold_s1)</span>
<span id="cb50-9"><a href="#cb50-9"></a></span>
<span id="cb50-10"><a href="#cb50-10"></a>ag_model_s1_predictor.save()  <span class="co"># Save the predictor with the new threshold</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Use the test set to evaluate the effectivness of the decision threshold.</p>
<div id="cell-evaluate-threshold-s1" class="cell" data-execution_count="40">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a>leaderboard_s1_optimized <span class="op">=</span> ag_model_s1_predictor.leaderboard(</span>
<span id="cb51-2"><a href="#cb51-2"></a>    df_test_ft.to_pandas()</span>
<span id="cb51-3"><a href="#cb51-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb51-4"><a href="#cb51-4"></a>)</span>
<span id="cb51-5"><a href="#cb51-5"></a></span>
<span id="cb51-6"><a href="#cb51-6"></a>display(leaderboard_s1_optimized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="evaluate-threshold-s1" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>-0.009853</td>
<td>0.891814</td>
<td>-0.009016</td>
<td>log_loss</td>
<td>2.120353</td>
<td>1.388612</td>
<td>276.839917</td>
<td>0.046662</td>
<td>0.006898</td>
<td>0.768027</td>
<td>2</td>
<td>True</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>CatBoost</td>
<td>-0.010596</td>
<td>0.852398</td>
<td>-0.009862</td>
<td>log_loss</td>
<td>0.070066</td>
<td>0.034045</td>
<td>39.844661</td>
<td>0.070066</td>
<td>0.034045</td>
<td>39.844661</td>
<td>1</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>LightGBM</td>
<td>-0.010889</td>
<td>0.848560</td>
<td>-0.010007</td>
<td>log_loss</td>
<td>0.176260</td>
<td>0.131139</td>
<td>2.310779</td>
<td>0.176260</td>
<td>0.131139</td>
<td>2.310779</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LightGBMXT</td>
<td>-0.011797</td>
<td>0.837006</td>
<td>-0.010833</td>
<td>log_loss</td>
<td>2.693791</td>
<td>2.101967</td>
<td>18.560482</td>
<td>2.693791</td>
<td>2.101967</td>
<td>18.560482</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>RandomForestGini</td>
<td>-0.013570</td>
<td>0.884607</td>
<td>-0.011785</td>
<td>log_loss</td>
<td>1.333762</td>
<td>0.899838</td>
<td>173.320902</td>
<td>1.333762</td>
<td>0.899838</td>
<td>173.320902</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>RandomForestEntr</td>
<td>-0.014303</td>
<td>0.883316</td>
<td>-0.012692</td>
<td>log_loss</td>
<td>0.493604</td>
<td>0.316692</td>
<td>60.595549</td>
<td>0.493604</td>
<td>0.316692</td>
<td>60.595549</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Tuning the decision threshold does not appear to substantially improve the F1-score on the test set. The default threshold of 0.5 yields a similar F1-score.</p>
</section>
<section id="class-sensitive-evaluation-approach-1" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="class-sensitive-evaluation-approach-1"><span class="header-section-number">9.3</span> Class-Sensitive Evaluation Approach</h2>
<p><strong>Concept Recap:</strong> Train the model on the original, imbalanced training data. We will use <code>average_precision</code> (aka PR-AUC) as the <code>eval_metric</code> for AutoGluon to select the best base models.</p>
<p>Setup AutoGluon parameters.</p>
<div id="setup-autogluon-class-sensitive-evaluation" class="cell" data-execution_count="41">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a>strategy_name_2 <span class="op">=</span> <span class="st">"2. Class Sensitive Evaluation"</span></span>
<span id="cb52-2"><a href="#cb52-2"></a>model_folder_s2 <span class="op">=</span> <span class="st">"Lab04_ag_models_s2_class_sensitive"</span></span>
<span id="cb52-3"><a href="#cb52-3"></a>remove_ag_folder(model_folder_s2)</span>
<span id="cb52-4"><a href="#cb52-4"></a></span>
<span id="cb52-5"><a href="#cb52-5"></a>predictor_args_s2 <span class="op">=</span> {</span>
<span id="cb52-6"><a href="#cb52-6"></a>    <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb52-7"><a href="#cb52-7"></a>    <span class="st">'eval_metric'</span>: <span class="st">'average_precision'</span>, </span>
<span id="cb52-8"><a href="#cb52-8"></a>    <span class="st">'path'</span>: model_folder_s2</span>
<span id="cb52-9"><a href="#cb52-9"></a>}</span>
<span id="cb52-10"><a href="#cb52-10"></a></span>
<span id="cb52-11"><a href="#cb52-11"></a>fit_args_s2 <span class="op">=</span> {<span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb52-12"><a href="#cb52-12"></a>            <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb52-13"><a href="#cb52-13"></a>            <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb52-14"><a href="#cb52-14"></a>            <span class="st">'time_limit'</span>: <span class="dv">300</span>}</span>
<span id="cb52-15"><a href="#cb52-15"></a></span>
<span id="cb52-16"><a href="#cb52-16"></a>ag_wrapper_s2 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb52-17"><a href="#cb52-17"></a>    label<span class="op">=</span>target_label,</span>
<span id="cb52-18"><a href="#cb52-18"></a>    predictor_args<span class="op">=</span>predictor_args_s2,</span>
<span id="cb52-19"><a href="#cb52-19"></a>    fit_args<span class="op">=</span>fit_args_s2</span>
<span id="cb52-20"><a href="#cb52-20"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Removed existing AutoGluon folder: Lab04_ag_models_s2_class_sensitive</code></pre>
</div>
</div>
<p>Fit the model using AutoGluon.</p>
<div id="fit-autogluon-class-sensitive-evaluation" class="cell" data-execution_count="42">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a>ag_model_s2 <span class="op">=</span> ag_wrapper_s2.fit(X_train, y_train)</span>
<span id="cb54-2"><a href="#cb54-2"></a></span>
<span id="cb54-3"><a href="#cb54-3"></a>ag_model_s2.predictor.save()  <span class="co"># Save the predictor for later use</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1000]  valid_set's binary_logloss: 0.0108684   valid_set's average_precision: 0.854774</code></pre>
</div>
</div>
<p>Access the AutoGluon predictor object.</p>
<div id="access-autogluon-predictor-s2" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1"></a>ag_model_s2_predictor <span class="op">=</span> ag_model_s2.predictor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check the leaderboard.</p>
<div id="cell-leaderboard-s2" class="cell" data-execution_count="44">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a>leaderboard_s2 <span class="op">=</span> ag_model_s2_predictor.leaderboard(</span>
<span id="cb57-2"><a href="#cb57-2"></a>    df_tuning_ft.to_pandas()</span>
<span id="cb57-3"><a href="#cb57-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>]</span>
<span id="cb57-4"><a href="#cb57-4"></a>)</span>
<span id="cb57-5"><a href="#cb57-5"></a>display(leaderboard_s2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="leaderboard-s2" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">average_precision</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>0.884749</td>
<td>0.884749</td>
<td>0.871848</td>
<td>0.892473</td>
<td>average_precision</td>
<td>1.235663</td>
<td>0.832053</td>
<td>145.719991</td>
<td>0.012569</td>
<td>0.027095</td>
<td>3.872444</td>
<td>2</td>
<td>True</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>RandomForestGini</td>
<td>0.879210</td>
<td>0.879210</td>
<td>0.870861</td>
<td>0.887466</td>
<td>average_precision</td>
<td>0.752131</td>
<td>0.483108</td>
<td>99.301560</td>
<td>0.752131</td>
<td>0.483108</td>
<td>99.301560</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>RandomForestEntr</td>
<td>0.872974</td>
<td>0.872974</td>
<td>0.870968</td>
<td>0.881989</td>
<td>average_precision</td>
<td>0.279671</td>
<td>0.191715</td>
<td>34.407330</td>
<td>0.279671</td>
<td>0.191715</td>
<td>34.407330</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>CatBoost</td>
<td>0.866402</td>
<td>0.866402</td>
<td>0.838466</td>
<td>0.874630</td>
<td>average_precision</td>
<td>0.049620</td>
<td>0.019969</td>
<td>24.265952</td>
<td>0.049620</td>
<td>0.019969</td>
<td>24.265952</td>
<td>1</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>LightGBM</td>
<td>0.862658</td>
<td>0.862658</td>
<td>0.834027</td>
<td>0.874268</td>
<td>average_precision</td>
<td>0.191293</td>
<td>0.130134</td>
<td>8.138657</td>
<td>0.191293</td>
<td>0.130134</td>
<td>8.138657</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>LightGBMXT</td>
<td>0.845749</td>
<td>0.845749</td>
<td>0.829583</td>
<td>0.855191</td>
<td>average_precision</td>
<td>2.973263</td>
<td>2.274780</td>
<td>128.826769</td>
<td>2.973263</td>
<td>2.274780</td>
<td>128.826769</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Set the best model to CatBoost due to inference speed and performance.</p>
<div id="set-best-model-s2" class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1"></a>ag_model_s2_predictor.set_model_best(<span class="st">'CatBoost'</span>)</span>
<span id="cb58-2"><a href="#cb58-2"></a></span>
<span id="cb58-3"><a href="#cb58-3"></a>ag_model_s2.predictor.save()  <span class="co"># Save the predictor for later use</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check feature importance.</p>
<div id="cell-feature-importance-s2" class="cell" data-execution_count="46">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a>feature_importance_s2 <span class="op">=</span> ag_model_s2_predictor.feature_importance(</span>
<span id="cb59-2"><a href="#cb59-2"></a>    df_tuning_ft.to_pandas(),</span>
<span id="cb59-3"><a href="#cb59-3"></a>    subsample_size <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb59-4"><a href="#cb59-4"></a>    num_shuffle_sets <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb59-5"><a href="#cb59-5"></a>)</span>
<span id="cb59-6"><a href="#cb59-6"></a></span>
<span id="cb59-7"><a href="#cb59-7"></a>display(feature_importance_s2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="feature-importance-s2" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">importance</th>
<th data-quarto-table-cell-role="th">stddev</th>
<th data-quarto-table-cell-role="th">p_value</th>
<th data-quarto-table-cell-role="th">n</th>
<th data-quarto-table-cell-role="th">p99_high</th>
<th data-quarto-table-cell-role="th">p99_low</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_30DAY_WINDOW</td>
<td>0.837139</td>
<td>0.000320</td>
<td>2.560153e-15</td>
<td>5</td>
<td>0.837798</td>
<td>0.836480</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TX_AMOUNT</td>
<td>0.833312</td>
<td>0.000411</td>
<td>7.110202e-15</td>
<td>5</td>
<td>0.834159</td>
<td>0.832466</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_RISK_1DAY_WINDOW</td>
<td>0.747344</td>
<td>0.002706</td>
<td>2.061281e-11</td>
<td>5</td>
<td>0.752915</td>
<td>0.741773</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_7DAY_WINDOW</td>
<td>0.638442</td>
<td>0.003790</td>
<td>1.490870e-10</td>
<td>5</td>
<td>0.646247</td>
<td>0.630638</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_1DAY_WINDOW</td>
<td>0.186134</td>
<td>0.004049</td>
<td>2.684877e-08</td>
<td>5</td>
<td>0.194471</td>
<td>0.177798</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_7DAY_WINDOW</td>
<td>0.059513</td>
<td>0.001201</td>
<td>1.990079e-08</td>
<td>5</td>
<td>0.061986</td>
<td>0.057040</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_NB_TX_1DAY_WINDOW</td>
<td>0.036579</td>
<td>0.001392</td>
<td>2.513723e-07</td>
<td>5</td>
<td>0.039446</td>
<td>0.033713</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CID_NB_TX_7DAY_WINDOW</td>
<td>0.004390</td>
<td>0.000684</td>
<td>6.832384e-05</td>
<td>5</td>
<td>0.005797</td>
<td>0.002982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_NB_TX_1DAY_WINDOW</td>
<td>0.003510</td>
<td>0.000558</td>
<td>7.402898e-05</td>
<td>5</td>
<td>0.004659</td>
<td>0.002362</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_30DAY_WINDOW</td>
<td>0.001208</td>
<td>0.000257</td>
<td>2.304034e-04</td>
<td>5</td>
<td>0.001736</td>
<td>0.000679</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_NB_TX_30DAY_WINDOW</td>
<td>0.000931</td>
<td>0.000491</td>
<td>6.627164e-03</td>
<td>5</td>
<td>0.001942</td>
<td>-0.000080</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TX_DURING_NIGHT</td>
<td>0.000392</td>
<td>0.000347</td>
<td>3.238100e-02</td>
<td>5</td>
<td>0.001106</td>
<td>-0.000322</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_NB_TX_30DAY_WINDOW</td>
<td>0.000377</td>
<td>0.000410</td>
<td>5.461492e-02</td>
<td>5</td>
<td>0.001221</td>
<td>-0.000468</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_NB_TX_7DAY_WINDOW</td>
<td>0.000233</td>
<td>0.000204</td>
<td>3.164443e-02</td>
<td>5</td>
<td>0.000653</td>
<td>-0.000187</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TX_DURING_WEEKEND</td>
<td>-0.000009</td>
<td>0.000068</td>
<td>6.044558e-01</td>
<td>5</td>
<td>0.000132</td>
<td>-0.000149</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Check probability calibration using the tuning set.</p>
<div id="calibration-s2" class="cell" data-execution_count="47">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb60-2"><a href="#cb60-2"></a></span>
<span id="cb60-3"><a href="#cb60-3"></a>pre_cal_disp_s2 <span class="op">=</span> CalibrationDisplay.from_estimator(</span>
<span id="cb60-4"><a href="#cb60-4"></a>        estimator <span class="op">=</span> ag_model_s2,</span>
<span id="cb60-5"><a href="#cb60-5"></a>        X <span class="op">=</span> X_tuning,</span>
<span id="cb60-6"><a href="#cb60-6"></a>        y <span class="op">=</span> y_tuning,</span>
<span id="cb60-7"><a href="#cb60-7"></a>        n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb60-8"><a href="#cb60-8"></a>        name <span class="op">=</span> <span class="st">'Pre-Calib Curve: Do Nothing Strategy'</span>,</span>
<span id="cb60-9"><a href="#cb60-9"></a>        color <span class="op">=</span> <span class="st">'orange'</span></span>
<span id="cb60-10"><a href="#cb60-10"></a>    )</span>
<span id="cb60-11"><a href="#cb60-11"></a></span>
<span id="cb60-12"><a href="#cb60-12"></a>pre_cal_disp_s2.ax_.set_title(<span class="st">"Calibration Plot (Tuning Set)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="calibration-s2-1" class="cell-output cell-output-display" data-execution_count="245">
<pre><code>Text(0.5, 1.0, 'Calibration Plot (Tuning Set)')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/calibration-s2-output-2.png" id="calibration-s2-2" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Fit a calibration model (isotonic regression) to the predicted probabilities from the tuning set. After fitting, we can no longer use the tuning set for calibration evaluation due to potential overfitting on the tuning set.</p>
<div id="253e7c47" class="cell" data-execution_count="48">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1"></a>cal_model_s2 <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb62-2"><a href="#cb62-2"></a>    estimator <span class="op">=</span> ag_model_s2,</span>
<span id="cb62-3"><a href="#cb62-3"></a>    method<span class="op">=</span><span class="st">'isotonic'</span>,</span>
<span id="cb62-4"><a href="#cb62-4"></a>    cv<span class="op">=</span><span class="st">"prefit"</span> <span class="co"># Use the fitted model from ag_model</span></span>
<span id="cb62-5"><a href="#cb62-5"></a>)</span>
<span id="cb62-6"><a href="#cb62-6"></a></span>
<span id="cb62-7"><a href="#cb62-7"></a>global_set_seed()</span>
<span id="cb62-8"><a href="#cb62-8"></a></span>
<span id="cb62-9"><a href="#cb62-9"></a>cal_model_s2.fit(X <span class="op">=</span> X_tuning,</span>
<span id="cb62-10"><a href="#cb62-10"></a>            y <span class="op">=</span> y_tuning)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="246">
<style>#sk-container-id-11 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-11 {
  color: var(--sklearn-color-text);
}

#sk-container-id-11 pre {
  padding: 0;
}

#sk-container-id-11 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-11 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-11 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-11 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-11 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-11 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-11 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-11 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-11 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-11 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-11 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-11 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-11 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-11 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-11 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-11 div.sk-label label.sk-toggleable__label,
#sk-container-id-11 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-11 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-11 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-11 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-11 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-11 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-11 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-11 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-11 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-11" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CalibratedClassifierCV(cv='prefit',
                       estimator=AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                                                   'holdout_frac': 0.2,
                                                                   'presets': 'medium_quality',
                                                                   'time_limit': 300},
                                                         label='TX_FRAUD',
                                                         predictor_args={'eval_metric': 'average_precision',
                                                                         'path': 'Lab04_ag_models_s2_class_sensitive',
                                                                         'problem_type': 'binary'}),
                       method='isotonic')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-31" type="checkbox"><label for="sk-estimator-id-31" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;CalibratedClassifierCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.calibration.CalibratedClassifierCV.html">?<span>Documentation for CalibratedClassifierCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>CalibratedClassifierCV(cv='prefit',
                       estimator=AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                                                   'holdout_frac': 0.2,
                                                                   'presets': 'medium_quality',
                                                                   'time_limit': 300},
                                                         label='TX_FRAUD',
                                                         predictor_args={'eval_metric': 'average_precision',
                                                                         'path': 'Lab04_ag_models_s2_class_sensitive',
                                                                         'problem_type': 'binary'}),
                       method='isotonic')</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-32" type="checkbox"><label for="sk-estimator-id-32" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">estimator: AutoGluonSklearnWrapper</label><div class="sk-toggleable__content fitted"><pre>AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                  'holdout_frac': 0.2,
                                  'presets': 'medium_quality',
                                  'time_limit': 300},
                        label='TX_FRAUD',
                        predictor_args={'eval_metric': 'average_precision',
                                        'path': 'Lab04_ag_models_s2_class_sensitive',
                                        'problem_type': 'binary'})</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-33" type="checkbox"><label for="sk-estimator-id-33" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">AutoGluonSklearnWrapper</label><div class="sk-toggleable__content fitted"><pre>AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                  'holdout_frac': 0.2,
                                  'presets': 'medium_quality',
                                  'time_limit': 300},
                        label='TX_FRAUD',
                        predictor_args={'eval_metric': 'average_precision',
                                        'path': 'Lab04_ag_models_s2_class_sensitive',
                                        'problem_type': 'binary'})</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<p>Since the isotonic regression model was fitted on the tuning set, we can no longer use the tuning set for calibration evaluation. We will use the test set for calibration evaluation.</p>
<div id="cell-calibration-s2-test" class="cell" data-execution_count="49">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb63-2"><a href="#cb63-2"></a></span>
<span id="cb63-3"><a href="#cb63-3"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb63-4"><a href="#cb63-4"></a></span>
<span id="cb63-5"><a href="#cb63-5"></a><span class="cf">for</span> estimator, name, color <span class="kw">in</span> [(ag_model_s2, <span class="st">'Uncalib_CatBoost'</span>, <span class="st">'orange'</span>),</span>
<span id="cb63-6"><a href="#cb63-6"></a>          (cal_model_s2, <span class="st">'Calib_CatBoost'</span>, <span class="st">'blue'</span>)]:</span>
<span id="cb63-7"><a href="#cb63-7"></a></span>
<span id="cb63-8"><a href="#cb63-8"></a>  CalibrationDisplay.from_estimator(</span>
<span id="cb63-9"><a href="#cb63-9"></a>      estimator <span class="op">=</span> estimator,</span>
<span id="cb63-10"><a href="#cb63-10"></a>      X <span class="op">=</span> X_test,</span>
<span id="cb63-11"><a href="#cb63-11"></a>      y <span class="op">=</span> y_test,</span>
<span id="cb63-12"><a href="#cb63-12"></a>      n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb63-13"><a href="#cb63-13"></a>      name <span class="op">=</span> name,</span>
<span id="cb63-14"><a href="#cb63-14"></a>      color <span class="op">=</span> color,</span>
<span id="cb63-15"><a href="#cb63-15"></a>      ax <span class="op">=</span> ax</span>
<span id="cb63-16"><a href="#cb63-16"></a>    )</span>
<span id="cb63-17"><a href="#cb63-17"></a>    </span>
<span id="cb63-18"><a href="#cb63-18"></a>ax.set_title(<span class="st">"Calibration Plot (Test Set)"</span>)</span>
<span id="cb63-19"><a href="#cb63-19"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/calibration-s2-test-output-1.png" id="calibration-s2-test" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The uncalibrated CatBoost model shows <strong>better</strong> calibration than the calibrated model. This is likely due to the isotonic regression model overfitting to the tuning set. We will use the uncalibrated model to set the optimal decision threshold.</p>
<p>Evalulate the original decision threshold of 0.5 on the test set.</p>
<div id="cell-evaluate-default-threshold-s2" class="cell" data-execution_count="50">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1"></a>leaderboard_s2_default <span class="op">=</span> ag_model_s2_predictor.leaderboard(</span>
<span id="cb64-2"><a href="#cb64-2"></a>    df_test_ft.to_pandas()</span>
<span id="cb64-3"><a href="#cb64-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb64-4"><a href="#cb64-4"></a>)</span>
<span id="cb64-5"><a href="#cb64-5"></a></span>
<span id="cb64-6"><a href="#cb64-6"></a>display(leaderboard_s2_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="evaluate-default-threshold-s2" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>0.887783</td>
<td>0.881716</td>
<td>0.892473</td>
<td>average_precision</td>
<td>1.165058</td>
<td>0.832053</td>
<td>145.719991</td>
<td>0.012000</td>
<td>0.027095</td>
<td>3.872444</td>
<td>2</td>
<td>True</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>RandomForestGini</td>
<td>0.882428</td>
<td>0.879566</td>
<td>0.887466</td>
<td>average_precision</td>
<td>0.732101</td>
<td>0.483108</td>
<td>99.301560</td>
<td>0.732101</td>
<td>0.483108</td>
<td>99.301560</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>CatBoost</td>
<td>0.877045</td>
<td>0.849505</td>
<td>0.874630</td>
<td>average_precision</td>
<td>0.051596</td>
<td>0.019969</td>
<td>24.265952</td>
<td>0.051596</td>
<td>0.019969</td>
<td>24.265952</td>
<td>1</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>RandomForestEntr</td>
<td>0.876554</td>
<td>0.879167</td>
<td>0.881989</td>
<td>average_precision</td>
<td>0.260797</td>
<td>0.191715</td>
<td>34.407330</td>
<td>0.260797</td>
<td>0.191715</td>
<td>34.407330</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>LightGBM</td>
<td>0.872023</td>
<td>0.848447</td>
<td>0.874268</td>
<td>average_precision</td>
<td>0.160160</td>
<td>0.130134</td>
<td>8.138657</td>
<td>0.160160</td>
<td>0.130134</td>
<td>8.138657</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>LightGBMXT</td>
<td>0.853871</td>
<td>0.835512</td>
<td>0.855191</td>
<td>average_precision</td>
<td>2.882113</td>
<td>2.274780</td>
<td>128.826769</td>
<td>2.882113</td>
<td>2.274780</td>
<td>128.826769</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Since the tuning set is no longer being used for probability calibration, we will use it to find the optimal decision threshold that maximizes the F1-score.</p>
<div id="threshold-tuning-s2" class="cell" data-execution_count="51">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1"></a>best_threshold_s2 <span class="op">=</span> (ag_model_s2_predictor</span>
<span id="cb65-2"><a href="#cb65-2"></a>                .calibrate_decision_threshold(</span>
<span id="cb65-3"><a href="#cb65-3"></a>                data <span class="op">=</span> df_tuning_ft.to_pandas(),</span>
<span id="cb65-4"><a href="#cb65-4"></a>                metric <span class="op">=</span> <span class="st">'f1'</span>,</span>
<span id="cb65-5"><a href="#cb65-5"></a>                decision_thresholds <span class="op">=</span> <span class="dv">200</span>)</span>
<span id="cb65-6"><a href="#cb65-6"></a>                )</span>
<span id="cb65-7"><a href="#cb65-7"></a></span>
<span id="cb65-8"><a href="#cb65-8"></a>ag_model_s2_predictor.set_decision_threshold(best_threshold_s2)</span>
<span id="cb65-9"><a href="#cb65-9"></a></span>
<span id="cb65-10"><a href="#cb65-10"></a>ag_model_s2_predictor.save()  <span class="co"># Save the predictor with the new threshold</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Use the test set to evaluate the effectivness of the decision threshold.</p>
<div id="cell-evaluate-threshold-s2" class="cell" data-execution_count="52">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1"></a>leaderboard_s2_optimized <span class="op">=</span> ag_model_s2_predictor.leaderboard(</span>
<span id="cb66-2"><a href="#cb66-2"></a>    df_test_ft.to_pandas()</span>
<span id="cb66-3"><a href="#cb66-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb66-4"><a href="#cb66-4"></a>)</span>
<span id="cb66-5"><a href="#cb66-5"></a></span>
<span id="cb66-6"><a href="#cb66-6"></a>display(leaderboard_s2_optimized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="evaluate-threshold-s2" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>0.887783</td>
<td>0.884615</td>
<td>0.892473</td>
<td>average_precision</td>
<td>1.221364</td>
<td>0.832053</td>
<td>145.719991</td>
<td>0.014518</td>
<td>0.027095</td>
<td>3.872444</td>
<td>2</td>
<td>True</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>RandomForestGini</td>
<td>0.882428</td>
<td>0.884058</td>
<td>0.887466</td>
<td>average_precision</td>
<td>0.739501</td>
<td>0.483108</td>
<td>99.301560</td>
<td>0.739501</td>
<td>0.483108</td>
<td>99.301560</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>CatBoost</td>
<td>0.877045</td>
<td>0.850790</td>
<td>0.874630</td>
<td>average_precision</td>
<td>0.053558</td>
<td>0.019969</td>
<td>24.265952</td>
<td>0.053558</td>
<td>0.019969</td>
<td>24.265952</td>
<td>1</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>RandomForestEntr</td>
<td>0.876554</td>
<td>0.883278</td>
<td>0.881989</td>
<td>average_precision</td>
<td>0.289131</td>
<td>0.191715</td>
<td>34.407330</td>
<td>0.289131</td>
<td>0.191715</td>
<td>34.407330</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>LightGBM</td>
<td>0.872023</td>
<td>0.848623</td>
<td>0.874268</td>
<td>average_precision</td>
<td>0.178214</td>
<td>0.130134</td>
<td>8.138657</td>
<td>0.178214</td>
<td>0.130134</td>
<td>8.138657</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>LightGBMXT</td>
<td>0.853871</td>
<td>0.835443</td>
<td>0.855191</td>
<td>average_precision</td>
<td>2.984126</td>
<td>2.274780</td>
<td>128.826769</td>
<td>2.984126</td>
<td>2.274780</td>
<td>128.826769</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Tuning the decision threshold does not appear to substantially improve the F1-score on the test set. The default threshold of 0.5 yields a similar F1-score.</p>
</section>
<section id="cost-sensitive-learning-approach-1" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="cost-sensitive-learning-approach-1"><span class="header-section-number">9.4</span> Cost-Sensitive Learning Approach</h2>
<p><strong>Concept Recap:</strong> Cost-sensitive learning is achieved by assigning higher weights to the minority class (fraud) instances during training. AutoGluon handles this internally when <code>sample_weight='balance_weight'</code> is specified. We will use <code>average_precision</code> as the evaluation metric.</p>
<p>Setup AutoGluon parameters.</p>
<div id="setup-autogluon-cost-sensitive" class="cell" data-execution_count="53">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a>strategy_name_3 <span class="op">=</span> <span class="st">"3. Cost Sensitive Learning"</span></span>
<span id="cb67-2"><a href="#cb67-2"></a>model_folder_s3 <span class="op">=</span> <span class="st">"Lab04_ag_models_s3_cost_sensitive"</span></span>
<span id="cb67-3"><a href="#cb67-3"></a>remove_ag_folder(model_folder_s3)</span>
<span id="cb67-4"><a href="#cb67-4"></a></span>
<span id="cb67-5"><a href="#cb67-5"></a>predictor_args_s3 <span class="op">=</span> {</span>
<span id="cb67-6"><a href="#cb67-6"></a>    <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb67-7"><a href="#cb67-7"></a>    <span class="st">'eval_metric'</span>: <span class="st">'average_precision'</span>, </span>
<span id="cb67-8"><a href="#cb67-8"></a>    <span class="st">'path'</span>: model_folder_s3,</span>
<span id="cb67-9"><a href="#cb67-9"></a>    <span class="st">'sample_weight'</span>: <span class="st">'balance_weight'</span> <span class="co"># Use balance weights for cost-sensitive learning</span></span>
<span id="cb67-10"><a href="#cb67-10"></a>}</span>
<span id="cb67-11"><a href="#cb67-11"></a></span>
<span id="cb67-12"><a href="#cb67-12"></a>fit_args_s3 <span class="op">=</span> {<span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb67-13"><a href="#cb67-13"></a>            <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb67-14"><a href="#cb67-14"></a>            <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb67-15"><a href="#cb67-15"></a>            <span class="st">'time_limit'</span>: <span class="dv">300</span>}  </span>
<span id="cb67-16"><a href="#cb67-16"></a></span>
<span id="cb67-17"><a href="#cb67-17"></a>ag_wrapper_s3 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb67-18"><a href="#cb67-18"></a>    label<span class="op">=</span>target_label,</span>
<span id="cb67-19"><a href="#cb67-19"></a>    predictor_args<span class="op">=</span>predictor_args_s3,</span>
<span id="cb67-20"><a href="#cb67-20"></a>    fit_args<span class="op">=</span>fit_args_s3</span>
<span id="cb67-21"><a href="#cb67-21"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Removed existing AutoGluon folder: Lab04_ag_models_s3_cost_sensitive</code></pre>
</div>
</div>
<p>Fit the model using AutoGluon.</p>
<div id="606d6f01" class="cell" data-execution_count="54">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1"></a>ag_model_s3 <span class="op">=</span> ag_wrapper_s3.fit(X_train, y_train) </span>
<span id="cb69-2"><a href="#cb69-2"></a></span>
<span id="cb69-3"><a href="#cb69-3"></a>ag_model_s3.predictor.save()  <span class="co"># Save the predictor for later use</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1000]  valid_set's binary_logloss: 0.0852008   valid_set's average_precision: 0.835404
[2000]  valid_set's binary_logloss: 0.0614944   valid_set's average_precision: 0.839847</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1000]  valid_set's binary_logloss: 0.0405128   valid_set's average_precision: 0.866161</code></pre>
</div>
</div>
<p>Access the AutoGluon predictor object.</p>
<div id="access-autogluon-predictor-s3" class="cell" data-execution_count="55">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a>ag_model_s3_predictor <span class="op">=</span> ag_model_s3.predictor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check the leaderboard.</p>
<div id="cell-leaderboard-s3" class="cell" data-execution_count="56">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1"></a>leaderboard_s3 <span class="op">=</span> ag_model_s3_predictor.leaderboard(</span>
<span id="cb73-2"><a href="#cb73-2"></a>    df_tuning_ft.to_pandas()</span>
<span id="cb73-3"><a href="#cb73-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>]</span>
<span id="cb73-4"><a href="#cb73-4"></a>)</span>
<span id="cb73-5"><a href="#cb73-5"></a>display(leaderboard_s3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="leaderboard-s3" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">average_precision</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>0.862377</td>
<td>0.862377</td>
<td>0.868367</td>
<td>0.877935</td>
<td>average_precision</td>
<td>2.187912</td>
<td>1.719211</td>
<td>130.803421</td>
<td>0.012061</td>
<td>0.036092</td>
<td>3.698972</td>
<td>2</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>LightGBM</td>
<td>0.859248</td>
<td>0.859248</td>
<td>0.701040</td>
<td>0.866827</td>
<td>average_precision</td>
<td>1.950844</td>
<td>1.512152</td>
<td>100.768353</td>
<td>1.950844</td>
<td>1.512152</td>
<td>100.768353</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>RandomForestGini</td>
<td>0.846160</td>
<td>0.846160</td>
<td>0.854614</td>
<td>0.865369</td>
<td>average_precision</td>
<td>0.189376</td>
<td>0.145381</td>
<td>19.120825</td>
<td>0.189376</td>
<td>0.145381</td>
<td>19.120825</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LightGBMXT</td>
<td>0.830649</td>
<td>0.830649</td>
<td>0.517019</td>
<td>0.840396</td>
<td>average_precision</td>
<td>3.644088</td>
<td>3.089920</td>
<td>162.693654</td>
<td>3.644088</td>
<td>3.089920</td>
<td>162.693654</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>CatBoost</td>
<td>0.813994</td>
<td>0.813994</td>
<td>0.451967</td>
<td>0.826635</td>
<td>average_precision</td>
<td>0.035630</td>
<td>0.025585</td>
<td>7.215271</td>
<td>0.035630</td>
<td>0.025585</td>
<td>7.215271</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Set the best model to CatBoost due to inference speed and performance.</p>
<div id="set-best-model-s3" class="cell" data-execution_count="57">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1"></a>ag_model_s3_predictor.set_model_best(<span class="st">'CatBoost'</span>)</span>
<span id="cb74-2"><a href="#cb74-2"></a></span>
<span id="cb74-3"><a href="#cb74-3"></a>ag_model_s3.predictor.save()  <span class="co"># Save the predictor for later use</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Check feature importance.</p>
<div id="cell-feature-importance-s3" class="cell" data-execution_count="58">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a>feature_importance_s3 <span class="op">=</span> ag_model_s3_predictor.feature_importance(</span>
<span id="cb75-2"><a href="#cb75-2"></a>    df_tuning_ft.to_pandas(),</span>
<span id="cb75-3"><a href="#cb75-3"></a>    subsample_size <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb75-4"><a href="#cb75-4"></a>    num_shuffle_sets <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb75-5"><a href="#cb75-5"></a>)</span>
<span id="cb75-6"><a href="#cb75-6"></a></span>
<span id="cb75-7"><a href="#cb75-7"></a>display(feature_importance_s3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="feature-importance-s3" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">importance</th>
<th data-quarto-table-cell-role="th">stddev</th>
<th data-quarto-table-cell-role="th">p_value</th>
<th data-quarto-table-cell-role="th">n</th>
<th data-quarto-table-cell-role="th">p99_high</th>
<th data-quarto-table-cell-role="th">p99_low</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_30DAY_WINDOW</td>
<td>0.772525</td>
<td>0.001363</td>
<td>1.162117e-12</td>
<td>5</td>
<td>0.775331</td>
<td>0.769719</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TX_AMOUNT</td>
<td>0.746275</td>
<td>0.000626</td>
<td>5.925048e-14</td>
<td>5</td>
<td>0.747563</td>
<td>0.744987</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_RISK_1DAY_WINDOW</td>
<td>0.653582</td>
<td>0.003359</td>
<td>8.371123e-11</td>
<td>5</td>
<td>0.660498</td>
<td>0.646666</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_7DAY_WINDOW</td>
<td>0.330079</td>
<td>0.005936</td>
<td>1.254827e-08</td>
<td>5</td>
<td>0.342302</td>
<td>0.317856</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_AVG_AMOUNT_1DAY_WINDOW</td>
<td>0.062428</td>
<td>0.003003</td>
<td>6.406525e-07</td>
<td>5</td>
<td>0.068611</td>
<td>0.056244</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_7DAY_WINDOW</td>
<td>0.009043</td>
<td>0.000386</td>
<td>3.986014e-07</td>
<td>5</td>
<td>0.009839</td>
<td>0.008248</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_NB_TX_7DAY_WINDOW</td>
<td>0.002180</td>
<td>0.000358</td>
<td>8.383681e-05</td>
<td>5</td>
<td>0.002917</td>
<td>0.001444</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_RISK_30DAY_WINDOW</td>
<td>0.001942</td>
<td>0.000535</td>
<td>6.239357e-04</td>
<td>5</td>
<td>0.003043</td>
<td>0.000842</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CID_NB_TX_30DAY_WINDOW</td>
<td>0.000744</td>
<td>0.000605</td>
<td>2.567883e-02</td>
<td>5</td>
<td>0.001991</td>
<td>-0.000502</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CID_NB_TX_1DAY_WINDOW</td>
<td>0.000411</td>
<td>0.000171</td>
<td>2.892718e-03</td>
<td>5</td>
<td>0.000762</td>
<td>0.000059</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TX_DURING_NIGHT</td>
<td>-0.000032</td>
<td>0.000222</td>
<td>6.197106e-01</td>
<td>5</td>
<td>0.000426</td>
<td>-0.000490</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_NB_TX_1DAY_WINDOW</td>
<td>-0.000063</td>
<td>0.000414</td>
<td>6.248559e-01</td>
<td>5</td>
<td>0.000789</td>
<td>-0.000915</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TX_DURING_WEEKEND</td>
<td>-0.000128</td>
<td>0.000115</td>
<td>9.658780e-01</td>
<td>5</td>
<td>0.000109</td>
<td>-0.000365</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TID_NB_TX_7DAY_WINDOW</td>
<td>-0.000335</td>
<td>0.000285</td>
<td>9.709905e-01</td>
<td>5</td>
<td>0.000251</td>
<td>-0.000921</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TID_NB_TX_30DAY_WINDOW</td>
<td>-0.000613</td>
<td>0.000240</td>
<td>9.976699e-01</td>
<td>5</td>
<td>-0.000119</td>
<td>-0.001108</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Check probability calibration using the tuning set.</p>
<div id="calibration-s3" class="cell" data-execution_count="59">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb76-2"><a href="#cb76-2"></a></span>
<span id="cb76-3"><a href="#cb76-3"></a>pre_cal_disp_s3 <span class="op">=</span> CalibrationDisplay.from_estimator(</span>
<span id="cb76-4"><a href="#cb76-4"></a>        estimator <span class="op">=</span> ag_model_s3,</span>
<span id="cb76-5"><a href="#cb76-5"></a>        X <span class="op">=</span> X_tuning,</span>
<span id="cb76-6"><a href="#cb76-6"></a>        y <span class="op">=</span> y_tuning,</span>
<span id="cb76-7"><a href="#cb76-7"></a>        n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb76-8"><a href="#cb76-8"></a>        name <span class="op">=</span> <span class="st">'Pre-Calib Curve: Do Nothing Strategy'</span>,</span>
<span id="cb76-9"><a href="#cb76-9"></a>        color <span class="op">=</span> <span class="st">'orange'</span></span>
<span id="cb76-10"><a href="#cb76-10"></a>    )</span>
<span id="cb76-11"><a href="#cb76-11"></a></span>
<span id="cb76-12"><a href="#cb76-12"></a>pre_cal_disp_s3.ax_.set_title(<span class="st">"Calibration Plot (Tuning Set)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="calibration-s3-1" class="cell-output cell-output-display" data-execution_count="257">
<pre><code>Text(0.5, 1.0, 'Calibration Plot (Tuning Set)')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/calibration-s3-output-2.png" id="calibration-s3-2" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Fit a calibration model (isotonic regression) to the predicted probabilities from the tuning set. After fitting, we can no longer use the tuning set for calibration evaluation due to potential overfitting on the tuning set.</p>
<div id="cf67b88d" class="cell" data-execution_count="60">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1"></a>cal_model_s3 <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb78-2"><a href="#cb78-2"></a>    estimator <span class="op">=</span> ag_model_s3,</span>
<span id="cb78-3"><a href="#cb78-3"></a>    method<span class="op">=</span><span class="st">'isotonic'</span>,</span>
<span id="cb78-4"><a href="#cb78-4"></a>    cv<span class="op">=</span><span class="st">"prefit"</span> <span class="co"># Use the fitted model from ag_model</span></span>
<span id="cb78-5"><a href="#cb78-5"></a>)</span>
<span id="cb78-6"><a href="#cb78-6"></a></span>
<span id="cb78-7"><a href="#cb78-7"></a>global_set_seed()</span>
<span id="cb78-8"><a href="#cb78-8"></a></span>
<span id="cb78-9"><a href="#cb78-9"></a>cal_model_s3.fit(X <span class="op">=</span> X_tuning,</span>
<span id="cb78-10"><a href="#cb78-10"></a>            y <span class="op">=</span> y_tuning)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="258">
<style>#sk-container-id-12 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-12 {
  color: var(--sklearn-color-text);
}

#sk-container-id-12 pre {
  padding: 0;
}

#sk-container-id-12 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-12 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-12 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-12 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-12 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-12 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-12 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-12 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-12 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-12 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-12 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-12 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-12 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-12 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-12 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-12 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-12 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-12 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-12 div.sk-label label.sk-toggleable__label,
#sk-container-id-12 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-12 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-12 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-12 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-12 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-12 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-12 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-12 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-12 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-12 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-12 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-12" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CalibratedClassifierCV(cv='prefit',
                       estimator=AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                                                   'holdout_frac': 0.2,
                                                                   'presets': 'medium_quality',
                                                                   'time_limit': 300},
                                                         label='TX_FRAUD',
                                                         predictor_args={'eval_metric': 'average_precision',
                                                                         'path': 'Lab04_ag_models_s3_cost_sensitive',
                                                                         'problem_type': 'binary',
                                                                         'sample_weight': 'balance_weight'}),
                       method='isotonic')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-34" type="checkbox"><label for="sk-estimator-id-34" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;CalibratedClassifierCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.calibration.CalibratedClassifierCV.html">?<span>Documentation for CalibratedClassifierCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>CalibratedClassifierCV(cv='prefit',
                       estimator=AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                                                   'holdout_frac': 0.2,
                                                                   'presets': 'medium_quality',
                                                                   'time_limit': 300},
                                                         label='TX_FRAUD',
                                                         predictor_args={'eval_metric': 'average_precision',
                                                                         'path': 'Lab04_ag_models_s3_cost_sensitive',
                                                                         'problem_type': 'binary',
                                                                         'sample_weight': 'balance_weight'}),
                       method='isotonic')</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-35" type="checkbox"><label for="sk-estimator-id-35" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">estimator: AutoGluonSklearnWrapper</label><div class="sk-toggleable__content fitted"><pre>AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                  'holdout_frac': 0.2,
                                  'presets': 'medium_quality',
                                  'time_limit': 300},
                        label='TX_FRAUD',
                        predictor_args={'eval_metric': 'average_precision',
                                        'path': 'Lab04_ag_models_s3_cost_sensitive',
                                        'problem_type': 'binary',
                                        'sample_weight': 'balance_weight'})</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-36" type="checkbox"><label for="sk-estimator-id-36" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">AutoGluonSklearnWrapper</label><div class="sk-toggleable__content fitted"><pre>AutoGluonSklearnWrapper(fit_args={'excluded_model_types': ['KNN'],
                                  'holdout_frac': 0.2,
                                  'presets': 'medium_quality',
                                  'time_limit': 300},
                        label='TX_FRAUD',
                        predictor_args={'eval_metric': 'average_precision',
                                        'path': 'Lab04_ag_models_s3_cost_sensitive',
                                        'problem_type': 'binary',
                                        'sample_weight': 'balance_weight'})</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<p>Since the isotonic regression model was fitted on the tuning set, we can no longer use the tuning set for calibration evaluation. We will use the test set for calibration evaluation.</p>
<div id="cell-calibration-s3-test" class="cell" data-execution_count="61">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb79-2"><a href="#cb79-2"></a></span>
<span id="cb79-3"><a href="#cb79-3"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb79-4"><a href="#cb79-4"></a></span>
<span id="cb79-5"><a href="#cb79-5"></a><span class="cf">for</span> estimator, name, color <span class="kw">in</span> [(ag_model_s3, <span class="st">'Uncalib_CatBoost'</span>, <span class="st">'orange'</span>),</span>
<span id="cb79-6"><a href="#cb79-6"></a>          (cal_model_s3, <span class="st">'Calib_CatBoost'</span>, <span class="st">'blue'</span>)]:</span>
<span id="cb79-7"><a href="#cb79-7"></a></span>
<span id="cb79-8"><a href="#cb79-8"></a>  CalibrationDisplay.from_estimator(</span>
<span id="cb79-9"><a href="#cb79-9"></a>      estimator <span class="op">=</span> estimator,</span>
<span id="cb79-10"><a href="#cb79-10"></a>      X <span class="op">=</span> X_test,</span>
<span id="cb79-11"><a href="#cb79-11"></a>      y <span class="op">=</span> y_test,</span>
<span id="cb79-12"><a href="#cb79-12"></a>      n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb79-13"><a href="#cb79-13"></a>      name <span class="op">=</span> name,</span>
<span id="cb79-14"><a href="#cb79-14"></a>      color <span class="op">=</span> color,</span>
<span id="cb79-15"><a href="#cb79-15"></a>      ax <span class="op">=</span> ax</span>
<span id="cb79-16"><a href="#cb79-16"></a>    )</span>
<span id="cb79-17"><a href="#cb79-17"></a>    </span>
<span id="cb79-18"><a href="#cb79-18"></a>ax.set_title(<span class="st">"Calibration Plot (Test Set)"</span>)</span>
<span id="cb79-19"><a href="#cb79-19"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/calibration-s3-test-output-1.png" id="calibration-s3-test" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The uncalibrated CatBoost model shows <strong>better</strong> calibration than the calibrated model. This is likely due to the isotonic regression model overfitting to the tuning set. We will use the uncalibrated model to set the optimal decision threshold.</p>
<p>Evalulate the original decision threshold of 0.5 on the test set.</p>
<div id="cell-evaluate-default-threshold-s3" class="cell" data-execution_count="62">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1"></a>leaderboard_s3_default <span class="op">=</span> ag_model_s3_predictor.leaderboard(</span>
<span id="cb80-2"><a href="#cb80-2"></a>    df_test_ft.to_pandas()</span>
<span id="cb80-3"><a href="#cb80-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb80-4"><a href="#cb80-4"></a>)</span>
<span id="cb80-5"><a href="#cb80-5"></a></span>
<span id="cb80-6"><a href="#cb80-6"></a>display(leaderboard_s3_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="evaluate-default-threshold-s3" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>0.869023</td>
<td>0.874585</td>
<td>0.877935</td>
<td>average_precision</td>
<td>2.155512</td>
<td>1.719211</td>
<td>130.803421</td>
<td>0.013524</td>
<td>0.036092</td>
<td>3.698972</td>
<td>2</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>LightGBM</td>
<td>0.862662</td>
<td>0.704334</td>
<td>0.866827</td>
<td>average_precision</td>
<td>1.905129</td>
<td>1.512152</td>
<td>100.768353</td>
<td>1.905129</td>
<td>1.512152</td>
<td>100.768353</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>RandomForestGini</td>
<td>0.852256</td>
<td>0.864360</td>
<td>0.865369</td>
<td>average_precision</td>
<td>0.202118</td>
<td>0.145381</td>
<td>19.120825</td>
<td>0.202118</td>
<td>0.145381</td>
<td>19.120825</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LightGBMXT</td>
<td>0.840984</td>
<td>0.515247</td>
<td>0.840396</td>
<td>average_precision</td>
<td>3.917534</td>
<td>3.089920</td>
<td>162.693654</td>
<td>3.917534</td>
<td>3.089920</td>
<td>162.693654</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>CatBoost</td>
<td>0.827440</td>
<td>0.449544</td>
<td>0.826635</td>
<td>average_precision</td>
<td>0.034740</td>
<td>0.025585</td>
<td>7.215271</td>
<td>0.034740</td>
<td>0.025585</td>
<td>7.215271</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Since the tuning set is no longer being used for probability calibration, we will use it to find the optimal decision threshold that maximizes the F1-score.</p>
<div id="threshold-tuning-s3" class="cell" data-execution_count="63">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1"></a>best_threshold_s3 <span class="op">=</span> (ag_model_s3_predictor</span>
<span id="cb81-2"><a href="#cb81-2"></a>                .calibrate_decision_threshold(</span>
<span id="cb81-3"><a href="#cb81-3"></a>                data <span class="op">=</span> df_tuning_ft.to_pandas(),</span>
<span id="cb81-4"><a href="#cb81-4"></a>                metric <span class="op">=</span> <span class="st">'f1'</span>,</span>
<span id="cb81-5"><a href="#cb81-5"></a>                decision_thresholds <span class="op">=</span> <span class="dv">200</span>)</span>
<span id="cb81-6"><a href="#cb81-6"></a>                )</span>
<span id="cb81-7"><a href="#cb81-7"></a></span>
<span id="cb81-8"><a href="#cb81-8"></a>ag_model_s3_predictor.set_decision_threshold(best_threshold_s3)</span>
<span id="cb81-9"><a href="#cb81-9"></a></span>
<span id="cb81-10"><a href="#cb81-10"></a>ag_model_s3_predictor.save()  <span class="co"># Save the predictor with the new threshold</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Use the test set to evaluate the effectivness of the decision threshold.</p>
<div id="cell-evaluate-threshold-s3" class="cell" data-execution_count="64">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1"></a>leaderboard_s3_optimized <span class="op">=</span> ag_model_s3_predictor.leaderboard(</span>
<span id="cb82-2"><a href="#cb82-2"></a>    df_test_ft.to_pandas()</span>
<span id="cb82-3"><a href="#cb82-3"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb82-4"><a href="#cb82-4"></a>)</span>
<span id="cb82-5"><a href="#cb82-5"></a></span>
<span id="cb82-6"><a href="#cb82-6"></a>display(leaderboard_s3_optimized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="evaluate-threshold-s3" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>WeightedEnsemble_L2</td>
<td>0.869023</td>
<td>0.267706</td>
<td>0.877935</td>
<td>average_precision</td>
<td>2.099171</td>
<td>1.719211</td>
<td>130.803421</td>
<td>0.010497</td>
<td>0.036092</td>
<td>3.698972</td>
<td>2</td>
<td>True</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>LightGBM</td>
<td>0.862662</td>
<td>0.831065</td>
<td>0.866827</td>
<td>average_precision</td>
<td>1.851408</td>
<td>1.512152</td>
<td>100.768353</td>
<td>1.851408</td>
<td>1.512152</td>
<td>100.768353</td>
<td>1</td>
<td>True</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>RandomForestGini</td>
<td>0.852256</td>
<td>0.268293</td>
<td>0.865369</td>
<td>average_precision</td>
<td>0.201094</td>
<td>0.145381</td>
<td>19.120825</td>
<td>0.201094</td>
<td>0.145381</td>
<td>19.120825</td>
<td>1</td>
<td>True</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LightGBMXT</td>
<td>0.840984</td>
<td>0.827600</td>
<td>0.840396</td>
<td>average_precision</td>
<td>3.769531</td>
<td>3.089920</td>
<td>162.693654</td>
<td>3.769531</td>
<td>3.089920</td>
<td>162.693654</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>CatBoost</td>
<td>0.827440</td>
<td>0.803539</td>
<td>0.826635</td>
<td>average_precision</td>
<td>0.036172</td>
<td>0.025585</td>
<td>7.215271</td>
<td>0.036172</td>
<td>0.025585</td>
<td>7.215271</td>
<td>1</td>
<td>True</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Tuning the decision threshold does not appear to substantially improve the F1-score on the test set. The default threshold of 0.5 yields a similar F1-score.</p>
<p><strong>stopped here 6/4</strong></p>
</section>
<section id="resampling-approach-1" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="resampling-approach-1"><span class="header-section-number">9.5</span> Resampling Approach</h2>
<p><strong>Concept Recap:</strong> Modify the training data distribution to be more balanced. We will use SMOTE (Synthetic Minority Over-sampling Technique) to oversample the minority (fraud) class in the training set. The tuning and test sets remain unchanged. Probability calibration after training on resampled data is a critical concern.</p>
<section id="random-undersampling-of-majority-class-rus" class="level3" data-number="9.5.1">
<h3 data-number="9.5.1" class="anchored" data-anchor-id="random-undersampling-of-majority-class-rus"><span class="header-section-number">9.5.1</span> Random Undersampling of Majority Class (RUS)</h3>
</section>
<section id="random-oversampling-of-minority-class-ros" class="level3" data-number="9.5.2">
<h3 data-number="9.5.2" class="anchored" data-anchor-id="random-oversampling-of-minority-class-ros"><span class="header-section-number">9.5.2</span> Random Oversampling of Minority Class (ROS)</h3>
<div id="model-strategy4-resampling-prep" class="cell" data-execution_count="65">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1"></a><span class="cf">if</span> X_train.empty:</span>
<span id="cb83-2"><a href="#cb83-2"></a>    <span class="bu">print</span>(<span class="st">"Skipping data preparation for Strategy 4: Training data is empty."</span>)</span>
<span id="cb83-3"><a href="#cb83-3"></a>    X_train_smote, y_train_smote <span class="op">=</span> pd.DataFrame(), pd.Series(dtype<span class="op">=</span><span class="st">'int'</span>) <span class="co"># Placeholders</span></span>
<span id="cb83-4"><a href="#cb83-4"></a><span class="cf">else</span>:</span>
<span id="cb83-5"><a href="#cb83-5"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Preparing Resampled Training Data (SMOTE) for Strategy 4 ---"</span>)</span>
<span id="cb83-6"><a href="#cb83-6"></a>    </span>
<span id="cb83-7"><a href="#cb83-7"></a>    <span class="co"># Initialize SMOTE. We can adjust the sampling_strategy if needed.</span></span>
<span id="cb83-8"><a href="#cb83-8"></a>    <span class="co"># Default is to oversample the minority class to have an equal number of samples as the majority class.</span></span>
<span id="cb83-9"><a href="#cb83-9"></a>    smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">2025</span>, k_neighbors<span class="op">=</span><span class="dv">5</span>) <span class="co"># k_neighbors should be less than minority samples</span></span>
<span id="cb83-10"><a href="#cb83-10"></a>    </span>
<span id="cb83-11"><a href="#cb83-11"></a>    <span class="co"># Check minority class size for k_neighbors</span></span>
<span id="cb83-12"><a href="#cb83-12"></a>    minority_class_count <span class="op">=</span> y_train.value_counts().<span class="bu">min</span>()</span>
<span id="cb83-13"><a href="#cb83-13"></a>    <span class="cf">if</span> minority_class_count <span class="op">&lt;=</span> smote.k_neighbors:</span>
<span id="cb83-14"><a href="#cb83-14"></a>        <span class="co"># Adjust k_neighbors if it's too large for the number of minority samples</span></span>
<span id="cb83-15"><a href="#cb83-15"></a>        <span class="co"># This is a common issue with very small minority classes in CV folds or small datasets.</span></span>
<span id="cb83-16"><a href="#cb83-16"></a>        new_k <span class="op">=</span> <span class="bu">max</span>(<span class="dv">1</span>, minority_class_count <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb83-17"><a href="#cb83-17"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Original k_neighbors (</span><span class="sc">{</span>smote<span class="sc">.</span>k_neighbors<span class="sc">}</span><span class="ss">) for SMOTE is &gt;= minority samples (</span><span class="sc">{</span>minority_class_count<span class="sc">}</span><span class="ss">). Adjusting k_neighbors to </span><span class="sc">{</span>new_k<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb83-18"><a href="#cb83-18"></a>        smote.k_neighbors <span class="op">=</span> new_k</span>
<span id="cb83-19"><a href="#cb83-19"></a></span>
<span id="cb83-20"><a href="#cb83-20"></a>    <span class="cf">if</span> minority_class_count <span class="op">&gt;</span> <span class="dv">1</span>: <span class="co"># SMOTE needs at least 2 samples in the minority class to operate with k_neighbors=1</span></span>
<span id="cb83-21"><a href="#cb83-21"></a>        start_time_smote <span class="op">=</span> time.time()</span>
<span id="cb83-22"><a href="#cb83-22"></a>        <span class="cf">try</span>:</span>
<span id="cb83-23"><a href="#cb83-23"></a>            X_train_smote, y_train_smote <span class="op">=</span> smote.fit_resample(X_train, y_train)</span>
<span id="cb83-24"><a href="#cb83-24"></a>            end_time_smote <span class="op">=</span> time.time()</span>
<span id="cb83-25"><a href="#cb83-25"></a>            <span class="bu">print</span>(<span class="ss">f"SMOTE applied in </span><span class="sc">{</span>end_time_smote <span class="op">-</span> start_time_smote<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb83-26"><a href="#cb83-26"></a>            <span class="bu">print</span>(<span class="ss">f"Resampled training data shape: </span><span class="sc">{</span>X_train_smote<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, Resampled target distribution:</span><span class="ch">\n</span><span class="sc">{</span>y_train_smote<span class="sc">.</span>value_counts(normalize<span class="op">=</span><span class="va">True</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb83-27"><a href="#cb83-27"></a>        <span class="cf">except</span> <span class="pp">ValueError</span> <span class="im">as</span> e:</span>
<span id="cb83-28"><a href="#cb83-28"></a>            <span class="bu">print</span>(<span class="ss">f"Error during SMOTE: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">. This can happen if minority class count is too low for k_neighbors."</span>)</span>
<span id="cb83-29"><a href="#cb83-29"></a>            <span class="bu">print</span>(<span class="st">"Skipping SMOTE, proceeding with original data for this strategy as a fallback."</span>)</span>
<span id="cb83-30"><a href="#cb83-30"></a>            X_train_smote, y_train_smote <span class="op">=</span> X_train.copy(), y_train.copy()</span>
<span id="cb83-31"><a href="#cb83-31"></a>    <span class="cf">else</span>:</span>
<span id="cb83-32"><a href="#cb83-32"></a>        <span class="bu">print</span>(<span class="st">"Minority class count is too low for SMOTE. Skipping resampling for Strategy 4."</span>)</span>
<span id="cb83-33"><a href="#cb83-33"></a>        X_train_smote, y_train_smote <span class="op">=</span> X_train.copy(), y_train.copy() <span class="co"># Fallback to original</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Preparing Resampled Training Data (SMOTE) for Strategy 4 ---
SMOTE applied in 0.80 seconds.
Resampled training data shape: (2301270, 15), Resampled target distribution:
TX_FRAUD
0    0.5
1    0.5
Name: proportion, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="synthetic-minority-over-sampling-technique-smote" class="level3" data-number="9.5.3">
<h3 data-number="9.5.3" class="anchored" data-anchor-id="synthetic-minority-over-sampling-technique-smote"><span class="header-section-number">9.5.3</span> Synthetic Minority Over-sampling Technique (SMOTE)</h3>
<div id="model-strategy4-resampling-train" class="cell" data-execution_count="66">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1"></a><span class="cf">if</span> X_train.empty <span class="kw">or</span> X_train_smote.empty:</span>
<span id="cb85-2"><a href="#cb85-2"></a>    <span class="bu">print</span>(<span class="st">"Skipping Strategy 4 training: Training data (original or resampled) is empty."</span>)</span>
<span id="cb85-3"><a href="#cb85-3"></a><span class="cf">else</span>:</span>
<span id="cb85-4"><a href="#cb85-4"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Strategy 4: Class-Based Resampling (SMOTE) ---"</span>)</span>
<span id="cb85-5"><a href="#cb85-5"></a>    strategy_name_4 <span class="op">=</span> <span class="st">"4. Resampling (SMOTE)"</span></span>
<span id="cb85-6"><a href="#cb85-6"></a>    model_folder_s4 <span class="op">=</span> <span class="st">"Lab04_ag_models_s4_smote"</span></span>
<span id="cb85-7"><a href="#cb85-7"></a>    remove_ag_folder(model_folder_s4)</span>
<span id="cb85-8"><a href="#cb85-8"></a></span>
<span id="cb85-9"><a href="#cb85-9"></a>    predictor_args_s4 <span class="op">=</span> {</span>
<span id="cb85-10"><a href="#cb85-10"></a>        <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb85-11"><a href="#cb85-11"></a>        <span class="st">'eval_metric'</span>: <span class="st">'average_precision'</span>, <span class="co"># Continue using PR-AUC</span></span>
<span id="cb85-12"><a href="#cb85-12"></a>        <span class="st">'path'</span>: model_folder_s4</span>
<span id="cb85-13"><a href="#cb85-13"></a>    }</span>
<span id="cb85-14"><a href="#cb85-14"></a></span>
<span id="cb85-15"><a href="#cb85-15"></a>    fit_args_s4 <span class="op">=</span> {</span>
<span id="cb85-16"><a href="#cb85-16"></a>        <span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb85-17"><a href="#cb85-17"></a>        <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb85-18"><a href="#cb85-18"></a>        <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb85-19"><a href="#cb85-19"></a>        <span class="st">'time_limit'</span>: <span class="dv">300</span></span>
<span id="cb85-20"><a href="#cb85-20"></a>    }</span>
<span id="cb85-21"><a href="#cb85-21"></a></span>
<span id="cb85-22"><a href="#cb85-22"></a>    ag_model_s4 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb85-23"><a href="#cb85-23"></a>        label<span class="op">=</span><span class="st">'TX_FRAUD'</span>,</span>
<span id="cb85-24"><a href="#cb85-24"></a>        predictor_args<span class="op">=</span>predictor_args_s4,</span>
<span id="cb85-25"><a href="#cb85-25"></a>        fit_args<span class="op">=</span>fit_args_s4</span>
<span id="cb85-26"><a href="#cb85-26"></a>    )</span>
<span id="cb85-27"><a href="#cb85-27"></a>    </span>
<span id="cb85-28"><a href="#cb85-28"></a>    <span class="bu">print</span>(<span class="st">"Training AutoGluon model for Strategy 4 on SMOTE data..."</span>)</span>
<span id="cb85-29"><a href="#cb85-29"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb85-30"><a href="#cb85-30"></a>    ag_model_s4.fit(X_train_smote, y_train_smote) <span class="co"># Train on resampled data</span></span>
<span id="cb85-31"><a href="#cb85-31"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb85-32"><a href="#cb85-32"></a>    <span class="bu">print</span>(<span class="ss">f"Strategy 4 model training finished in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb85-33"><a href="#cb85-33"></a></span>
<span id="cb85-34"><a href="#cb85-34"></a>    <span class="co"># Performance Reporting</span></span>
<span id="cb85-35"><a href="#cb85-35"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Performance on Test Set (Strategy 4) ---"</span>)</span>
<span id="cb85-36"><a href="#cb85-36"></a>    leaderboard_s4 <span class="op">=</span> ag_model_s4.predictor.leaderboard(df_test_ft.to_pandas(), extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>, <span class="st">'roc_auc'</span>], silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb85-37"><a href="#cb85-37"></a>    display(leaderboard_s4)</span>
<span id="cb85-38"><a href="#cb85-38"></a>    </span>
<span id="cb85-39"><a href="#cb85-39"></a>    best_model_name_s4 <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'model'</span>]</span>
<span id="cb85-40"><a href="#cb85-40"></a>    pr_auc_s4_test <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'score_test'</span>] <span class="co"># average_precision</span></span>
<span id="cb85-41"><a href="#cb85-41"></a>    roc_auc_s4_test <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'roc_auc'</span>]</span>
<span id="cb85-42"><a href="#cb85-42"></a>    f1_default_s4_test <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'f1'</span>]</span>
<span id="cb85-43"><a href="#cb85-43"></a>    <span class="bu">print</span>(<span class="ss">f"Best model: </span><span class="sc">{</span>best_model_name_s4<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb85-44"><a href="#cb85-44"></a>    <span class="bu">print</span>(<span class="ss">f"Test PR-AUC (average_precision, from leaderboard): </span><span class="sc">{</span>pr_auc_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb85-45"><a href="#cb85-45"></a>    <span class="bu">print</span>(<span class="ss">f"Test ROC-AUC (from leaderboard): </span><span class="sc">{</span>roc_auc_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb85-46"><a href="#cb85-46"></a>    <span class="bu">print</span>(<span class="ss">f"Test F1 Score at default 0.5 threshold (from leaderboard): </span><span class="sc">{</span>f1_default_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb85-47"><a href="#cb85-47"></a></span>
<span id="cb85-48"><a href="#cb85-48"></a>    <span class="co"># Probability Calibration Check &amp; Threshold Tuning</span></span>
<span id="cb85-49"><a href="#cb85-49"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Probability Calibration &amp; Threshold Tuning (Strategy 4) ---"</span>)</span>
<span id="cb85-50"><a href="#cb85-50"></a>    pred_proba_tuning_s4_raw <span class="op">=</span> ag_model_s4.predict_proba(X_tuning)[:, <span class="dv">1</span>]</span>
<span id="cb85-51"><a href="#cb85-51"></a></span>
<span id="cb85-52"><a href="#cb85-52"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb85-53"><a href="#cb85-53"></a>    disp_raw <span class="op">=</span> CalibrationDisplay.from_predictions(y_tuning, pred_proba_tuning_s4_raw, n_bins<span class="op">=</span><span class="dv">10</span>, name<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>best_model_name_s4<span class="sc">}</span><span class="ss"> (Raw from SMOTE)"</span>)</span>
<span id="cb85-54"><a href="#cb85-54"></a>    plt.title(<span class="st">"Calibration Curve (Strategy 4: SMOTE - Before Calibration)"</span>)</span>
<span id="cb85-55"><a href="#cb85-55"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb85-56"><a href="#cb85-56"></a>    plt.show()</span>
<span id="cb85-57"><a href="#cb85-57"></a>    calibration_note_s4 <span class="op">=</span> <span class="st">"Review plot; SMOTE often miscalibrates. Explicit calibration likely needed."</span></span>
<span id="cb85-58"><a href="#cb85-58"></a>    <span class="bu">print</span>(calibration_note_s4)</span>
<span id="cb85-59"><a href="#cb85-59"></a></span>
<span id="cb85-60"><a href="#cb85-60"></a>    <span class="co"># Explicit Probability Calibration Step for resampled model (if needed)</span></span>
<span id="cb85-61"><a href="#cb85-61"></a>    <span class="co"># We use CalibratedClassifierCV on the *predictions* of the AutoGluon model.</span></span>
<span id="cb85-62"><a href="#cb85-62"></a>    <span class="co"># This requires fitting CalibratedClassifierCV on the tuning set predictions.</span></span>
<span id="cb85-63"><a href="#cb85-63"></a>    <span class="co"># For simplicity with AutoGluon, which is an ensemble, we might re-calibrate its best model's predictions.</span></span>
<span id="cb85-64"><a href="#cb85-64"></a>    <span class="co"># However, AutoGluon's internal models might already have some calibration.</span></span>
<span id="cb85-65"><a href="#cb85-65"></a>    <span class="co"># Let's demonstrate a conceptual recalibration on the tuning set predictions if they look off.</span></span>
<span id="cb85-66"><a href="#cb85-66"></a>    </span>
<span id="cb85-67"><a href="#cb85-67"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Attempting to calibrate probabilities from SMOTE model using Isotonic Regression on tuning set..."</span>)</span>
<span id="cb85-68"><a href="#cb85-68"></a>    <span class="co"># We fit the calibrator on the tuning set's raw probabilities and tuning labels</span></span>
<span id="cb85-69"><a href="#cb85-69"></a>    isotonic_calibrator <span class="op">=</span> CalibratedClassifierCV(estimator<span class="op">=</span><span class="va">None</span>, method<span class="op">=</span><span class="st">'isotonic'</span>, cv<span class="op">=</span><span class="st">'prefit'</span>) </span>
<span id="cb85-70"><a href="#cb85-70"></a>    <span class="co"># To use CalibratedClassifierCV with a pre-fitted model's probabilities, we need to wrap it slightly</span></span>
<span id="cb85-71"><a href="#cb85-71"></a>    <span class="co"># or directly use IsotonicRegression from sklearn.calibration.</span></span>
<span id="cb85-72"><a href="#cb85-72"></a>    <span class="co"># For this lab, we'll use a simpler path: fit IsotonicRegression on (pred_proba_tuning_s4_raw, y_tuning)</span></span>
<span id="cb85-73"><a href="#cb85-73"></a>    <span class="co"># and then apply it to pred_proba_tuning_s4_raw for threshold tuning, and pred_proba_test_s4_raw for final eval.</span></span>
<span id="cb85-74"><a href="#cb85-74"></a>    </span>
<span id="cb85-75"><a href="#cb85-75"></a>    <span class="im">from</span> sklearn.isotonic <span class="im">import</span> IsotonicRegression</span>
<span id="cb85-76"><a href="#cb85-76"></a>    iso_reg <span class="op">=</span> IsotonicRegression(out_of_bounds<span class="op">=</span><span class="st">'clip'</span>) <span class="co"># y_min=0, y_max=1 by default for clip</span></span>
<span id="cb85-77"><a href="#cb85-77"></a>    <span class="co"># Fit on tuning probabilities and tuning labels</span></span>
<span id="cb85-78"><a href="#cb85-78"></a>    <span class="co"># Reshape pred_proba_tuning_s4_raw if it gives shape warning for IsotonicRegression</span></span>
<span id="cb85-79"><a href="#cb85-79"></a>    <span class="cf">try</span>:</span>
<span id="cb85-80"><a href="#cb85-80"></a>        iso_reg.fit(pred_proba_tuning_s4_raw, y_tuning)</span>
<span id="cb85-81"><a href="#cb85-81"></a>        pred_proba_tuning_s4_calibrated <span class="op">=</span> iso_reg.predict(pred_proba_tuning_s4_raw)</span>
<span id="cb85-82"><a href="#cb85-82"></a>        <span class="bu">print</span>(<span class="st">"Probabilities calibrated using Isotonic Regression for threshold tuning."</span>)</span>
<span id="cb85-83"><a href="#cb85-83"></a>        </span>
<span id="cb85-84"><a href="#cb85-84"></a>        <span class="co"># Display calibrated curve</span></span>
<span id="cb85-85"><a href="#cb85-85"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb85-86"><a href="#cb85-86"></a>        disp_calib <span class="op">=</span> CalibrationDisplay.from_predictions(y_tuning, pred_proba_tuning_s4_calibrated, n_bins<span class="op">=</span><span class="dv">10</span>, name<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>best_model_name_s4<span class="sc">}</span><span class="ss"> (Calibrated)"</span>)</span>
<span id="cb85-87"><a href="#cb85-87"></a>        plt.title(<span class="st">"Calibration Curve (Strategy 4: SMOTE - After Isotonic Calibration)"</span>)</span>
<span id="cb85-88"><a href="#cb85-88"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb85-89"><a href="#cb85-89"></a>        plt.show()</span>
<span id="cb85-90"><a href="#cb85-90"></a>        calibration_note_s4 <span class="op">+=</span> <span class="st">" Applied Isotonic."</span></span>
<span id="cb85-91"><a href="#cb85-91"></a>        <span class="co"># Use calibrated probabilities for threshold tuning</span></span>
<span id="cb85-92"><a href="#cb85-92"></a>        pred_proba_tuning_for_thresholding <span class="op">=</span> pred_proba_tuning_s4_calibrated</span>
<span id="cb85-93"><a href="#cb85-93"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb85-94"><a href="#cb85-94"></a>        <span class="bu">print</span>(<span class="ss">f"Could not fit IsotonicRegression (e.g. if all probabilities are same): </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">. Using raw probabilities."</span>)</span>
<span id="cb85-95"><a href="#cb85-95"></a>        pred_proba_tuning_for_thresholding <span class="op">=</span> pred_proba_tuning_s4_raw <span class="co"># Fallback to raw if calibration failed</span></span>
<span id="cb85-96"><a href="#cb85-96"></a></span>
<span id="cb85-97"><a href="#cb85-97"></a></span>
<span id="cb85-98"><a href="#cb85-98"></a>    best_f1_s4 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb85-99"><a href="#cb85-99"></a>    best_threshold_s4 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb85-100"><a href="#cb85-100"></a>    thresholds <span class="op">=</span> np.arange(<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="fl">0.01</span>)</span>
<span id="cb85-101"><a href="#cb85-101"></a>    f1_scores_tuning_s4 <span class="op">=</span> []</span>
<span id="cb85-102"><a href="#cb85-102"></a>    <span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb85-103"><a href="#cb85-103"></a>        y_pred_tuning_thresholded_s4 <span class="op">=</span> (pred_proba_tuning_for_thresholding <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb85-104"><a href="#cb85-104"></a>        current_f1 <span class="op">=</span> f1_score(y_tuning, y_pred_tuning_thresholded_s4)</span>
<span id="cb85-105"><a href="#cb85-105"></a>        f1_scores_tuning_s4.append(current_f1)</span>
<span id="cb85-106"><a href="#cb85-106"></a>        <span class="cf">if</span> current_f1 <span class="op">&gt;</span> best_f1_s4:</span>
<span id="cb85-107"><a href="#cb85-107"></a>            best_f1_s4 <span class="op">=</span> current_f1</span>
<span id="cb85-108"><a href="#cb85-108"></a>            best_threshold_s4 <span class="op">=</span> threshold</span>
<span id="cb85-109"><a href="#cb85-109"></a>            </span>
<span id="cb85-110"><a href="#cb85-110"></a>    <span class="bu">print</span>(<span class="ss">f"Best F1-score on (potentially calibrated) tuning probabilities: </span><span class="sc">{</span>best_f1_s4<span class="sc">:.4f}</span><span class="ss"> at threshold </span><span class="sc">{</span>best_threshold_s4<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb85-111"><a href="#cb85-111"></a></span>
<span id="cb85-112"><a href="#cb85-112"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb85-113"><a href="#cb85-113"></a>    plt.plot(thresholds, f1_scores_tuning_s4, marker<span class="op">=</span><span class="st">'.'</span>)</span>
<span id="cb85-114"><a href="#cb85-114"></a>    plt.axvline(best_threshold_s4, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Threshold: </span><span class="sc">{</span>best_threshold_s4<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb85-115"><a href="#cb85-115"></a>    plt.title(<span class="st">'F1 Score vs. Threshold on (Potentially Calibrated) Tuning Probs (Strategy 4)'</span>)</span>
<span id="cb85-116"><a href="#cb85-116"></a>    plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb85-117"><a href="#cb85-117"></a>    plt.ylabel(<span class="st">'F1 Score'</span>)</span>
<span id="cb85-118"><a href="#cb85-118"></a>    plt.legend()</span>
<span id="cb85-119"><a href="#cb85-119"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb85-120"><a href="#cb85-120"></a>    plt.show()</span>
<span id="cb85-121"><a href="#cb85-121"></a></span>
<span id="cb85-122"><a href="#cb85-122"></a>    <span class="co"># Evaluate on test set with optimal threshold, using calibrated probabilities for test set too</span></span>
<span id="cb85-123"><a href="#cb85-123"></a>    pred_proba_test_s4_raw <span class="op">=</span> ag_model_s4.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb85-124"><a href="#cb85-124"></a>    <span class="cf">if</span> <span class="st">'iso_reg'</span> <span class="kw">in</span> <span class="bu">locals</span>() <span class="kw">and</span> <span class="bu">hasattr</span>(iso_reg, <span class="st">'is_fitted_'</span>) <span class="kw">and</span> iso_reg.is_fitted_ : <span class="co"># Check if calibrator was successfully fitted</span></span>
<span id="cb85-125"><a href="#cb85-125"></a>         pred_proba_test_s4_final <span class="op">=</span> iso_reg.predict(pred_proba_test_s4_raw)</span>
<span id="cb85-126"><a href="#cb85-126"></a>    <span class="cf">else</span>:</span>
<span id="cb85-127"><a href="#cb85-127"></a>         pred_proba_test_s4_final <span class="op">=</span> pred_proba_test_s4_raw <span class="co"># Fallback to raw if calibration failed</span></span>
<span id="cb85-128"><a href="#cb85-128"></a>         </span>
<span id="cb85-129"><a href="#cb85-129"></a>    y_pred_test_optimal_s4 <span class="op">=</span> (pred_proba_test_s4_final <span class="op">&gt;=</span> best_threshold_s4).astype(<span class="bu">int</span>)</span>
<span id="cb85-130"><a href="#cb85-130"></a>    f1_optimal_s4_test <span class="op">=</span> f1_score(y_test, y_pred_test_optimal_s4)</span>
<span id="cb85-131"><a href="#cb85-131"></a>    <span class="bu">print</span>(<span class="ss">f"F1-score on test set with optimal threshold (</span><span class="sc">{</span>best_threshold_s4<span class="sc">:.2f}</span><span class="ss">) using (potentially calibrated) probabilities: </span><span class="sc">{</span>f1_optimal_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb85-132"><a href="#cb85-132"></a></span>
<span id="cb85-133"><a href="#cb85-133"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report on Test Set (Optimal Threshold, Strategy 4):"</span>)</span>
<span id="cb85-134"><a href="#cb85-134"></a>    <span class="bu">print</span>(classification_report(y_test, y_pred_test_optimal_s4, target_names<span class="op">=</span>[<span class="st">'Legitimate'</span>, <span class="st">'Fraud'</span>]))</span>
<span id="cb85-135"><a href="#cb85-135"></a></span>
<span id="cb85-136"><a href="#cb85-136"></a>    comparison_results.append({</span>
<span id="cb85-137"><a href="#cb85-137"></a>        <span class="st">"Strategy"</span>: strategy_name_4,</span>
<span id="cb85-138"><a href="#cb85-138"></a>        <span class="st">"Test ROC-AUC"</span>: roc_auc_s4_test,</span>
<span id="cb85-139"><a href="#cb85-139"></a>        <span class="st">"Test PR-AUC"</span>: pr_auc_s4_test,</span>
<span id="cb85-140"><a href="#cb85-140"></a>        <span class="st">"Test F1 (Optimized)"</span>: f1_optimal_s4_test,</span>
<span id="cb85-141"><a href="#cb85-141"></a>        <span class="st">"Optimized Threshold"</span>: best_threshold_s4,</span>
<span id="cb85-142"><a href="#cb85-142"></a>        <span class="st">"Calibration Note"</span>: calibration_note_s4</span>
<span id="cb85-143"><a href="#cb85-143"></a>    })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Strategy 4: Class-Based Resampling (SMOTE) ---
Removed existing AutoGluon folder: Lab04_ag_models_s4_smote
Training AutoGluon model for Strategy 4 on SMOTE data...</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1000]  valid_set's binary_logloss: 0.0328349   valid_set's average_precision: 0.999232</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Strategy 4 model training finished in 308.69 seconds.

--- Performance on Test Set (Strategy 4) ---</code></pre>
</div>
<div id="model-strategy4-resampling-train-1" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">score_test</th>
<th data-quarto-table-cell-role="th">average_precision</th>
<th data-quarto-table-cell-role="th">f1</th>
<th data-quarto-table-cell-role="th">roc_auc</th>
<th data-quarto-table-cell-role="th">score_val</th>
<th data-quarto-table-cell-role="th">eval_metric</th>
<th data-quarto-table-cell-role="th">pred_time_test</th>
<th data-quarto-table-cell-role="th">pred_time_val</th>
<th data-quarto-table-cell-role="th">fit_time</th>
<th data-quarto-table-cell-role="th">pred_time_test_marginal</th>
<th data-quarto-table-cell-role="th">pred_time_val_marginal</th>
<th data-quarto-table-cell-role="th">fit_time_marginal</th>
<th data-quarto-table-cell-role="th">stack_level</th>
<th data-quarto-table-cell-role="th">can_infer</th>
<th data-quarto-table-cell-role="th">fit_order</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>LightGBMXT</td>
<td>0.878155</td>
<td>0.878155</td>
<td>0.733095</td>
<td>0.96875</td>
<td>0.999598</td>
<td>average_precision</td>
<td>4.906156</td>
<td>7.074890</td>
<td>296.745330</td>
<td>4.906156</td>
<td>7.074890</td>
<td>296.745330</td>
<td>1</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>WeightedEnsemble_L2</td>
<td>0.878155</td>
<td>0.878155</td>
<td>0.733095</td>
<td>0.96875</td>
<td>0.999598</td>
<td>average_precision</td>
<td>4.917168</td>
<td>7.165081</td>
<td>296.860518</td>
<td>0.011012</td>
<td>0.090191</td>
<td>0.115188</td>
<td>2</td>
<td>True</td>
<td>2</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best model: LightGBMXT
Test PR-AUC (average_precision, from leaderboard): 0.8782
Test ROC-AUC (from leaderboard): 0.9687
Test F1 Score at default 0.5 threshold (from leaderboard): 0.7331

--- Probability Calibration &amp; Threshold Tuning (Strategy 4) ---</code></pre>
</div>
<div id="model-strategy4-resampling-train-2" class="cell-output cell-output-display">
<pre><code>&lt;Figure size 960x672 with 0 Axes&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/model-strategy4-resampling-train-output-7.png" id="model-strategy4-resampling-train-3" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Review plot; SMOTE often miscalibrates. Explicit calibration likely needed.

Attempting to calibrate probabilities from SMOTE model using Isotonic Regression on tuning set...
Probabilities calibrated using Isotonic Regression for threshold tuning.</code></pre>
</div>
<div id="model-strategy4-resampling-train-4" class="cell-output cell-output-display">
<pre><code>&lt;Figure size 960x672 with 0 Axes&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/model-strategy4-resampling-train-output-10.png" id="model-strategy4-resampling-train-5" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best F1-score on (potentially calibrated) tuning probabilities: 0.8642 at threshold 0.42</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/model-strategy4-resampling-train-output-12.png" id="model-strategy4-resampling-train-6" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>F1-score on test set with optimal threshold (0.42) using (potentially calibrated) probabilities: 0.6934

Classification Report on Test Set (Optimal Threshold, Strategy 4):
              precision    recall  f1-score   support

  Legitimate       1.00      0.99      1.00    285326
       Fraud       0.57      0.89      0.69      2547

    accuracy                           0.99    287873
   macro avg       0.78      0.94      0.84    287873
weighted avg       1.00      0.99      0.99    287873
</code></pre>
</div>
</div>
</section>
<section id="hybrid-smote-rus" class="level3" data-number="9.5.4">
<h3 data-number="9.5.4" class="anchored" data-anchor-id="hybrid-smote-rus"><span class="header-section-number">9.5.4</span> Hybrid: SMOTE + RUS</h3>
</section>
<section id="comparison-of-resampling-strategies" class="level3" data-number="9.5.5">
<h3 data-number="9.5.5" class="anchored" data-anchor-id="comparison-of-resampling-strategies"><span class="header-section-number">9.5.5</span> Comparison of Resampling Strategies</h3>
<p>After running all strategies, we compile the results into a summary table to compare their effectiveness.</p>
<div class="cell" data-execution_count="67">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1"></a><span class="cf">if</span> comparison_results:</span>
<span id="cb95-2"><a href="#cb95-2"></a>    summary_df <span class="op">=</span> pd.DataFrame(comparison_results)</span>
<span id="cb95-3"><a href="#cb95-3"></a>    display(summary_df)</span>
<span id="cb95-4"><a href="#cb95-4"></a><span class="cf">else</span>:</span>
<span id="cb95-5"><a href="#cb95-5"></a>    <span class="bu">print</span>(<span class="st">"No modeling results to display in the summary table."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="tbl-comparison-summary" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="67">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-comparison-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Comparison of Imbalance Handling Strategies
</figcaption>
<div aria-describedby="tbl-comparison-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Strategy</th>
<th data-quarto-table-cell-role="th">Test ROC-AUC</th>
<th data-quarto-table-cell-role="th">Test PR-AUC</th>
<th data-quarto-table-cell-role="th">Test F1 (Optimized)</th>
<th data-quarto-table-cell-role="th">Optimized Threshold</th>
<th data-quarto-table-cell-role="th">Calibration Note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>4. Resampling (SMOTE)</td>
<td>0.96875</td>
<td>0.878155</td>
<td>0.693386</td>
<td>0.42</td>
<td>Review plot; SMOTE often miscalibrates. Explic...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
</section>
<section id="interpreting-the-best-model" class="level3" data-number="9.5.6">
<h3 data-number="9.5.6" class="anchored" data-anchor-id="interpreting-the-best-model"><span class="header-section-number">9.5.6</span> Interpreting the Best Model</h3>
<p>Assuming one of the strategies yielded a satisfactory model (e.g., based on a combination of PR-AUC, F1-score, and good calibration), we can perform further interpretability analysis on it. Lets assume <code>ag_model_s2</code> (PR-AUC metric) was chosen as a good candidate for this example. You should replace this with your actual best model.</p>
<div id="interpret-best-model" class="cell" data-execution_count="68">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1"></a><span class="co"># Choose the model to interpret (e.g., ag_model_s2)</span></span>
<span id="cb96-2"><a href="#cb96-2"></a><span class="co"># For the lab, let's assume Strategy 2 (PR-AUC) gave a good balance.</span></span>
<span id="cb96-3"><a href="#cb96-3"></a><span class="co"># If another model was better, replace ag_model_s2 accordingly.</span></span>
<span id="cb96-4"><a href="#cb96-4"></a><span class="cf">if</span> <span class="st">'ag_model_s2'</span> <span class="kw">in</span> <span class="bu">locals</span>() <span class="kw">and</span> ag_model_s2.is_fitted_:</span>
<span id="cb96-5"><a href="#cb96-5"></a>    chosen_model_to_interpret <span class="op">=</span> ag_model_s2</span>
<span id="cb96-6"><a href="#cb96-6"></a>    chosen_model_name <span class="op">=</span> <span class="st">"Strategy 2 Model (PR-AUC)"</span></span>
<span id="cb96-7"><a href="#cb96-7"></a>    <span class="bu">print</span>(<span class="ss">f"--- Interpreting: </span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb96-8"><a href="#cb96-8"></a></span>
<span id="cb96-9"><a href="#cb96-9"></a>    <span class="co"># 1. Permutation Feature Importance</span></span>
<span id="cb96-10"><a href="#cb96-10"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Calculating Permutation Feature Importance..."</span>)</span>
<span id="cb96-11"><a href="#cb96-11"></a>    <span class="co"># AutoGluon's feature_importance is essentially permutation importance</span></span>
<span id="cb96-12"><a href="#cb96-12"></a>    <span class="co"># It needs the data to have the label column for evaluation during permutation.</span></span>
<span id="cb96-13"><a href="#cb96-13"></a>    X_test_with_label <span class="op">=</span> X_test.copy()</span>
<span id="cb96-14"><a href="#cb96-14"></a>    X_test_with_label[<span class="st">'TX_FRAUD'</span>] <span class="op">=</span> y_test</span>
<span id="cb96-15"><a href="#cb96-15"></a>    </span>
<span id="cb96-16"><a href="#cb96-16"></a>    pfi <span class="op">=</span> chosen_model_to_interpret.predictor.feature_importance(data<span class="op">=</span>X_test_with_label, silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb96-17"><a href="#cb96-17"></a>    pfi_df <span class="op">=</span> pfi.reset_index().rename(columns<span class="op">=</span>{<span class="st">'index'</span>: <span class="st">'feature'</span>, <span class="dv">0</span>: <span class="st">'importance'</span>})</span>
<span id="cb96-18"><a href="#cb96-18"></a>    <span class="bu">print</span>(<span class="st">"Permutation Feature Importance (Test Set):"</span>)</span>
<span id="cb96-19"><a href="#cb96-19"></a>    display(pfi_df)</span>
<span id="cb96-20"><a href="#cb96-20"></a></span>
<span id="cb96-21"><a href="#cb96-21"></a>    <span class="co"># 2. Partial Dependence Plots (PDP) / Individual Conditional Expectation (ICE)</span></span>
<span id="cb96-22"><a href="#cb96-22"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Generating PDP/ICE plots..."</span>)</span>
<span id="cb96-23"><a href="#cb96-23"></a>    <span class="co"># We need a sample of the data for PDP/ICE for performance reasons</span></span>
<span id="cb96-24"><a href="#cb96-24"></a>    <span class="co"># Background data for PDP should not have the target column</span></span>
<span id="cb96-25"><a href="#cb96-25"></a>    pdp_ice_sample_data <span class="op">=</span> X_train.sample(<span class="bu">min</span>(<span class="dv">1000</span>, <span class="bu">len</span>(X_train)), random_state<span class="op">=</span><span class="dv">2025</span>) </span>
<span id="cb96-26"><a href="#cb96-26"></a>    </span>
<span id="cb96-27"><a href="#cb96-27"></a>    <span class="co"># Get features from the predictor if possible</span></span>
<span id="cb96-28"><a href="#cb96-28"></a>    <span class="cf">try</span>:</span>
<span id="cb96-29"><a href="#cb96-29"></a>        pdp_features <span class="op">=</span> chosen_model_to_interpret.predictor.features()</span>
<span id="cb96-30"><a href="#cb96-30"></a>        <span class="co"># Select top N features by PFI for PDP/ICE if too many features</span></span>
<span id="cb96-31"><a href="#cb96-31"></a>        <span class="cf">if</span> <span class="bu">len</span>(pdp_features) <span class="op">&gt;</span> <span class="dv">5</span>:</span>
<span id="cb96-32"><a href="#cb96-32"></a>            pdp_features_to_plot <span class="op">=</span> pfi_df[<span class="st">'feature'</span>].head(<span class="dv">5</span>).tolist()</span>
<span id="cb96-33"><a href="#cb96-33"></a>        <span class="cf">else</span>:</span>
<span id="cb96-34"><a href="#cb96-34"></a>            pdp_features_to_plot <span class="op">=</span> pdp_features</span>
<span id="cb96-35"><a href="#cb96-35"></a>            </span>
<span id="cb96-36"><a href="#cb96-36"></a>        <span class="co"># Get categorical features metadata</span></span>
<span id="cb96-37"><a href="#cb96-37"></a>        cat_features_metadata <span class="op">=</span> chosen_model_to_interpret.predictor.feature_metadata</span>
<span id="cb96-38"><a href="#cb96-38"></a>        categorical_for_pdp <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> pdp_features_to_plot <span class="cf">if</span> cat_features_metadata.get_feature_type_raw(f) <span class="op">==</span> <span class="st">'category'</span>]</span>
<span id="cb96-39"><a href="#cb96-39"></a></span>
<span id="cb96-40"><a href="#cb96-40"></a>        <span class="cf">for</span> feature_to_plot <span class="kw">in</span> pdp_features_to_plot:</span>
<span id="cb96-41"><a href="#cb96-41"></a>            <span class="bu">print</span>(<span class="ss">f"PDP/ICE for feature: </span><span class="sc">{</span>feature_to_plot<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb96-42"><a href="#cb96-42"></a>            <span class="cf">try</span>:</span>
<span id="cb96-43"><a href="#cb96-43"></a>                PartialDependenceDisplay.from_estimator(</span>
<span id="cb96-44"><a href="#cb96-44"></a>                    chosen_model_to_interpret, </span>
<span id="cb96-45"><a href="#cb96-45"></a>                    pdp_ice_sample_data, </span>
<span id="cb96-46"><a href="#cb96-46"></a>                    features<span class="op">=</span>[feature_to_plot],</span>
<span id="cb96-47"><a href="#cb96-47"></a>                    categorical_features<span class="op">=</span>[feature_to_plot] <span class="cf">if</span> feature_to_plot <span class="kw">in</span> categorical_for_pdp <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb96-48"><a href="#cb96-48"></a>                    kind<span class="op">=</span><span class="st">'both'</span>, <span class="co"># PDP and ICE</span></span>
<span id="cb96-49"><a href="#cb96-49"></a>                    subsample<span class="op">=</span><span class="dv">50</span>, <span class="co"># Number of ICE lines</span></span>
<span id="cb96-50"><a href="#cb96-50"></a>                    random_state<span class="op">=</span><span class="dv">2025</span>,</span>
<span id="cb96-51"><a href="#cb96-51"></a>                    pd_line_kw<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"red"</span>, <span class="st">"linestyle"</span>: <span class="st">"--"</span>, <span class="st">"linewidth"</span>: <span class="dv">2</span>},</span>
<span id="cb96-52"><a href="#cb96-52"></a>                    ice_lines_kw<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"lightblue"</span>, <span class="st">"alpha"</span>: <span class="fl">0.5</span>, <span class="st">"linewidth"</span>: <span class="fl">0.5</span>}</span>
<span id="cb96-53"><a href="#cb96-53"></a>                )</span>
<span id="cb96-54"><a href="#cb96-54"></a>                plt.title(<span class="ss">f"PDP and ICE for </span><span class="sc">{</span>feature_to_plot<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb96-55"><a href="#cb96-55"></a>                plt.grid(<span class="va">True</span>)</span>
<span id="cb96-56"><a href="#cb96-56"></a>                plt.show()</span>
<span id="cb96-57"><a href="#cb96-57"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e_pdp:</span>
<span id="cb96-58"><a href="#cb96-58"></a>                <span class="bu">print</span>(<span class="ss">f"  Could not generate PDP/ICE for </span><span class="sc">{</span>feature_to_plot<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e_pdp<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb96-59"><a href="#cb96-59"></a></span>
<span id="cb96-60"><a href="#cb96-60"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb96-61"><a href="#cb96-61"></a>        <span class="bu">print</span>(<span class="ss">f"Could not generate PDP/ICE plots: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb96-62"><a href="#cb96-62"></a></span>
<span id="cb96-63"><a href="#cb96-63"></a>    <span class="co"># 3. SHAP Values (using a sample of test data for SHAP summary)</span></span>
<span id="cb96-64"><a href="#cb96-64"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Calculating SHAP values for summary plots..."</span>)</span>
<span id="cb96-65"><a href="#cb96-65"></a>    <span class="co"># SHAP can be slow on large datasets, so use a sample of X_test</span></span>
<span id="cb96-66"><a href="#cb96-66"></a>    <span class="cf">if</span> <span class="bu">len</span>(X_test) <span class="op">&gt;</span> <span class="dv">200</span>:</span>
<span id="cb96-67"><a href="#cb96-67"></a>        shap_sample_data <span class="op">=</span> X_test.sample(<span class="dv">200</span>, random_state<span class="op">=</span><span class="dv">2025</span>)</span>
<span id="cb96-68"><a href="#cb96-68"></a>    <span class="cf">else</span>:</span>
<span id="cb96-69"><a href="#cb96-69"></a>        shap_sample_data <span class="op">=</span> X_test</span>
<span id="cb96-70"><a href="#cb96-70"></a></span>
<span id="cb96-71"><a href="#cb96-71"></a>    <span class="cf">try</span>:</span>
<span id="cb96-72"><a href="#cb96-72"></a>        <span class="co"># Create a SHAP explainer. For tree models, TreeExplainer is efficient.</span></span>
<span id="cb96-73"><a href="#cb96-73"></a>        <span class="co"># AutoGluon often ensembles, so KernelExplainer might be more general but slower.</span></span>
<span id="cb96-74"><a href="#cb96-74"></a>        <span class="co"># If the best model is a single tree-based one (e.g. LGBM, CatBoost), we can try to optimize.</span></span>
<span id="cb96-75"><a href="#cb96-75"></a>        <span class="co"># For the wrapper, a generic lambda explainer is safer.</span></span>
<span id="cb96-76"><a href="#cb96-76"></a>        shap_explainer <span class="op">=</span> shap.Explainer(<span class="kw">lambda</span> x: chosen_model_to_interpret.predict_proba(x)[:,<span class="dv">1</span>], shap_sample_data)</span>
<span id="cb96-77"><a href="#cb96-77"></a>        shap_values_summary <span class="op">=</span> shap_explainer(shap_sample_data)</span>
<span id="cb96-78"><a href="#cb96-78"></a></span>
<span id="cb96-79"><a href="#cb96-79"></a>        <span class="bu">print</span>(<span class="st">"SHAP Summary Plot (Beeswarm):"</span>)</span>
<span id="cb96-80"><a href="#cb96-80"></a>        shap.summary_plot(shap_values_summary, shap_sample_data, plot_type<span class="op">=</span><span class="st">"beeswarm"</span>, show<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb96-81"><a href="#cb96-81"></a>        plt.title(<span class="ss">f"SHAP Beeswarm Plot (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb96-82"><a href="#cb96-82"></a>        plt.show()</span>
<span id="cb96-83"><a href="#cb96-83"></a></span>
<span id="cb96-84"><a href="#cb96-84"></a>        <span class="bu">print</span>(<span class="st">"SHAP Feature Importance (Bar Plot based on mean absolute SHAP values):"</span>)</span>
<span id="cb96-85"><a href="#cb96-85"></a>        shap.summary_plot(shap_values_summary, shap_sample_data, plot_type<span class="op">=</span><span class="st">"bar"</span>, show<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb96-86"><a href="#cb96-86"></a>        plt.title(<span class="ss">f"SHAP Bar Plot (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb96-87"><a href="#cb96-87"></a>        plt.show()</span>
<span id="cb96-88"><a href="#cb96-88"></a></span>
<span id="cb96-89"><a href="#cb96-89"></a>        <span class="co"># SHAP Dependence Plots for top features</span></span>
<span id="cb96-90"><a href="#cb96-90"></a>        <span class="bu">print</span>(<span class="st">"SHAP Dependence Plots:"</span>)</span>
<span id="cb96-91"><a href="#cb96-91"></a>        <span class="co"># Get top features from PFI to plot SHAP dependence</span></span>
<span id="cb96-92"><a href="#cb96-92"></a>        top_shap_features <span class="op">=</span> pfi_df[<span class="st">'feature'</span>].head(<span class="bu">min</span>(<span class="dv">5</span>, <span class="bu">len</span>(pfi_df))).tolist()</span>
<span id="cb96-93"><a href="#cb96-93"></a>        <span class="cf">for</span> feature_shap_dep <span class="kw">in</span> top_shap_features:</span>
<span id="cb96-94"><a href="#cb96-94"></a>            <span class="cf">if</span> feature_shap_dep <span class="kw">in</span> shap_sample_data.columns:</span>
<span id="cb96-95"><a href="#cb96-95"></a>                <span class="bu">print</span>(<span class="ss">f"  Dependence plot for </span><span class="sc">{</span>feature_shap_dep<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb96-96"><a href="#cb96-96"></a>                shap.dependence_plot(feature_shap_dep, shap_values_summary.values, shap_sample_data, show<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb96-97"><a href="#cb96-97"></a>                plt.title(<span class="ss">f"SHAP Dependence Plot for </span><span class="sc">{</span>feature_shap_dep<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb96-98"><a href="#cb96-98"></a>                plt.show()</span>
<span id="cb96-99"><a href="#cb96-99"></a>            <span class="cf">else</span>:</span>
<span id="cb96-100"><a href="#cb96-100"></a>                 <span class="bu">print</span>(<span class="ss">f"  Skipping SHAP dependence for </span><span class="sc">{</span>feature_shap_dep<span class="sc">}</span><span class="ss"> as it is not in shap_sample_data columns (this should not happen if PFI features are correct)."</span>)</span>
<span id="cb96-101"><a href="#cb96-101"></a></span>
<span id="cb96-102"><a href="#cb96-102"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e_shap:</span>
<span id="cb96-103"><a href="#cb96-103"></a>        <span class="bu">print</span>(<span class="ss">f"Could not generate SHAP plots: </span><span class="sc">{</span>e_shap<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb96-104"><a href="#cb96-104"></a><span class="cf">else</span>:</span>
<span id="cb96-105"><a href="#cb96-105"></a>    <span class="bu">print</span>(<span class="st">"Chosen model for interpretation (ag_model_s2) not available or not fitted. Skipping interpretation."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>--- Interpreting: Strategy 2 Model (PR-AUC) ---

Calculating Permutation Feature Importance...
Permutation Feature Importance (Test Set):</code></pre>
</div>
<div id="interpret-best-model-1" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">feature</th>
<th data-quarto-table-cell-role="th">importance</th>
<th data-quarto-table-cell-role="th">stddev</th>
<th data-quarto-table-cell-role="th">p_value</th>
<th data-quarto-table-cell-role="th">n</th>
<th data-quarto-table-cell-role="th">p99_high</th>
<th data-quarto-table-cell-role="th">p99_low</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>CID_AVG_AMOUNT_30DAY_WINDOW</td>
<td>0.832754</td>
<td>0.050022</td>
<td>0.000002</td>
<td>5</td>
<td>0.935750</td>
<td>0.729759</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>TX_AMOUNT</td>
<td>0.825019</td>
<td>0.053955</td>
<td>0.000002</td>
<td>5</td>
<td>0.936113</td>
<td>0.713924</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>TID_RISK_1DAY_WINDOW</td>
<td>0.729176</td>
<td>0.075452</td>
<td>0.000014</td>
<td>5</td>
<td>0.884532</td>
<td>0.573819</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>CID_AVG_AMOUNT_7DAY_WINDOW</td>
<td>0.616349</td>
<td>0.111730</td>
<td>0.000124</td>
<td>5</td>
<td>0.846401</td>
<td>0.386296</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>CID_AVG_AMOUNT_1DAY_WINDOW</td>
<td>0.200692</td>
<td>0.068406</td>
<td>0.001396</td>
<td>5</td>
<td>0.341541</td>
<td>0.059842</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>TID_RISK_7DAY_WINDOW</td>
<td>0.056637</td>
<td>0.026929</td>
<td>0.004644</td>
<td>5</td>
<td>0.112083</td>
<td>0.001190</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>TID_NB_TX_1DAY_WINDOW</td>
<td>0.007819</td>
<td>0.022537</td>
<td>0.240578</td>
<td>5</td>
<td>0.054222</td>
<td>-0.038583</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>CID_NB_TX_7DAY_WINDOW</td>
<td>0.004639</td>
<td>0.004280</td>
<td>0.036226</td>
<td>5</td>
<td>0.013452</td>
<td>-0.004173</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>CID_NB_TX_30DAY_WINDOW</td>
<td>0.002621</td>
<td>0.004396</td>
<td>0.126684</td>
<td>5</td>
<td>0.011673</td>
<td>-0.006431</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>CID_NB_TX_1DAY_WINDOW</td>
<td>0.001939</td>
<td>0.006042</td>
<td>0.256366</td>
<td>5</td>
<td>0.014380</td>
<td>-0.010502</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>TX_DURING_WEEKEND</td>
<td>0.001108</td>
<td>0.001839</td>
<td>0.124652</td>
<td>5</td>
<td>0.004894</td>
<td>-0.002679</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>TID_NB_TX_30DAY_WINDOW</td>
<td>0.000081</td>
<td>0.006248</td>
<td>0.489157</td>
<td>5</td>
<td>0.012946</td>
<td>-0.012785</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>TID_RISK_30DAY_WINDOW</td>
<td>-0.000109</td>
<td>0.000411</td>
<td>0.706661</td>
<td>5</td>
<td>0.000738</td>
<td>-0.000955</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>TID_NB_TX_7DAY_WINDOW</td>
<td>-0.000675</td>
<td>0.003043</td>
<td>0.677103</td>
<td>5</td>
<td>0.005590</td>
<td>-0.006941</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>TX_DURING_NIGHT</td>
<td>-0.001027</td>
<td>0.002791</td>
<td>0.771581</td>
<td>5</td>
<td>0.004719</td>
<td>-0.006773</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Generating PDP/ICE plots...
PDP/ICE for feature: CID_AVG_AMOUNT_30DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-4.png" id="interpret-best-model-2" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>PDP/ICE for feature: TX_AMOUNT</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-6.png" id="interpret-best-model-3" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>PDP/ICE for feature: TID_RISK_1DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-8.png" id="interpret-best-model-4" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>PDP/ICE for feature: CID_AVG_AMOUNT_7DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-10.png" id="interpret-best-model-5" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>PDP/ICE for feature: CID_AVG_AMOUNT_1DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-12.png" id="interpret-best-model-6" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Calculating SHAP values for summary plots...</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>SHAP Summary Plot (Beeswarm):</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-15.png" id="interpret-best-model-7" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>SHAP Feature Importance (Bar Plot based on mean absolute SHAP values):</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-17.png" id="interpret-best-model-8" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>SHAP Dependence Plots:
  Dependence plot for CID_AVG_AMOUNT_30DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-19.png" id="interpret-best-model-9" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Dependence plot for TX_AMOUNT</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-21.png" id="interpret-best-model-10" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Dependence plot for TID_RISK_1DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-23.png" id="interpret-best-model-11" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Dependence plot for CID_AVG_AMOUNT_7DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-25.png" id="interpret-best-model-12" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Dependence plot for CID_AVG_AMOUNT_1DAY_WINDOW</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Lab%2004_files/figure-html/interpret-best-model-output-27.png" id="interpret-best-model-13" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="key-conclusions-and-recommendations" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Key Conclusions and Recommendations</h1>
<p>This lab explored several common strategies for handling class imbalance in the context of credit card fraud detection. We compared: 1. Doing nothing (training on original imbalanced data). 2. Using a class-sensitive evaluation metric (PR-AUC / <code>average_precision</code>) for model selection. 3. Employing cost-sensitive learning via <code>sample_weight='balance_weight'</code>. 4. Applying class-based resampling (SMOTE) to the training data.</p>
<p><strong>Hypothetical Findings &amp; Discussion:</strong></p>
<p>(Students should replace this with their actual findings based on the lab execution. The following is a general discussion based on common outcomes in such scenarios.)</p>
<ul>
<li><p><strong>Strategy 1 (Do Nothing with ROC-AUC):</strong> While simple, relying solely on ROC-AUC for model selection in highly imbalanced scenarios can be misleading. The model might achieve a high ROC-AUC by correctly classifying the vast majority of legitimate transactions, yet still perform poorly on identifying fraud. The F1-score after threshold tuning is the more critical indicator here.</p></li>
<li><p><strong>Strategy 2 (PR-AUC Metric):</strong> Using PR-AUC (<code>average_precision</code>) as the primary evaluation metric often leads to models that are better at distinguishing the minority (fraud) class. This is because PR-AUC focuses on the trade-off between precision and recall, which is more relevant when the number of true negatives is very large. The F1-score obtained after threshold tuning on this model is usually a strong contender.</p></li>
<li><p><strong>Strategy 3 (Cost-Sensitive Learning with <code>balance_weight</code>):</strong> This approach directly tells the learning algorithm to pay more attention to the minority class by up-weighting its instances. It often yields good performance, comparable to or sometimes better than just using PR-AUC, especially in terms of recall for the fraud class. The <code>balance_weight</code> option in AutoGluon is a convenient way to implement this.</p></li>
<li><p><strong>Strategy 4 (SMOTE Resampling):</strong> While resampling techniques like SMOTE aim to provide the model with more minority examples, they come with significant caveats:</p>
<ul>
<li><strong>Probability Calibration:</strong> SMOTE (and other oversampling methods) almost invariably destroy the probability calibration of a model. The predicted probabilities from a model trained on SMOTE-d data often do not reflect the true likelihoods on the original, imbalanced data distribution. This was likely observed in the calibration plot for Strategy 4 before explicit recalibration.</li>
<li><strong>Recalibration Necessity:</strong> If using resampled data, an explicit probability recalibration step (e.g., using Isotonic Regression or Platt Scaling, often via <code>sklearn.calibration.CalibratedClassifierCV</code> applied to the <em>predictions</em> of the already trained model) is crucial if reliable probabilities are needed.</li>
<li><strong>Overfitting Risk:</strong> SMOTE can sometimes lead to overfitting if the synthetic samples do not generalize well or if the underlying minority class patterns are not distinct enough.</li>
<li><strong>Performance:</strong> In practice, despite the intuitive appeal, resampling methods like SMOTE do not always outperform strategies like using PR-AUC and/or cost-sensitive learning, especially when considering the F1-score on an unadulterated test set and the reliability of probabilities.</li>
</ul></li>
</ul>
<p><strong>General Recommendations:</strong></p>
<ol type="1">
<li><p><strong>Prioritize Class-Sensitive Metrics:</strong> For imbalanced fraud detection, always prioritize metrics like PR-AUC (<code>average_precision</code>), F1-score, precision, and recall over simple accuracy or ROC-AUC for final model assessment and selection. AutoGluon makes it easy to specify <code>eval_metric='average_precision'</code>.</p></li>
<li><p><strong>Consider Cost-Sensitive Learning:</strong> Techniques like <code>sample_weight='balance_weight'</code> are often effective and less prone to distorting probabilities compared to aggressive resampling. This is generally a robust approach.</p></li>
<li><p><strong>Be Cautious with Resampling:</strong> Do not manipulate training data (e.g., via RUS, ROS, SMOTE) solely because it is imbalanced or difficult to model. Such methods can introduce their own problems:</p>
<ul>
<li><strong>Loss of Information (RUS):</strong> Undersampling can discard valuable data from the majority class.</li>
<li><strong>Overfitting (ROS, SMOTE):</strong> Oversampling can lead to models that are too specific to the (potentially synthetic) minority samples.</li>
<li><strong>Destroyed Probability Calibration:</strong> This is a major issue, especially if the model outputs are used for more than just binary classification (e.g., risk scoring, estimating expected fraud rates).</li>
<li><strong>Increased Complexity:</strong> More complex pipelines can be harder to maintain, understand, and debug.</li>
</ul></li>
<li><p><strong>Probability Calibration is Crucial:</strong> If the models predicted probabilities are used for downstream tasks like estimating expected frauds per day, expected fraud value, or for any decision-making that relies on the magnitude of the probability (not just its rank), then accurate probability calibration is essential. Models trained on heavily resampled data often require a separate, explicit calibration step on a non-resampled tuning set.</p></li>
<li><p><strong>Threshold Tuning is Key:</strong> Regardless of the imbalance strategy, always use a dedicated tuning set to find an optimal decision threshold that aligns with business objectives (e.g., maximizing F1-score, or balancing precision and recall according to specific cost considerations).</p></li>
<li><p><strong>Domain Knowledge &amp; Feature Engineering:</strong> Robust feature engineering, informed by domain knowledge, often provides more significant and reliable gains than complex imbalance handling techniques alone.</p></li>
</ol>
<p><strong>Further Reading:</strong></p>
<p>For a deeper dive into practical fraud detection and the nuances of handling imbalanced data, students are highly encouraged to explore the <strong>Fraud Detection Handbook</strong>: <a href="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html" class="uri">https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html</a></p>
<p>This handbook provides extensive insights into various aspects of fraud detection, including data preprocessing, feature engineering, model selection, and dealing with challenges like class imbalance and concept drift.</p>
<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-leborgne2022fraud" class="csl-entry" role="listitem">
Le Borgne, Yann-Al, Wissam Siblini, Bertrand Lebichot, and Gianluca Bontempi. 2022. <em>Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook</em>. Universit<span></span> Libre de Bruxelles. <a href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook">https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb111" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb111-1"><a href="#cb111-1"></a><span class="co">---</span></span>
<span id="cb111-2"><a href="#cb111-2"></a><span class="an">title:</span><span class="co"> "Lab 04: Fraud Detection and Imbalanced Learning"</span></span>
<span id="cb111-3"><a href="#cb111-3"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb111-4"><a href="#cb111-4"></a><span class="co">    html:</span></span>
<span id="cb111-5"><a href="#cb111-5"></a><span class="co">        toc: true</span></span>
<span id="cb111-6"><a href="#cb111-6"></a><span class="co">        code-fold: true</span></span>
<span id="cb111-7"><a href="#cb111-7"></a><span class="co">        code-tools: true</span></span>
<span id="cb111-8"><a href="#cb111-8"></a><span class="co">        code-line-numbers: true</span></span>
<span id="cb111-9"><a href="#cb111-9"></a><span class="co">        page-layout: full</span></span>
<span id="cb111-10"><a href="#cb111-10"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb111-11"><a href="#cb111-11"></a><span class="an">number-figures:</span><span class="co"> true</span></span>
<span id="cb111-12"><a href="#cb111-12"></a><span class="an">number-tables:</span><span class="co"> true</span></span>
<span id="cb111-13"><a href="#cb111-13"></a><span class="an">execute:</span></span>
<span id="cb111-14"><a href="#cb111-14"></a><span class="co">    warning: false</span></span>
<span id="cb111-15"><a href="#cb111-15"></a><span class="co">    message: false</span></span>
<span id="cb111-16"><a href="#cb111-16"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb111-17"><a href="#cb111-17"></a><span class="co">---</span></span>
<span id="cb111-18"><a href="#cb111-18"></a></span>
<span id="cb111-19"><a href="#cb111-19"></a><span class="fu"># Overview</span></span>
<span id="cb111-20"><a href="#cb111-20"></a></span>
<span id="cb111-21"><a href="#cb111-21"></a>The lab explores Python libraries for handling large datasets, feature engineering, and strategies for addressing imbalanced data in fraud detection.</span>
<span id="cb111-22"><a href="#cb111-22"></a></span>
<span id="cb111-23"><a href="#cb111-23"></a><span class="fu"># Import Code</span></span>
<span id="cb111-24"><a href="#cb111-24"></a></span>
<span id="cb111-25"><a href="#cb111-25"></a>The chunks below include all necessary Python libraries and helper functions/classes that will be used in the lab. The helpers are adapted from previous labs.</span>
<span id="cb111-26"><a href="#cb111-26"></a></span>
<span id="cb111-29"><a href="#cb111-29"></a><span class="in">```{python}</span></span>
<span id="cb111-30"><a href="#cb111-30"></a><span class="co">#| label: setup-imports</span></span>
<span id="cb111-31"><a href="#cb111-31"></a></span>
<span id="cb111-32"><a href="#cb111-32"></a><span class="co"># System utilities</span></span>
<span id="cb111-33"><a href="#cb111-33"></a><span class="im">import</span> os</span>
<span id="cb111-34"><a href="#cb111-34"></a><span class="im">import</span> shutil</span>
<span id="cb111-35"><a href="#cb111-35"></a><span class="im">import</span> random</span>
<span id="cb111-36"><a href="#cb111-36"></a><span class="im">import</span> warnings</span>
<span id="cb111-37"><a href="#cb111-37"></a><span class="im">import</span> time</span>
<span id="cb111-38"><a href="#cb111-38"></a><span class="im">import</span> gc</span>
<span id="cb111-39"><a href="#cb111-39"></a><span class="im">import</span> psutil</span>
<span id="cb111-40"><a href="#cb111-40"></a><span class="im">import</span> glob <span class="co"># For finding files</span></span>
<span id="cb111-41"><a href="#cb111-41"></a><span class="im">import</span> time</span>
<span id="cb111-42"><a href="#cb111-42"></a></span>
<span id="cb111-43"><a href="#cb111-43"></a><span class="co"># Data manipulation and visualization</span></span>
<span id="cb111-44"><a href="#cb111-44"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb111-45"><a href="#cb111-45"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb111-46"><a href="#cb111-46"></a><span class="im">import</span> polars <span class="im">as</span> pl <span class="co"># Polars is a fast DataFrame library</span></span>
<span id="cb111-47"><a href="#cb111-47"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb111-48"><a href="#cb111-48"></a><span class="im">from</span> IPython.display <span class="im">import</span> display <span class="co"># Explicit import for display</span></span>
<span id="cb111-49"><a href="#cb111-49"></a><span class="im">import</span> re</span>
<span id="cb111-50"><a href="#cb111-50"></a><span class="im">import</span> duckdb</span>
<span id="cb111-51"><a href="#cb111-51"></a></span>
<span id="cb111-52"><a href="#cb111-52"></a><span class="co"># Machine learning - scikit-learn</span></span>
<span id="cb111-53"><a href="#cb111-53"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb111-54"><a href="#cb111-54"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression, LogisticRegressionCV</span>
<span id="cb111-55"><a href="#cb111-55"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, average_precision_score, f1_score, classification_report</span>
<span id="cb111-56"><a href="#cb111-56"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb111-57"><a href="#cb111-57"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> PartialDependenceDisplay</span>
<span id="cb111-58"><a href="#cb111-58"></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> CalibratedClassifierCV, CalibrationDisplay <span class="co"># Added for probability calibration</span></span>
<span id="cb111-59"><a href="#cb111-59"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, ClassifierMixin, TransformerMixin</span>
<span id="cb111-60"><a href="#cb111-60"></a><span class="im">from</span> sklearn.utils.validation <span class="im">import</span> check_is_fitted</span>
<span id="cb111-61"><a href="#cb111-61"></a><span class="im">from</span> sklearn <span class="im">import</span> set_config</span>
<span id="cb111-62"><a href="#cb111-62"></a></span>
<span id="cb111-63"><a href="#cb111-63"></a><span class="co"># Imbalanced-learn for resampling</span></span>
<span id="cb111-64"><a href="#cb111-64"></a><span class="im">from</span> imblearn.pipeline <span class="im">import</span> Pipeline <span class="im">as</span> ImbPipeline</span>
<span id="cb111-65"><a href="#cb111-65"></a><span class="im">from</span> imblearn.under_sampling <span class="im">import</span> RandomUnderSampler</span>
<span id="cb111-66"><a href="#cb111-66"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> RandomOverSampler, SMOTE</span>
<span id="cb111-67"><a href="#cb111-67"></a></span>
<span id="cb111-68"><a href="#cb111-68"></a><span class="co"># Specialized ML libraries</span></span>
<span id="cb111-69"><a href="#cb111-69"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor, TabularDataset</span>
<span id="cb111-70"><a href="#cb111-70"></a><span class="im">from</span> ydata_profiling <span class="im">import</span> ProfileReport</span>
<span id="cb111-71"><a href="#cb111-71"></a><span class="im">import</span> shap</span>
<span id="cb111-72"><a href="#cb111-72"></a><span class="im">import</span> dice_ml</span>
<span id="cb111-73"><a href="#cb111-73"></a><span class="im">from</span> dice_ml.utils <span class="im">import</span> helpers </span>
<span id="cb111-74"><a href="#cb111-74"></a><span class="im">import</span> torch</span>
<span id="cb111-75"><a href="#cb111-75"></a></span>
<span id="cb111-76"><a href="#cb111-76"></a><span class="co"># Settings</span></span>
<span id="cb111-77"><a href="#cb111-77"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="dv">50</span>)</span>
<span id="cb111-78"><a href="#cb111-78"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="dv">100</span>)</span>
<span id="cb111-79"><a href="#cb111-79"></a>warnings.filterwarnings(<span class="st">'ignore'</span>, category<span class="op">=</span><span class="pp">FutureWarning</span>) <span class="co"># Suppress specific FutureWarnings</span></span>
<span id="cb111-80"><a href="#cb111-80"></a>warnings.filterwarnings(<span class="st">'ignore'</span>, category<span class="op">=</span><span class="pp">UserWarning</span>) <span class="co"># Suppress some UserWarnings from libraries</span></span>
<span id="cb111-81"><a href="#cb111-81"></a>set_config(transform_output<span class="op">=</span><span class="st">"pandas"</span>) <span class="co"># Set sklearn output to pandas</span></span>
<span id="cb111-82"><a href="#cb111-82"></a><span class="in">```</span></span>
<span id="cb111-83"><a href="#cb111-83"></a></span>
<span id="cb111-86"><a href="#cb111-86"></a><span class="in">```{python}</span></span>
<span id="cb111-87"><a href="#cb111-87"></a><span class="co">#| label: setup-helpers</span></span>
<span id="cb111-88"><a href="#cb111-88"></a></span>
<span id="cb111-89"><a href="#cb111-89"></a><span class="co"># Helper Functions and Classes</span></span>
<span id="cb111-90"><a href="#cb111-90"></a></span>
<span id="cb111-91"><a href="#cb111-91"></a><span class="kw">def</span> global_set_seed(seed_value<span class="op">=</span><span class="dv">2025</span>):</span>
<span id="cb111-92"><a href="#cb111-92"></a>    <span class="co">"""Sets random seeds for reproducibility."""</span></span>
<span id="cb111-93"><a href="#cb111-93"></a>    random.seed(seed_value)</span>
<span id="cb111-94"><a href="#cb111-94"></a>    np.random.seed(seed_value)</span>
<span id="cb111-95"><a href="#cb111-95"></a>    torch.manual_seed(seed_value)</span>
<span id="cb111-96"><a href="#cb111-96"></a>    <span class="cf">if</span> dice_ml: <span class="co"># If dice_ml is imported, try to set its seed</span></span>
<span id="cb111-97"><a href="#cb111-97"></a>        <span class="cf">try</span>:</span>
<span id="cb111-98"><a href="#cb111-98"></a>            dice_ml.utils.helpers.set_random_seed(seed_value)</span>
<span id="cb111-99"><a href="#cb111-99"></a>        <span class="cf">except</span> <span class="pp">AttributeError</span>: <span class="co"># In case the function path changes</span></span>
<span id="cb111-100"><a href="#cb111-100"></a>            <span class="cf">pass</span></span>
<span id="cb111-101"><a href="#cb111-101"></a></span>
<span id="cb111-102"><a href="#cb111-102"></a></span>
<span id="cb111-103"><a href="#cb111-103"></a><span class="kw">def</span> remove_ag_folder(mdl_folder: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb111-104"><a href="#cb111-104"></a>    <span class="co">"""Removes the AutoGluon model folder if it exists."""</span></span>
<span id="cb111-105"><a href="#cb111-105"></a>    <span class="cf">if</span> os.path.exists(mdl_folder):</span>
<span id="cb111-106"><a href="#cb111-106"></a>        shutil.rmtree(mdl_folder)</span>
<span id="cb111-107"><a href="#cb111-107"></a>        <span class="bu">print</span>(<span class="ss">f"Removed existing AutoGluon folder: </span><span class="sc">{</span>mdl_folder<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-108"><a href="#cb111-108"></a></span>
<span id="cb111-109"><a href="#cb111-109"></a><span class="kw">class</span> AutoGluonSklearnWrapper(BaseEstimator, ClassifierMixin):</span>
<span id="cb111-110"><a href="#cb111-110"></a>    <span class="co">"""</span></span>
<span id="cb111-111"><a href="#cb111-111"></a><span class="co">    Scikit-learn compatible wrapper for AutoGluon TabularPredictor</span></span>
<span id="cb111-112"><a href="#cb111-112"></a><span class="co">    </span></span>
<span id="cb111-113"><a href="#cb111-113"></a><span class="co">    Inherits from scikit-learn's BaseEstimator and ClassifierMixin to provide</span></span>
<span id="cb111-114"><a href="#cb111-114"></a><span class="co">    full compatibility with scikit-learn tools like PartialDependenceDisplay().</span></span>
<span id="cb111-115"><a href="#cb111-115"></a><span class="co">    </span></span>
<span id="cb111-116"><a href="#cb111-116"></a><span class="co">    Parameters</span></span>
<span id="cb111-117"><a href="#cb111-117"></a><span class="co">    ----------</span></span>
<span id="cb111-118"><a href="#cb111-118"></a><span class="co">    label : str</span></span>
<span id="cb111-119"><a href="#cb111-119"></a><span class="co">        Name of the target column</span></span>
<span id="cb111-120"><a href="#cb111-120"></a></span>
<span id="cb111-121"><a href="#cb111-121"></a><span class="co">    **predictor_args : dict</span></span>
<span id="cb111-122"><a href="#cb111-122"></a><span class="co">        Additional arguments passed to TabularPredictor()</span></span>
<span id="cb111-123"><a href="#cb111-123"></a><span class="co">        (e.g., problem_type, eval_metric, path, sample_weight)</span></span>
<span id="cb111-124"><a href="#cb111-124"></a></span>
<span id="cb111-125"><a href="#cb111-125"></a><span class="co">    **fit_args : dict</span></span>
<span id="cb111-126"><a href="#cb111-126"></a><span class="co">        Additional arguments passed to TabularPredictor.fit() method</span></span>
<span id="cb111-127"><a href="#cb111-127"></a><span class="co">        (e.g., holdout_frac, presets, time_limit, excluded_model_types, hyperparameters)</span></span>
<span id="cb111-128"><a href="#cb111-128"></a></span>
<span id="cb111-129"><a href="#cb111-129"></a></span>
<span id="cb111-130"><a href="#cb111-130"></a><span class="co">    Attributes</span></span>
<span id="cb111-131"><a href="#cb111-131"></a><span class="co">    ----------</span></span>
<span id="cb111-132"><a href="#cb111-132"></a><span class="co">    predictor : TabularPredictor</span></span>
<span id="cb111-133"><a href="#cb111-133"></a><span class="co">        The trained AutoGluon predictor</span></span>
<span id="cb111-134"><a href="#cb111-134"></a></span>
<span id="cb111-135"><a href="#cb111-135"></a><span class="co">    classes_ : ndarray</span></span>
<span id="cb111-136"><a href="#cb111-136"></a><span class="co">        Class labels (for classification tasks)</span></span>
<span id="cb111-137"><a href="#cb111-137"></a></span>
<span id="cb111-138"><a href="#cb111-138"></a><span class="co">    n_features_in_ : int</span></span>
<span id="cb111-139"><a href="#cb111-139"></a><span class="co">        Number of features seen during fit</span></span>
<span id="cb111-140"><a href="#cb111-140"></a></span>
<span id="cb111-141"><a href="#cb111-141"></a><span class="co">    feature_names_ : list</span></span>
<span id="cb111-142"><a href="#cb111-142"></a><span class="co">        Feature names inferred during fitting</span></span>
<span id="cb111-143"><a href="#cb111-143"></a></span>
<span id="cb111-144"><a href="#cb111-144"></a><span class="co">    is_fitted_ : bool</span></span>
<span id="cb111-145"><a href="#cb111-145"></a><span class="co">        Whether the estimator has been fitted</span></span>
<span id="cb111-146"><a href="#cb111-146"></a><span class="co">    """</span></span>
<span id="cb111-147"><a href="#cb111-147"></a>    </span>
<span id="cb111-148"><a href="#cb111-148"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, label, predictor_args<span class="op">=</span><span class="va">None</span>, fit_args<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb111-149"><a href="#cb111-149"></a>        <span class="va">self</span>.label <span class="op">=</span> label</span>
<span id="cb111-150"><a href="#cb111-150"></a>        <span class="va">self</span>.predictor_args <span class="op">=</span> predictor_args <span class="cf">if</span> predictor_args <span class="cf">else</span> {}</span>
<span id="cb111-151"><a href="#cb111-151"></a>        <span class="va">self</span>.fit_args <span class="op">=</span> fit_args <span class="cf">if</span> fit_args <span class="cf">else</span> {}</span>
<span id="cb111-152"><a href="#cb111-152"></a>        <span class="va">self</span>.predictor <span class="op">=</span> <span class="va">None</span></span>
<span id="cb111-153"><a href="#cb111-153"></a>        <span class="va">self</span>.classes_ <span class="op">=</span> <span class="va">None</span></span>
<span id="cb111-154"><a href="#cb111-154"></a>        <span class="va">self</span>.n_features_in_ <span class="op">=</span> <span class="va">None</span></span>
<span id="cb111-155"><a href="#cb111-155"></a>        <span class="va">self</span>.feature_names_ <span class="op">=</span> <span class="va">None</span></span>
<span id="cb111-156"><a href="#cb111-156"></a>        <span class="va">self</span>.is_fitted_ <span class="op">=</span> <span class="va">False</span></span>
<span id="cb111-157"><a href="#cb111-157"></a></span>
<span id="cb111-158"><a href="#cb111-158"></a>    <span class="kw">def</span> __sklearn_is_fitted__(<span class="va">self</span>):</span>
<span id="cb111-159"><a href="#cb111-159"></a>        <span class="co">"""Official scikit-learn API for checking fitted status"""</span></span>
<span id="cb111-160"><a href="#cb111-160"></a>        <span class="cf">return</span> <span class="va">self</span>.is_fitted_</span>
<span id="cb111-161"><a href="#cb111-161"></a></span>
<span id="cb111-162"><a href="#cb111-162"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y, sample_weight<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb111-163"><a href="#cb111-163"></a>        <span class="co">"""</span></span>
<span id="cb111-164"><a href="#cb111-164"></a><span class="co">        Fit AutoGluon model using scikit-learn interface.</span></span>
<span id="cb111-165"><a href="#cb111-165"></a><span class="co">        If sample_weight is provided directly to fit, it's used if 'sample_weight' </span></span>
<span id="cb111-166"><a href="#cb111-166"></a><span class="co">        is also specified in predictor_args.</span></span>
<span id="cb111-167"><a href="#cb111-167"></a><span class="co">        """</span></span>
<span id="cb111-168"><a href="#cb111-168"></a>        <span class="va">self</span>._check_feature_names(X, reset<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb111-169"><a href="#cb111-169"></a>        <span class="va">self</span>._check_n_features(X, reset<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb111-170"><a href="#cb111-170"></a></span>
<span id="cb111-171"><a href="#cb111-171"></a>        train_data_df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span><span class="va">self</span>.feature_names_)</span>
<span id="cb111-172"><a href="#cb111-172"></a>        train_data_df[<span class="va">self</span>.label] <span class="op">=</span> y</span>
<span id="cb111-173"><a href="#cb111-173"></a></span>
<span id="cb111-174"><a href="#cb111-174"></a>        ag_weight_col_name <span class="op">=</span> <span class="va">self</span>.predictor_args.get(<span class="st">'sample_weight'</span>, <span class="va">None</span>)</span>
<span id="cb111-175"><a href="#cb111-175"></a></span>
<span id="cb111-176"><a href="#cb111-176"></a>        <span class="cf">if</span> sample_weight <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb111-177"><a href="#cb111-177"></a>            <span class="cf">if</span> ag_weight_col_name:</span>
<span id="cb111-178"><a href="#cb111-178"></a>                train_data_df[ag_weight_col_name] <span class="op">=</span> sample_weight</span>
<span id="cb111-179"><a href="#cb111-179"></a>            <span class="cf">else</span>:</span>
<span id="cb111-180"><a href="#cb111-180"></a>                default_sw_col <span class="op">=</span> <span class="st">'autogluon_sample_weight_fit'</span></span>
<span id="cb111-181"><a href="#cb111-181"></a>                train_data_df[default_sw_col] <span class="op">=</span> sample_weight</span>
<span id="cb111-182"><a href="#cb111-182"></a>                <span class="va">self</span>.predictor_args[<span class="st">'sample_weight'</span>] <span class="op">=</span> default_sw_col</span>
<span id="cb111-183"><a href="#cb111-183"></a>                <span class="bu">print</span>(<span class="ss">f"Warning: sample_weight passed to fit() but 'sample_weight' not in predictor_args. "</span></span>
<span id="cb111-184"><a href="#cb111-184"></a>                      <span class="ss">f"Using '</span><span class="sc">{</span>default_sw_col<span class="sc">}</span><span class="ss">' as weight column for AutoGluon."</span>)</span>
<span id="cb111-185"><a href="#cb111-185"></a>        <span class="cf">elif</span> ag_weight_col_name <span class="kw">and</span> ag_weight_col_name <span class="kw">not</span> <span class="kw">in</span> train_data_df.columns <span class="kw">and</span> ag_weight_col_name <span class="op">!=</span> <span class="st">"balance_weight"</span>:</span>
<span id="cb111-186"><a href="#cb111-186"></a>            <span class="co"># If predictor_args has a specific column name for weights, and it's not in X, and not 'balance_weight'</span></span>
<span id="cb111-187"><a href="#cb111-187"></a>             <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"sample_weight column '</span><span class="sc">{</span>ag_weight_col_name<span class="sc">}</span><span class="ss">' specified in predictor_args but not found in X."</span>)</span>
<span id="cb111-188"><a href="#cb111-188"></a></span>
<span id="cb111-189"><a href="#cb111-189"></a>        train_data <span class="op">=</span> TabularDataset(train_data_df)</span>
<span id="cb111-190"><a href="#cb111-190"></a>        </span>
<span id="cb111-191"><a href="#cb111-191"></a>        current_fit_args <span class="op">=</span> <span class="va">self</span>.fit_args.copy()</span>
<span id="cb111-192"><a href="#cb111-192"></a>        <span class="co"># AutoGluon's .fit() doesn't take sample_weight as a direct argument.</span></span>
<span id="cb111-193"><a href="#cb111-193"></a>        <span class="co"># It's handled if 'sample_weight' (column name or 'balance_weight') is in predictor_args (passed to TabularPredictor constructor)</span></span>
<span id="cb111-194"><a href="#cb111-194"></a>        <span class="co"># or if a column with that name exists in the training data.</span></span>
<span id="cb111-195"><a href="#cb111-195"></a>        <span class="cf">if</span> <span class="st">'sample_weight'</span> <span class="kw">in</span> current_fit_args:</span>
<span id="cb111-196"><a href="#cb111-196"></a>            <span class="kw">del</span> current_fit_args[<span class="st">'sample_weight'</span>] </span>
<span id="cb111-197"><a href="#cb111-197"></a></span>
<span id="cb111-198"><a href="#cb111-198"></a>        <span class="va">self</span>.predictor <span class="op">=</span> TabularPredictor(</span>
<span id="cb111-199"><a href="#cb111-199"></a>            label<span class="op">=</span><span class="va">self</span>.label, </span>
<span id="cb111-200"><a href="#cb111-200"></a>            <span class="op">**</span><span class="va">self</span>.predictor_args</span>
<span id="cb111-201"><a href="#cb111-201"></a>        ).fit(train_data, <span class="op">**</span>current_fit_args)</span>
<span id="cb111-202"><a href="#cb111-202"></a>        </span>
<span id="cb111-203"><a href="#cb111-203"></a>        <span class="cf">if</span> <span class="va">self</span>.predictor.problem_type <span class="kw">in</span> [<span class="st">'binary'</span>, <span class="st">'multiclass'</span>]:</span>
<span id="cb111-204"><a href="#cb111-204"></a>            <span class="va">self</span>.classes_ <span class="op">=</span> np.array(<span class="va">self</span>.predictor.class_labels)</span>
<span id="cb111-205"><a href="#cb111-205"></a>            </span>
<span id="cb111-206"><a href="#cb111-206"></a>        <span class="va">self</span>.is_fitted_ <span class="op">=</span> <span class="va">True</span></span>
<span id="cb111-207"><a href="#cb111-207"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb111-208"><a href="#cb111-208"></a></span>
<span id="cb111-209"><a href="#cb111-209"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb111-210"><a href="#cb111-210"></a>        check_is_fitted(<span class="va">self</span>)</span>
<span id="cb111-211"><a href="#cb111-211"></a>        <span class="co"># Convert X to pandas DataFrame if it's Polars, as AG expects pandas for predict</span></span>
<span id="cb111-212"><a href="#cb111-212"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb111-213"><a href="#cb111-213"></a>            X_pd <span class="op">=</span> X.to_pandas()</span>
<span id="cb111-214"><a href="#cb111-214"></a>        <span class="cf">else</span>:</span>
<span id="cb111-215"><a href="#cb111-215"></a>            X_pd <span class="op">=</span> X</span>
<span id="cb111-216"><a href="#cb111-216"></a>        <span class="va">self</span>._check_feature_names(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-217"><a href="#cb111-217"></a>        <span class="va">self</span>._check_n_features(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-218"><a href="#cb111-218"></a></span>
<span id="cb111-219"><a href="#cb111-219"></a>        df <span class="op">=</span> pd.DataFrame(X_pd, columns<span class="op">=</span><span class="va">self</span>.feature_names_)</span>
<span id="cb111-220"><a href="#cb111-220"></a>        df <span class="op">=</span> TabularDataset(df)</span>
<span id="cb111-221"><a href="#cb111-221"></a>        <span class="cf">return</span> <span class="va">self</span>.predictor.predict(df).values</span>
<span id="cb111-222"><a href="#cb111-222"></a></span>
<span id="cb111-223"><a href="#cb111-223"></a>    <span class="kw">def</span> predict_proba(<span class="va">self</span>, X):</span>
<span id="cb111-224"><a href="#cb111-224"></a>        check_is_fitted(<span class="va">self</span>)</span>
<span id="cb111-225"><a href="#cb111-225"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb111-226"><a href="#cb111-226"></a>            X_pd <span class="op">=</span> X.to_pandas()</span>
<span id="cb111-227"><a href="#cb111-227"></a>        <span class="cf">else</span>:</span>
<span id="cb111-228"><a href="#cb111-228"></a>            X_pd <span class="op">=</span> X</span>
<span id="cb111-229"><a href="#cb111-229"></a>        <span class="va">self</span>._check_feature_names(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-230"><a href="#cb111-230"></a>        <span class="va">self</span>._check_n_features(X_pd, reset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-231"><a href="#cb111-231"></a>        </span>
<span id="cb111-232"><a href="#cb111-232"></a>        df <span class="op">=</span> pd.DataFrame(X_pd, columns<span class="op">=</span><span class="va">self</span>.feature_names_)</span>
<span id="cb111-233"><a href="#cb111-233"></a>        df <span class="op">=</span> TabularDataset(df)</span>
<span id="cb111-234"><a href="#cb111-234"></a>        <span class="cf">return</span> <span class="va">self</span>.predictor.predict_proba(df).values</span>
<span id="cb111-235"><a href="#cb111-235"></a></span>
<span id="cb111-236"><a href="#cb111-236"></a>    <span class="kw">def</span> get_params(<span class="va">self</span>, deep<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb111-237"><a href="#cb111-237"></a>        <span class="cf">return</span> {</span>
<span id="cb111-238"><a href="#cb111-238"></a>            <span class="st">'label'</span>: <span class="va">self</span>.label,</span>
<span id="cb111-239"><a href="#cb111-239"></a>            <span class="st">'predictor_args'</span>: <span class="va">self</span>.predictor_args,</span>
<span id="cb111-240"><a href="#cb111-240"></a>            <span class="st">'fit_args'</span>: <span class="va">self</span>.fit_args</span>
<span id="cb111-241"><a href="#cb111-241"></a>        }</span>
<span id="cb111-242"><a href="#cb111-242"></a></span>
<span id="cb111-243"><a href="#cb111-243"></a>    <span class="kw">def</span> set_params(<span class="va">self</span>, <span class="op">**</span>params):</span>
<span id="cb111-244"><a href="#cb111-244"></a>        <span class="cf">for</span> param, value <span class="kw">in</span> params.items():</span>
<span id="cb111-245"><a href="#cb111-245"></a>            <span class="cf">if</span> param <span class="op">==</span> <span class="st">'label'</span>:</span>
<span id="cb111-246"><a href="#cb111-246"></a>                <span class="va">self</span>.label <span class="op">=</span> value</span>
<span id="cb111-247"><a href="#cb111-247"></a>            <span class="cf">elif</span> param <span class="op">==</span> <span class="st">'predictor_args'</span>:</span>
<span id="cb111-248"><a href="#cb111-248"></a>                <span class="va">self</span>.predictor_args <span class="op">=</span> value</span>
<span id="cb111-249"><a href="#cb111-249"></a>            <span class="cf">elif</span> param <span class="op">==</span> <span class="st">'fit_args'</span>:</span>
<span id="cb111-250"><a href="#cb111-250"></a>                <span class="va">self</span>.fit_args <span class="op">=</span> value</span>
<span id="cb111-251"><a href="#cb111-251"></a>            <span class="cf">else</span>:</span>
<span id="cb111-252"><a href="#cb111-252"></a>                <span class="cf">if</span> <span class="st">'.'</span> <span class="kw">in</span> param:</span>
<span id="cb111-253"><a href="#cb111-253"></a>                    <span class="co"># Handle nested params like predictor_args.eval_metric</span></span>
<span id="cb111-254"><a href="#cb111-254"></a>                    main_key, sub_key <span class="op">=</span> param.split(<span class="st">'.'</span>, <span class="dv">1</span>)</span>
<span id="cb111-255"><a href="#cb111-255"></a>                    <span class="cf">if</span> main_key <span class="op">==</span> <span class="st">'predictor_args'</span> <span class="kw">and</span> <span class="bu">isinstance</span>(<span class="va">self</span>.predictor_args, <span class="bu">dict</span>):</span>
<span id="cb111-256"><a href="#cb111-256"></a>                        <span class="va">self</span>.predictor_args[sub_key] <span class="op">=</span> value</span>
<span id="cb111-257"><a href="#cb111-257"></a>                    <span class="cf">elif</span> main_key <span class="op">==</span> <span class="st">'fit_args'</span> <span class="kw">and</span> <span class="bu">isinstance</span>(<span class="va">self</span>.fit_args, <span class="bu">dict</span>):</span>
<span id="cb111-258"><a href="#cb111-258"></a>                        <span class="va">self</span>.fit_args[sub_key] <span class="op">=</span> value</span>
<span id="cb111-259"><a href="#cb111-259"></a>                    <span class="cf">else</span>:</span>
<span id="cb111-260"><a href="#cb111-260"></a>                        <span class="bu">setattr</span>(<span class="va">self</span>, param, value)</span>
<span id="cb111-261"><a href="#cb111-261"></a>                <span class="cf">else</span>:</span>
<span id="cb111-262"><a href="#cb111-262"></a>                    <span class="bu">setattr</span>(<span class="va">self</span>, param, value)</span>
<span id="cb111-263"><a href="#cb111-263"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb111-264"><a href="#cb111-264"></a>        </span>
<span id="cb111-265"><a href="#cb111-265"></a>    <span class="kw">def</span> _check_n_features(<span class="va">self</span>, X, reset<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb111-266"><a href="#cb111-266"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pd.DataFrame):</span>
<span id="cb111-267"><a href="#cb111-267"></a>            n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb111-268"><a href="#cb111-268"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, np.ndarray):</span>
<span id="cb111-269"><a href="#cb111-269"></a>            n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb111-270"><a href="#cb111-270"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb111-271"><a href="#cb111-271"></a>            n_features <span class="op">=</span> X.width </span>
<span id="cb111-272"><a href="#cb111-272"></a>        <span class="cf">else</span>:</span>
<span id="cb111-273"><a href="#cb111-273"></a>            <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="ss">f"Input X type </span><span class="sc">{</span><span class="bu">type</span>(X)<span class="sc">}</span><span class="ss"> not supported for _check_n_features."</span>)</span>
<span id="cb111-274"><a href="#cb111-274"></a>            </span>
<span id="cb111-275"><a href="#cb111-275"></a>        <span class="cf">if</span> reset:</span>
<span id="cb111-276"><a href="#cb111-276"></a>            <span class="va">self</span>.n_features_in_ <span class="op">=</span> n_features</span>
<span id="cb111-277"><a href="#cb111-277"></a>        <span class="cf">elif</span> n_features <span class="op">!=</span> <span class="va">self</span>.n_features_in_:</span>
<span id="cb111-278"><a href="#cb111-278"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Expected </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>n_features_in_<span class="sc">}</span><span class="ss"> features, got </span><span class="sc">{</span>n_features<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-279"><a href="#cb111-279"></a></span>
<span id="cb111-280"><a href="#cb111-280"></a>    <span class="kw">def</span> _check_feature_names(<span class="va">self</span>, X, reset<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb111-281"><a href="#cb111-281"></a>        current_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb111-282"><a href="#cb111-282"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(X, pd.DataFrame):</span>
<span id="cb111-283"><a href="#cb111-283"></a>            current_feature_names <span class="op">=</span> X.columns.tolist()</span>
<span id="cb111-284"><a href="#cb111-284"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, pl.DataFrame):</span>
<span id="cb111-285"><a href="#cb111-285"></a>            current_feature_names <span class="op">=</span> X.columns <span class="co"># Polars columns are already a list of strings</span></span>
<span id="cb111-286"><a href="#cb111-286"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(X, np.ndarray) <span class="kw">and</span> reset: <span class="co"># Only generate for np.ndarray if resetting names</span></span>
<span id="cb111-287"><a href="#cb111-287"></a>            current_feature_names <span class="op">=</span> [<span class="ss">f'feat_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb111-288"><a href="#cb111-288"></a>        <span class="cf">elif</span> <span class="kw">not</span> reset <span class="kw">and</span> <span class="bu">isinstance</span>(X, np.ndarray):</span>
<span id="cb111-289"><a href="#cb111-289"></a>             <span class="co"># If not resetting and X is numpy, assume feature order matches self.feature_names_</span></span>
<span id="cb111-290"><a href="#cb111-290"></a>            <span class="co"># No explicit name check possible here other than count (done in _check_n_features)</span></span>
<span id="cb111-291"><a href="#cb111-291"></a>            <span class="cf">return</span> </span>
<span id="cb111-292"><a href="#cb111-292"></a>        <span class="cf">else</span>:</span>
<span id="cb111-293"><a href="#cb111-293"></a>            <span class="cf">raise</span> <span class="pp">TypeError</span>(<span class="ss">f"Input X type </span><span class="sc">{</span><span class="bu">type</span>(X)<span class="sc">}</span><span class="ss"> not supported for _check_feature_names."</span>)</span>
<span id="cb111-294"><a href="#cb111-294"></a></span>
<span id="cb111-295"><a href="#cb111-295"></a>        <span class="cf">if</span> reset:</span>
<span id="cb111-296"><a href="#cb111-296"></a>            <span class="va">self</span>.feature_names_ <span class="op">=</span> current_feature_names</span>
<span id="cb111-297"><a href="#cb111-297"></a>        <span class="cf">elif</span> current_feature_names <span class="op">!=</span> <span class="va">self</span>.feature_names_:</span>
<span id="cb111-298"><a href="#cb111-298"></a>            <span class="co"># More informative error message for mismatch</span></span>
<span id="cb111-299"><a href="#cb111-299"></a>            msg <span class="op">=</span> <span class="ss">f"Feature names mismatch. Expected: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>feature_names_<span class="sc">}</span><span class="ss">. Got: </span><span class="sc">{</span>current_feature_names<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb111-300"><a href="#cb111-300"></a>            <span class="co"># Find differences for clarity</span></span>
<span id="cb111-301"><a href="#cb111-301"></a>            expected_set <span class="op">=</span> <span class="bu">set</span>(<span class="va">self</span>.feature_names_)</span>
<span id="cb111-302"><a href="#cb111-302"></a>            got_set <span class="op">=</span> <span class="bu">set</span>(current_feature_names)</span>
<span id="cb111-303"><a href="#cb111-303"></a>            <span class="cf">if</span> <span class="bu">len</span>(expected_set) <span class="op">!=</span> <span class="bu">len</span>(<span class="va">self</span>.feature_names_) <span class="kw">or</span> <span class="bu">len</span>(got_set) <span class="op">!=</span> <span class="bu">len</span>(current_feature_names):</span>
<span id="cb111-304"><a href="#cb111-304"></a>                msg <span class="op">+=</span> <span class="st">" (Note: Duplicate feature names might be an issue)"</span></span>
<span id="cb111-305"><a href="#cb111-305"></a>            <span class="cf">if</span> expected_set <span class="op">-</span> got_set:</span>
<span id="cb111-306"><a href="#cb111-306"></a>                msg <span class="op">+=</span> <span class="ss">f" Missing expected features: </span><span class="sc">{</span>expected_set <span class="op">-</span> got_set<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb111-307"><a href="#cb111-307"></a>            <span class="cf">if</span> got_set <span class="op">-</span> expected_set:</span>
<span id="cb111-308"><a href="#cb111-308"></a>                msg <span class="op">+=</span> <span class="ss">f" Unexpected features provided: </span><span class="sc">{</span>got_set <span class="op">-</span> expected_set<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb111-309"><a href="#cb111-309"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(msg)</span>
<span id="cb111-310"><a href="#cb111-310"></a></span>
<span id="cb111-311"><a href="#cb111-311"></a></span>
<span id="cb111-312"><a href="#cb111-312"></a><span class="co"># Initialize global seed</span></span>
<span id="cb111-313"><a href="#cb111-313"></a>global_set_seed(<span class="dv">2025</span>)</span>
<span id="cb111-314"><a href="#cb111-314"></a></span>
<span id="cb111-315"><a href="#cb111-315"></a><span class="in">```</span></span>
<span id="cb111-316"><a href="#cb111-316"></a></span>
<span id="cb111-317"><a href="#cb111-317"></a><span class="fu"># Credit Card Fraud Detection</span></span>
<span id="cb111-318"><a href="#cb111-318"></a></span>
<span id="cb111-319"><a href="#cb111-319"></a>Credit card fraud is a significant concern for financial institutions, merchants, and consumers. Understanding the types of fraud and how detection systems operate is crucial for developing effective machine learning models.</span>
<span id="cb111-320"><a href="#cb111-320"></a></span>
<span id="cb111-321"><a href="#cb111-321"></a><span class="fu">## Card-present frauds</span></span>
<span id="cb111-322"><a href="#cb111-322"></a></span>
<span id="cb111-323"><a href="#cb111-323"></a><span class="ss">-   </span>Card-present (CP) fraud occurs when a transaction is made using a **physical credit card** that has been lost, stolen, counterfeited, or intercepted.</span>
<span id="cb111-324"><a href="#cb111-324"></a><span class="ss">-   </span>The legitimate cardholder is typically unaware of the fraudulent use until they notice unauthorized transactions on their statement or are alerted by their bank.</span>
<span id="cb111-325"><a href="#cb111-325"></a><span class="ss">-   </span>The key characteristic of CP fraud is that the **physical card** is used at the point of sale (e.g., a retail store, restaurant).</span>
<span id="cb111-326"><a href="#cb111-326"></a></span>
<span id="cb111-327"><a href="#cb111-327"></a><span class="fu">## Card-not-present frauds</span></span>
<span id="cb111-328"><a href="#cb111-328"></a></span>
<span id="cb111-329"><a href="#cb111-329"></a><span class="ss">-   </span>Card-not-present (CNP) fraud occurs when credit card information (such as card number, expiry date, CVV) is used **without** the physical card being present.</span>
<span id="cb111-330"><a href="#cb111-330"></a><span class="ss">-   </span>This type of fraud is common in online purchases.</span>
<span id="cb111-331"><a href="#cb111-331"></a><span class="ss">-   </span>Fraudsters may obtain card details through data breaches, phishing scams, or malware.</span>
<span id="cb111-332"><a href="#cb111-332"></a><span class="ss">-   </span>CNP fraud has become increasingly prevalent with the growth of e-commerce.</span>
<span id="cb111-333"><a href="#cb111-333"></a></span>
<span id="cb111-334"><a href="#cb111-334"></a><span class="fu">## Credit Card Fraud Detection Systems (CCFDS)</span></span>
<span id="cb111-335"><a href="#cb111-335"></a></span>
<span id="cb111-336"><a href="#cb111-336"></a><span class="ss">-   </span>**Credit Card Fraud Detection Systems (CCFDS)** are designed to identify and prevent fraudulent transactions in real-time or near real-time by analyzing transaction data (e.g., amount, location, time, customer behavior, terminal ID) using rules and machine learning models.</span>
<span id="cb111-337"><a href="#cb111-337"></a><span class="ss">-   </span>If a transaction is flagged as potentially fraudulent, the system may block the transaction, alert the cardholder (e.g., via SMS or app notification), or refer the case to human fraud analysts for review.</span>
<span id="cb111-338"><a href="#cb111-338"></a><span class="ss">-   </span>The primary goal of a CCFDS is to minimize financial losses from fraud while also reducing false positives (legitimate transactions incorrectly blocked), which can negatively impact customer experience.</span>
<span id="cb111-339"><a href="#cb111-339"></a><span class="ss">-   </span>CCFDS must balance detection accuracy, speed, and customer convenience, often operating under strict latency requirements to avoid disrupting normal transaction flows.</span>
<span id="cb111-340"><a href="#cb111-340"></a></span>
<span id="cb111-341"><a href="#cb111-341"></a><span class="fu">## Class Imbalance in Fraud Detection</span></span>
<span id="cb111-342"><a href="#cb111-342"></a></span>
<span id="cb111-343"><a href="#cb111-343"></a>Class imbalance occurs when one class (e.g., fraudulent transactions) is significantly smaller compared to another class (e.g., legitimate transactions).</span>
<span id="cb111-344"><a href="#cb111-344"></a></span>
<span id="cb111-345"><a href="#cb111-345"></a>**Characteristics in Fraud Data**</span>
<span id="cb111-346"><a href="#cb111-346"></a></span>
<span id="cb111-347"><a href="#cb111-347"></a><span class="ss">-   </span>Rarity of Fraud: Fraudulent transactions are typically a small fraction (often $&lt; 1\%$, sometimes $&lt; 0.1\%$) of total transactions.</span>
<span id="cb111-348"><a href="#cb111-348"></a></span>
<span id="cb111-349"><a href="#cb111-349"></a><span class="ss">-   </span>Standard accuracy can be misleading; a naive model predicting "no fraud" for all transactions might appear highly accurate.</span>
<span id="cb111-350"><a href="#cb111-350"></a></span>
<span id="cb111-351"><a href="#cb111-351"></a>**Impact of Sample Size**</span>
<span id="cb111-352"><a href="#cb111-352"></a></span>
<span id="cb111-353"><a href="#cb111-353"></a>The difficulty of modeling depends on both the imbalance ratio (IR) and the absolute number of samples in the minority class (fraud) .</span>
<span id="cb111-354"><a href="#cb111-354"></a></span>
<span id="cb111-355"><a href="#cb111-355"></a>A higher imbalance ratio (IR) indicates greater class imbalance: $$IR = \frac{\text{Number of samples in majority class}}{\text{Number of samples in minority class}}$$</span>
<span id="cb111-356"><a href="#cb111-356"></a></span>
<span id="cb111-357"><a href="#cb111-357"></a>The absolute number of samples in the minority class (fraud) also matters:</span>
<span id="cb111-358"><a href="#cb111-358"></a></span>
<span id="cb111-359"><a href="#cb111-359"></a><span class="ss">-   </span>**Large Datasets:** A low fraud rate (e.g., 0.1%) in a large dataset (e.g., 100 million transactions) can still yield enough fraud examples (e.g., 100,000) for effective modeling training and testing.</span>
<span id="cb111-360"><a href="#cb111-360"></a></span>
<span id="cb111-361"><a href="#cb111-361"></a><span class="ss">-   </span>**Small Datasets:** The same low fraud rate in a small dataset (e.g., 1,000 transactions) results in too few fraud examples (e.g., 1) for reliable model training and testing.</span>
<span id="cb111-362"><a href="#cb111-362"></a></span>
<span id="cb111-363"><a href="#cb111-363"></a>The lab assumes large imbalanced data sets.</span>
<span id="cb111-364"><a href="#cb111-364"></a></span>
<span id="cb111-365"><a href="#cb111-365"></a><span class="fu"># Dealing with Class Imbalance</span></span>
<span id="cb111-366"><a href="#cb111-366"></a></span>
<span id="cb111-367"><a href="#cb111-367"></a>Several strategies can be employed to mitigate the effects of class imbalance when training fraud detection models. The choice of strategy can significantly impact model performance and its real-world effectiveness.</span>
<span id="cb111-368"><a href="#cb111-368"></a></span>
<span id="cb111-369"><a href="#cb111-369"></a><span class="fu">## Do-Nothing Approach</span></span>
<span id="cb111-370"><a href="#cb111-370"></a></span>
<span id="cb111-371"><a href="#cb111-371"></a>**Rationale:**</span>
<span id="cb111-372"><a href="#cb111-372"></a></span>
<span id="cb111-373"><a href="#cb111-373"></a><span class="ss">-   </span>Class imbalance is an inherent characteristic of the data that reflects the true state of the world</span>
<span id="cb111-374"><a href="#cb111-374"></a><span class="ss">-   </span>Modifying the data (e.g., through resampling) distorts reality</span>
<span id="cb111-375"><a href="#cb111-375"></a><span class="ss">-   </span>Many modern machine learning estimators are relatively insensitive to class imbalance if configured and evaluated appropriately, including:</span>
<span id="cb111-376"><a href="#cb111-376"></a><span class="ss">    -   </span>Tree-based ensembles (LightGBM, XGBoost, CatBoost)</span>
<span id="cb111-377"><a href="#cb111-377"></a><span class="ss">    -   </span>Neural networks</span>
<span id="cb111-378"><a href="#cb111-378"></a><span class="ss">-   </span>Under the do-nothing approach, class imbalance is a "key feature" of the data rather than a bug/defect that needs to be fixed.</span>
<span id="cb111-379"><a href="#cb111-379"></a></span>
<span id="cb111-380"><a href="#cb111-380"></a>**Process:**</span>
<span id="cb111-381"><a href="#cb111-381"></a></span>
<span id="cb111-382"><a href="#cb111-382"></a><span class="ss">1.  </span>Train multiple estimators on the original, imbalanced dataset.</span>
<span id="cb111-383"><a href="#cb111-383"></a></span>
<span id="cb111-384"><a href="#cb111-384"></a><span class="ss">2.  </span>Select the best model with the lowest **log loss** on the test set.</span>
<span id="cb111-385"><a href="#cb111-385"></a></span>
<span id="cb111-386"><a href="#cb111-386"></a><span class="ss">3.  </span>Check for proper probability calibration (i.e., how well aligned are the predicted probabilities to the observed frequencies of fraud). Calibrate the predicted probabilities if needed.</span>
<span id="cb111-387"><a href="#cb111-387"></a></span>
<span id="cb111-388"><a href="#cb111-388"></a><span class="ss">4.  </span>Select the optimal decision threshold.</span>
<span id="cb111-389"><a href="#cb111-389"></a></span>
<span id="cb111-390"><a href="#cb111-390"></a><span class="ss">5.  </span>Evaluate the performance of the calibrated model and the optimal threshold on the test set.</span>
<span id="cb111-391"><a href="#cb111-391"></a></span>
<span id="cb111-392"><a href="#cb111-392"></a><span class="fu">## Class-Sensitive Evaluation Approach</span></span>
<span id="cb111-393"><a href="#cb111-393"></a></span>
<span id="cb111-394"><a href="#cb111-394"></a>**Rationale:**</span>
<span id="cb111-395"><a href="#cb111-395"></a></span>
<span id="cb111-396"><a href="#cb111-396"></a><span class="ss">-   </span>In fraud detection, the positive class (fraud) is much rarer than the negative class (legitimate transactions).</span>
<span id="cb111-397"><a href="#cb111-397"></a><span class="ss">-   </span>**ROC-AUC** is a very common binary classification metric (the gold standard), but it can be misleading when classes are highly imbalanced:</span>
<span id="cb111-398"><a href="#cb111-398"></a><span class="ss">    -   </span>ROC plots the True Positive Rate (also known as TPR, recall, sensitivity, or gain) against the False Positive Rate (FPR) at different decision thresholds.</span>
<span id="cb111-399"><a href="#cb111-399"></a><span class="ss">    -   </span>The FPR denominator is huge (all legitimate transactions), so even many false positives may not increase the FPR much, making the ROC-AUC look artificially good.</span>
<span id="cb111-400"><a href="#cb111-400"></a><span class="ss">    -   </span>Because there are so many legitimate transactions, even a model that misses many frauds (low recall) can still achieve a decent ROC-AUC if the model correctly classifies most legitimate transactions (true negatives).</span>
<span id="cb111-401"><a href="#cb111-401"></a><span class="ss">-   </span>**Precision-Recall (PR) curves** are more informative for imbalanced data:</span>
<span id="cb111-402"><a href="#cb111-402"></a><span class="ss">    -   </span>The PR curve plots Precision (the proportion of predicted frauds that are actually fraud) against Recall (the proportion of actual frauds that are detected).</span>
<span id="cb111-403"><a href="#cb111-403"></a><span class="ss">    -   </span>A model with high precision is desirable to minimize false alarms (which flag legitimate transactions as fraud).</span>
<span id="cb111-404"><a href="#cb111-404"></a><span class="ss">-   </span>**PR-AUC** (Area Under the PR Curve, also called Average Precision or AP) summarizes the PR curve in a single number.</span>
<span id="cb111-405"><a href="#cb111-405"></a><span class="ss">    -   </span>A high PR-AUC means the model can achieve both high precision and high recall for fraud.</span>
<span id="cb111-406"><a href="#cb111-406"></a><span class="ss">    -   </span>PR-AUC removes the effect of true negatives and focuses on the positive class (fraud).</span>
<span id="cb111-407"><a href="#cb111-407"></a></span>
<span id="cb111-408"><a href="#cb111-408"></a>**Process:**</span>
<span id="cb111-409"><a href="#cb111-409"></a></span>
<span id="cb111-410"><a href="#cb111-410"></a><span class="ss">1.  </span>Train multiple estimators on the original, imbalanced dataset.</span>
<span id="cb111-411"><a href="#cb111-411"></a></span>
<span id="cb111-412"><a href="#cb111-412"></a><span class="ss">2.  </span>Select the best model with the highest **average precision** on the test set.</span>
<span id="cb111-413"><a href="#cb111-413"></a></span>
<span id="cb111-414"><a href="#cb111-414"></a><span class="ss">3.  </span>Check for proper probability calibration. Calibrate the predicted probabilities if needed.</span>
<span id="cb111-415"><a href="#cb111-415"></a></span>
<span id="cb111-416"><a href="#cb111-416"></a><span class="ss">4.  </span>Select the optimal decision threshold.</span>
<span id="cb111-417"><a href="#cb111-417"></a></span>
<span id="cb111-418"><a href="#cb111-418"></a><span class="ss">5.  </span>Evaluate the performance of the calibrated model and the optimal threshold on the test set.</span>
<span id="cb111-419"><a href="#cb111-419"></a></span>
<span id="cb111-420"><a href="#cb111-420"></a><span class="fu">## Cost-Sensitive Learning Approach</span></span>
<span id="cb111-421"><a href="#cb111-421"></a></span>
<span id="cb111-422"><a href="#cb111-422"></a>**Rationale:**</span>
<span id="cb111-423"><a href="#cb111-423"></a></span>
<span id="cb111-424"><a href="#cb111-424"></a><span class="ss">-   </span>Cost-sensitive learning assigns different costs to classification errors.</span>
<span id="cb111-425"><a href="#cb111-425"></a><span class="ss">-   </span>In fraud detection, failing to detect a fraudulent transaction (a false negative) is typically much more costly than incorrectly flagging a legitimate transaction as fraudulent (a false positive).</span>
<span id="cb111-426"><a href="#cb111-426"></a><span class="ss">-   </span>By incorporating these costs, the model is encouraged to pay more attention to the minority (fraud) class.</span>
<span id="cb111-427"><a href="#cb111-427"></a></span>
<span id="cb111-428"><a href="#cb111-428"></a>**Implementation Detail:**</span>
<span id="cb111-429"><a href="#cb111-429"></a></span>
<span id="cb111-430"><a href="#cb111-430"></a><span class="ss">-   </span>One common way to implement cost-sensitive learning is by using sample weights:</span>
<span id="cb111-431"><a href="#cb111-431"></a><span class="ss">    -   </span>Instances from the minority class are given higher weights.</span>
<span id="cb111-432"><a href="#cb111-432"></a><span class="ss">    -   </span>Instances from the majority class are given lower weights.</span>
<span id="cb111-433"><a href="#cb111-433"></a><span class="ss">    -   </span>The weights are inversely proportional to class frequencies.</span>
<span id="cb111-434"><a href="#cb111-434"></a><span class="ss">-   </span>AutoGluon provides a convenient way to do this:</span>
<span id="cb111-435"><a href="#cb111-435"></a><span class="ss">    -   </span>Set the <span class="in">`sample_weight`</span> argument in <span class="in">`predictor_args`</span> to the special string <span class="in">`"balance_weight"`</span>.</span>
<span id="cb111-436"><a href="#cb111-436"></a><span class="ss">    -   </span>This automatically calculates and applies appropriate weights to balance the classes during training.</span>
<span id="cb111-437"><a href="#cb111-437"></a><span class="ss">-   </span>Sample weights are not needed for the test set evaluation.</span>
<span id="cb111-438"><a href="#cb111-438"></a></span>
<span id="cb111-439"><a href="#cb111-439"></a>**Process:**</span>
<span id="cb111-440"><a href="#cb111-440"></a></span>
<span id="cb111-441"><a href="#cb111-441"></a><span class="ss">1.  </span>Specify sample weights for each observation in the training set. This can be done by setting the <span class="in">`sample_weight`</span> argument in <span class="in">`predictor_args`</span> to <span class="in">`"balance_weight"`</span>.</span>
<span id="cb111-442"><a href="#cb111-442"></a></span>
<span id="cb111-443"><a href="#cb111-443"></a><span class="ss">2.  </span>Train multiple estimators on the original, imbalanced dataset.</span>
<span id="cb111-444"><a href="#cb111-444"></a></span>
<span id="cb111-445"><a href="#cb111-445"></a><span class="ss">3.  </span>Select the best model with the highest **average precision** on the test set.</span>
<span id="cb111-446"><a href="#cb111-446"></a></span>
<span id="cb111-447"><a href="#cb111-447"></a><span class="ss">4.  </span>Check for proper probability calibration. Calibrate the predicted probabilities if needed.</span>
<span id="cb111-448"><a href="#cb111-448"></a></span>
<span id="cb111-449"><a href="#cb111-449"></a><span class="ss">5.  </span>Select the optimal decision threshold.</span>
<span id="cb111-450"><a href="#cb111-450"></a></span>
<span id="cb111-451"><a href="#cb111-451"></a><span class="ss">6.  </span>Evaluate the performance of the calibrated model and the optimal threshold on the test set.</span>
<span id="cb111-452"><a href="#cb111-452"></a></span>
<span id="cb111-453"><a href="#cb111-453"></a><span class="fu">## Resampling Approach</span></span>
<span id="cb111-454"><a href="#cb111-454"></a></span>
<span id="cb111-455"><a href="#cb111-455"></a>**Rationale:**</span>
<span id="cb111-456"><a href="#cb111-456"></a></span>
<span id="cb111-457"><a href="#cb111-457"></a><span class="ss">-   </span>Class-based resampling techniques modify the training data's class distribution to create a more balanced dataset.</span>
<span id="cb111-458"><a href="#cb111-458"></a><span class="ss">-   </span>Resampling is performed **only** on the training data</span>
<span id="cb111-459"><a href="#cb111-459"></a><span class="ss">-   </span>The calibration and test sets remain in their original, imbalanced form to reflect reality (i.e., fraud is rare).</span>
<span id="cb111-460"><a href="#cb111-460"></a></span>
<span id="cb111-461"><a href="#cb111-461"></a>**Common Resampling Schemes:**</span>
<span id="cb111-462"><a href="#cb111-462"></a></span>
<span id="cb111-463"><a href="#cb111-463"></a><span class="ss">-   </span>**Random Undersampling (RUS):** Randomly remove instances from the majority class until the dataset is more balanced. This can lead to loss of information from the majority class. However, the scheme substantially reduces the dataset size, which can be beneficial for training speed and memory usage.</span>
<span id="cb111-464"><a href="#cb111-464"></a></span>
<span id="cb111-465"><a href="#cb111-465"></a><span class="ss">-   </span>**Random Oversampling (ROS):** Randomly duplicate instances from the minority class. This can lead to overfitting on the minority class examples.</span>
<span id="cb111-466"><a href="#cb111-466"></a></span>
<span id="cb111-467"><a href="#cb111-467"></a><span class="ss">-   </span>**SMOTE (Synthetic Minority Over-sampling Technique):** Creates synthetic samples for the minority class by interpolating between actual minority instances. This can help to create a more diverse set of minority examples than simple oversampling.</span>
<span id="cb111-468"><a href="#cb111-468"></a></span>
<span id="cb111-469"><a href="#cb111-469"></a><span class="ss">-   </span>**Hybrid Methods:** Combine oversampling and undersampling. For example:</span>
<span id="cb111-470"><a href="#cb111-470"></a></span>
<span id="cb111-471"><a href="#cb111-471"></a><span class="ss">    -   </span>First, apply SMOTE to generate synthetic samples for the minority class.</span>
<span id="cb111-472"><a href="#cb111-472"></a><span class="ss">    -   </span>Then, apply random undersampling to the majority class.</span>
<span id="cb111-473"><a href="#cb111-473"></a></span>
<span id="cb111-474"><a href="#cb111-474"></a>**Process:**</span>
<span id="cb111-475"><a href="#cb111-475"></a></span>
<span id="cb111-476"><a href="#cb111-476"></a><span class="ss">1.  </span>Use RUS, ROS, SMOTE, or hybrid to create a **balanced** training set.</span>
<span id="cb111-477"><a href="#cb111-477"></a></span>
<span id="cb111-478"><a href="#cb111-478"></a><span class="ss">2.  </span>Train multiple estimators on the **balanced** training set.</span>
<span id="cb111-479"><a href="#cb111-479"></a></span>
<span id="cb111-480"><a href="#cb111-480"></a><span class="ss">3.  </span>Select the best model with the highest **average precision** on the test set (which is imbalanced).</span>
<span id="cb111-481"><a href="#cb111-481"></a></span>
<span id="cb111-482"><a href="#cb111-482"></a><span class="ss">4.  </span>Check for proper probability calibration. Calibrate the predicted probabilities if needed.</span>
<span id="cb111-483"><a href="#cb111-483"></a></span>
<span id="cb111-484"><a href="#cb111-484"></a><span class="ss">5.  </span>Select the optimal decision threshold.</span>
<span id="cb111-485"><a href="#cb111-485"></a></span>
<span id="cb111-486"><a href="#cb111-486"></a><span class="ss">6.  </span>Evaluate the performance of the calibrated model and the optimal threshold on the test set (which is imbalanced).</span>
<span id="cb111-487"><a href="#cb111-487"></a></span>
<span id="cb111-488"><a href="#cb111-488"></a><span class="fu"># Data Prep for Big Data</span></span>
<span id="cb111-489"><a href="#cb111-489"></a></span>
<span id="cb111-490"><a href="#cb111-490"></a><span class="ss">-   </span>Credit card transaction data involves a huge number of records, often millions or even billions, and new data arrives quickly.</span>
<span id="cb111-491"><a href="#cb111-491"></a><span class="ss">-   </span>Handling such large datasets efficiently is essential for fast analysis and model building.</span>
<span id="cb111-492"><a href="#cb111-492"></a><span class="ss">-   </span>Traditional tools like <span class="in">`pandas`</span> can be slow and use a lot of memory with big data.</span>
<span id="cb111-493"><a href="#cb111-493"></a><span class="ss">-   </span>Modern libraries like <span class="in">`polars`</span> and databases like <span class="in">`DuckDB`</span> are designed to work faster and use memory more efficiently, making them better choices for large-scale data tasks.</span>
<span id="cb111-494"><a href="#cb111-494"></a></span>
<span id="cb111-495"><a href="#cb111-495"></a><span class="fu">## Data Loading</span></span>
<span id="cb111-496"><a href="#cb111-496"></a></span>
<span id="cb111-497"><a href="#cb111-497"></a>We will load all the parquet files found in the <span class="in">`Data/credit-card-fraud/simulated-data/`</span> folder. Each parquet file contains credit card transactions for a single day.</span>
<span id="cb111-498"><a href="#cb111-498"></a></span>
<span id="cb111-499"><a href="#cb111-499"></a>Some notes about the parquet file format:</span>
<span id="cb111-500"><a href="#cb111-500"></a></span>
<span id="cb111-501"><a href="#cb111-501"></a><span class="ss">-   </span>The parquet file format is widely used for tabular data.</span>
<span id="cb111-502"><a href="#cb111-502"></a><span class="ss">-   </span>Parquet is designed for efficient storage (small file sizes) and fast processing (quick reads).</span>
<span id="cb111-503"><a href="#cb111-503"></a><span class="ss">-   </span>Data frame libraries such as <span class="in">`pandas`</span>, <span class="in">`polars`</span>, and <span class="in">`DuckDB`</span> support reading from and writing to parquet files.</span>
<span id="cb111-504"><a href="#cb111-504"></a><span class="ss">-   </span>One drawback of parquet files is the lack of human readability, unlike CSV files.</span>
<span id="cb111-505"><a href="#cb111-505"></a><span class="ss">-   </span>Writing a parquet file to disk is also slower than writing a CSV file.</span>
<span id="cb111-506"><a href="#cb111-506"></a></span>
<span id="cb111-507"><a href="#cb111-507"></a>Read all the parquet files into a <span class="in">`polars`</span> data frame and a <span class="in">`DuckDB`</span> table.</span>
<span id="cb111-508"><a href="#cb111-508"></a></span>
<span id="cb111-511"><a href="#cb111-511"></a><span class="in">```{python}</span></span>
<span id="cb111-512"><a href="#cb111-512"></a><span class="co">#| label: read-parquet-polars</span></span>
<span id="cb111-513"><a href="#cb111-513"></a></span>
<span id="cb111-514"><a href="#cb111-514"></a>data_dir <span class="op">=</span> <span class="st">"../Data/credit-card-fraud/simulated-data/"</span></span>
<span id="cb111-515"><a href="#cb111-515"></a></span>
<span id="cb111-516"><a href="#cb111-516"></a>path_parquet_files <span class="op">=</span> glob.glob(os.path.join(data_dir, <span class="st">"*.parquet"</span>))</span>
<span id="cb111-517"><a href="#cb111-517"></a></span>
<span id="cb111-518"><a href="#cb111-518"></a>df_fraud <span class="op">=</span> pl.read_parquet(path_parquet_files)</span>
<span id="cb111-519"><a href="#cb111-519"></a><span class="in">```</span></span>
<span id="cb111-520"><a href="#cb111-520"></a></span>
<span id="cb111-523"><a href="#cb111-523"></a><span class="in">```{python}</span></span>
<span id="cb111-524"><a href="#cb111-524"></a><span class="co">#| label: read-parquet-duckdb</span></span>
<span id="cb111-525"><a href="#cb111-525"></a></span>
<span id="cb111-526"><a href="#cb111-526"></a>tbl_fraud <span class="op">=</span> duckdb.query(<span class="ss">f"""</span></span>
<span id="cb111-527"><a href="#cb111-527"></a><span class="ss">    SELECT * </span></span>
<span id="cb111-528"><a href="#cb111-528"></a><span class="ss">    FROM read_parquet(</span><span class="sc">{</span>path_parquet_files<span class="sc">}</span><span class="ss">)</span></span>
<span id="cb111-529"><a href="#cb111-529"></a><span class="ss">    """</span>)</span>
<span id="cb111-530"><a href="#cb111-530"></a><span class="in">```</span></span>
<span id="cb111-531"><a href="#cb111-531"></a></span>
<span id="cb111-534"><a href="#cb111-534"></a><span class="in">```{python}</span></span>
<span id="cb111-535"><a href="#cb111-535"></a><span class="co">#| label: num-parquet-files</span></span>
<span id="cb111-536"><a href="#cb111-536"></a></span>
<span id="cb111-537"><a href="#cb111-537"></a><span class="bu">print</span>(<span class="bu">len</span>(path_parquet_files)) <span class="co"># Display the number of parquet files found</span></span>
<span id="cb111-538"><a href="#cb111-538"></a><span class="in">```</span></span>
<span id="cb111-539"><a href="#cb111-539"></a></span>
<span id="cb111-540"><a href="#cb111-540"></a>Take a peek at the data.</span>
<span id="cb111-541"><a href="#cb111-541"></a></span>
<span id="cb111-544"><a href="#cb111-544"></a><span class="in">```{python}</span></span>
<span id="cb111-545"><a href="#cb111-545"></a><span class="co">#| label: peek-polars</span></span>
<span id="cb111-546"><a href="#cb111-546"></a></span>
<span id="cb111-547"><a href="#cb111-547"></a>display(df_fraud.head(<span class="dv">10</span>))</span>
<span id="cb111-548"><a href="#cb111-548"></a><span class="in">```</span></span>
<span id="cb111-549"><a href="#cb111-549"></a></span>
<span id="cb111-552"><a href="#cb111-552"></a><span class="in">```{python}</span></span>
<span id="cb111-553"><a href="#cb111-553"></a><span class="co">#| label: peek-duckdb</span></span>
<span id="cb111-554"><a href="#cb111-554"></a></span>
<span id="cb111-555"><a href="#cb111-555"></a>display(tbl_fraud.limit(<span class="dv">10</span>))</span>
<span id="cb111-556"><a href="#cb111-556"></a><span class="in">```</span></span>
<span id="cb111-557"><a href="#cb111-557"></a></span>
<span id="cb111-558"><a href="#cb111-558"></a>Get column names and data types for both <span class="in">`polars`</span> and <span class="in">`DuckDB`</span>.</span>
<span id="cb111-559"><a href="#cb111-559"></a></span>
<span id="cb111-562"><a href="#cb111-562"></a><span class="in">```{python}</span></span>
<span id="cb111-563"><a href="#cb111-563"></a><span class="co">#| label: column-info-polars</span></span>
<span id="cb111-564"><a href="#cb111-564"></a></span>
<span id="cb111-565"><a href="#cb111-565"></a><span class="co"># Get schema as a dictionary</span></span>
<span id="cb111-566"><a href="#cb111-566"></a>summary_df <span class="op">=</span> pl.DataFrame({</span>
<span id="cb111-567"><a href="#cb111-567"></a>    <span class="st">"Column Name"</span>: df_fraud.columns,</span>
<span id="cb111-568"><a href="#cb111-568"></a>    <span class="st">"Data Type"</span>: [<span class="bu">str</span>(dtype) <span class="cf">for</span> dtype <span class="kw">in</span> df_fraud.dtypes]</span>
<span id="cb111-569"><a href="#cb111-569"></a>})</span>
<span id="cb111-570"><a href="#cb111-570"></a></span>
<span id="cb111-571"><a href="#cb111-571"></a>display(summary_df)</span>
<span id="cb111-572"><a href="#cb111-572"></a><span class="in">```</span></span>
<span id="cb111-573"><a href="#cb111-573"></a></span>
<span id="cb111-576"><a href="#cb111-576"></a><span class="in">```{python}</span></span>
<span id="cb111-577"><a href="#cb111-577"></a><span class="co">#| label: column-info-duckdb</span></span>
<span id="cb111-578"><a href="#cb111-578"></a></span>
<span id="cb111-579"><a href="#cb111-579"></a>duckdb.sql(<span class="st">"""</span></span>
<span id="cb111-580"><a href="#cb111-580"></a><span class="st">    SELECT column_name, column_type</span></span>
<span id="cb111-581"><a href="#cb111-581"></a><span class="st">    FROM</span></span>
<span id="cb111-582"><a href="#cb111-582"></a><span class="st">    (DESCRIBE SELECT * FROM tbl_fraud)</span></span>
<span id="cb111-583"><a href="#cb111-583"></a><span class="st">    """</span>).show()</span>
<span id="cb111-584"><a href="#cb111-584"></a><span class="in">```</span></span>
<span id="cb111-585"><a href="#cb111-585"></a></span>
<span id="cb111-586"><a href="#cb111-586"></a>Read the same parquet files with <span class="in">`pandas`</span> for comparison.</span>
<span id="cb111-587"><a href="#cb111-587"></a></span>
<span id="cb111-590"><a href="#cb111-590"></a><span class="in">```{python}</span></span>
<span id="cb111-591"><a href="#cb111-591"></a><span class="co"># Read all parquet files into a pandas DataFrame (only .parquet files)</span></span>
<span id="cb111-592"><a href="#cb111-592"></a></span>
<span id="cb111-593"><a href="#cb111-593"></a>df_fraud_pd <span class="op">=</span> pd.read_parquet(path_parquet_files)</span>
<span id="cb111-594"><a href="#cb111-594"></a></span>
<span id="cb111-595"><a href="#cb111-595"></a><span class="co"># Display the first few rows</span></span>
<span id="cb111-596"><a href="#cb111-596"></a>display(df_fraud_pd.head())</span>
<span id="cb111-597"><a href="#cb111-597"></a><span class="in">```</span></span>
<span id="cb111-598"><a href="#cb111-598"></a></span>
<span id="cb111-599"><a href="#cb111-599"></a><span class="fu">## Data Frame Benchmarks</span></span>
<span id="cb111-600"><a href="#cb111-600"></a></span>
<span id="cb111-601"><a href="#cb111-601"></a>Calculate the fraud rate per CUSTOMER_ID using <span class="in">`polars`</span>, <span class="in">`DuckDB`</span>, and <span class="in">`pandas`</span>. Show the fraud rate only for customers with more than 10 transactions. This will help us compare the performance of these libraries on a common task.</span>
<span id="cb111-602"><a href="#cb111-602"></a></span>
<span id="cb111-605"><a href="#cb111-605"></a><span class="in">```{python}</span></span>
<span id="cb111-606"><a href="#cb111-606"></a><span class="co">#| label: fraud-rate-polars-complex</span></span>
<span id="cb111-607"><a href="#cb111-607"></a></span>
<span id="cb111-608"><a href="#cb111-608"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb111-609"><a href="#cb111-609"></a></span>
<span id="cb111-610"><a href="#cb111-610"></a>fraud_analysis_polars <span class="op">=</span> (</span>
<span id="cb111-611"><a href="#cb111-611"></a>    df_fraud</span>
<span id="cb111-612"><a href="#cb111-612"></a>    .group_by(pl.col(<span class="st">"CUSTOMER_ID"</span>))</span>
<span id="cb111-613"><a href="#cb111-613"></a>    .agg(</span>
<span id="cb111-614"><a href="#cb111-614"></a>        FRAUD_RATE <span class="op">=</span> pl.col(<span class="st">"TX_FRAUD"</span>).mean(),  <span class="co"># FRAUD_RATE by CUSTOMER_ID</span></span>
<span id="cb111-615"><a href="#cb111-615"></a>        TOTAL_FRAUDS <span class="op">=</span> pl.col(<span class="st">"TX_FRAUD"</span>).<span class="bu">sum</span>(),</span>
<span id="cb111-616"><a href="#cb111-616"></a>        AVG_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).mean(),</span>
<span id="cb111-617"><a href="#cb111-617"></a>        STD_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).std(),</span>
<span id="cb111-618"><a href="#cb111-618"></a>        P95_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).quantile(<span class="fl">0.95</span>),</span>
<span id="cb111-619"><a href="#cb111-619"></a>        MIN_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).<span class="bu">min</span>(),</span>
<span id="cb111-620"><a href="#cb111-620"></a>        MAX_AMOUNT <span class="op">=</span> pl.col(<span class="st">"TX_AMOUNT"</span>).<span class="bu">max</span>(),</span>
<span id="cb111-621"><a href="#cb111-621"></a>        TX_COUNT <span class="op">=</span> pl.<span class="bu">len</span>(),</span>
<span id="cb111-622"><a href="#cb111-622"></a>        FRAUD_VALUE <span class="op">=</span> (pl.col(<span class="st">"TX_AMOUNT"</span>) <span class="op">*</span> pl.col(<span class="st">"TX_FRAUD"</span>)).<span class="bu">sum</span>(),</span>
<span id="cb111-623"><a href="#cb111-623"></a>        FIRST_TX <span class="op">=</span> pl.col(<span class="st">"TX_DATETIME"</span>).<span class="bu">min</span>(),</span>
<span id="cb111-624"><a href="#cb111-624"></a>        LAST_TX <span class="op">=</span> pl.col(<span class="st">"TX_DATETIME"</span>).<span class="bu">max</span>()</span>
<span id="cb111-625"><a href="#cb111-625"></a>    )</span>
<span id="cb111-626"><a href="#cb111-626"></a>    .with_columns(</span>
<span id="cb111-627"><a href="#cb111-627"></a>        AVG_FRAUD_AMOUNT <span class="op">=</span> (pl.col(<span class="st">"FRAUD_VALUE"</span>) <span class="op">/</span> pl.col(<span class="st">"TX_COUNT"</span>)),</span>
<span id="cb111-628"><a href="#cb111-628"></a>        CUSTOMER_TENURE_DAYS <span class="op">=</span> (pl.col(<span class="st">"LAST_TX"</span>) <span class="op">-</span> pl.col(<span class="st">"FIRST_TX"</span>)).dt.total_days()</span>
<span id="cb111-629"><a href="#cb111-629"></a>    )</span>
<span id="cb111-630"><a href="#cb111-630"></a>    .<span class="bu">filter</span>(pl.col(<span class="st">"TX_COUNT"</span>) <span class="op">&gt;</span> <span class="dv">10</span>)</span>
<span id="cb111-631"><a href="#cb111-631"></a>    .sort(<span class="st">"FRAUD_RATE"</span>, descending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb111-632"><a href="#cb111-632"></a>)</span>
<span id="cb111-633"><a href="#cb111-633"></a></span>
<span id="cb111-634"><a href="#cb111-634"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb111-635"><a href="#cb111-635"></a><span class="bu">print</span>(<span class="ss">f"Polars fraud analysis completed in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb111-636"><a href="#cb111-636"></a></span>
<span id="cb111-637"><a href="#cb111-637"></a><span class="in">```</span></span>
<span id="cb111-638"><a href="#cb111-638"></a></span>
<span id="cb111-641"><a href="#cb111-641"></a><span class="in">```{python}</span></span>
<span id="cb111-642"><a href="#cb111-642"></a><span class="co">#| label: print-polars-fraud-rate</span></span>
<span id="cb111-643"><a href="#cb111-643"></a></span>
<span id="cb111-644"><a href="#cb111-644"></a>display(fraud_analysis_polars.head(<span class="dv">10</span>))</span>
<span id="cb111-645"><a href="#cb111-645"></a><span class="in">```</span></span>
<span id="cb111-646"><a href="#cb111-646"></a></span>
<span id="cb111-649"><a href="#cb111-649"></a><span class="in">```{python}</span></span>
<span id="cb111-650"><a href="#cb111-650"></a><span class="co">#| label: fraud-rate-duckdb-complex</span></span>
<span id="cb111-651"><a href="#cb111-651"></a></span>
<span id="cb111-652"><a href="#cb111-652"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb111-653"><a href="#cb111-653"></a></span>
<span id="cb111-654"><a href="#cb111-654"></a>fraud_analysis_duckdb <span class="op">=</span> duckdb.query(<span class="st">"""</span></span>
<span id="cb111-655"><a href="#cb111-655"></a><span class="st">    WITH customer_stats AS (</span></span>
<span id="cb111-656"><a href="#cb111-656"></a><span class="st">        SELECT </span></span>
<span id="cb111-657"><a href="#cb111-657"></a><span class="st">            CUSTOMER_ID,</span></span>
<span id="cb111-658"><a href="#cb111-658"></a><span class="st">            AVG(TX_FRAUD) AS FRAUD_RATE,  -- FRAUD_RATE by CUSTOMER_ID</span></span>
<span id="cb111-659"><a href="#cb111-659"></a><span class="st">            SUM(TX_FRAUD) AS TOTAL_FRAUDS,</span></span>
<span id="cb111-660"><a href="#cb111-660"></a><span class="st">            AVG(TX_AMOUNT) AS AVG_AMOUNT,</span></span>
<span id="cb111-661"><a href="#cb111-661"></a><span class="st">            STDDEV(TX_AMOUNT) AS STD_AMOUNT,</span></span>
<span id="cb111-662"><a href="#cb111-662"></a><span class="st">            PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY TX_AMOUNT) AS P95_AMOUNT,</span></span>
<span id="cb111-663"><a href="#cb111-663"></a><span class="st">            MIN(TX_AMOUNT) AS MIN_AMOUNT,</span></span>
<span id="cb111-664"><a href="#cb111-664"></a><span class="st">            MAX(TX_AMOUNT) AS MAX_AMOUNT,</span></span>
<span id="cb111-665"><a href="#cb111-665"></a><span class="st">            COUNT(*) AS TX_COUNT,</span></span>
<span id="cb111-666"><a href="#cb111-666"></a><span class="st">            SUM(TX_AMOUNT * TX_FRAUD) AS FRAUD_VALUE,</span></span>
<span id="cb111-667"><a href="#cb111-667"></a><span class="st">            MIN(TX_DATETIME) AS FIRST_TX,</span></span>
<span id="cb111-668"><a href="#cb111-668"></a><span class="st">            MAX(TX_DATETIME) AS LAST_TX</span></span>
<span id="cb111-669"><a href="#cb111-669"></a><span class="st">        FROM tbl_fraud</span></span>
<span id="cb111-670"><a href="#cb111-670"></a><span class="st">        GROUP BY CUSTOMER_ID</span></span>
<span id="cb111-671"><a href="#cb111-671"></a><span class="st">        HAVING COUNT(*) &gt; 10</span></span>
<span id="cb111-672"><a href="#cb111-672"></a><span class="st">    )</span></span>
<span id="cb111-673"><a href="#cb111-673"></a><span class="st">    SELECT *,</span></span>
<span id="cb111-674"><a href="#cb111-674"></a><span class="st">        FRAUD_VALUE / TX_COUNT AS AVG_FRAUD_AMOUNT,</span></span>
<span id="cb111-675"><a href="#cb111-675"></a><span class="st">        DATE_DIFF('day', FIRST_TX, LAST_TX) AS CUSTOMER_TENURE_DAYS</span></span>
<span id="cb111-676"><a href="#cb111-676"></a><span class="st">    FROM customer_stats</span></span>
<span id="cb111-677"><a href="#cb111-677"></a><span class="st">    ORDER BY FRAUD_RATE DESC</span></span>
<span id="cb111-678"><a href="#cb111-678"></a><span class="st">"""</span>)</span>
<span id="cb111-679"><a href="#cb111-679"></a></span>
<span id="cb111-680"><a href="#cb111-680"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb111-681"><a href="#cb111-681"></a><span class="bu">print</span>(<span class="ss">f"DuckDB fraud analysis completed in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb111-682"><a href="#cb111-682"></a></span>
<span id="cb111-683"><a href="#cb111-683"></a><span class="in">```</span></span>
<span id="cb111-684"><a href="#cb111-684"></a></span>
<span id="cb111-687"><a href="#cb111-687"></a><span class="in">```{python}</span></span>
<span id="cb111-688"><a href="#cb111-688"></a><span class="co">#| label: print-duckdb-fraud-rate</span></span>
<span id="cb111-689"><a href="#cb111-689"></a></span>
<span id="cb111-690"><a href="#cb111-690"></a>display(fraud_analysis_duckdb.limit(<span class="dv">10</span>))</span>
<span id="cb111-691"><a href="#cb111-691"></a><span class="in">```</span></span>
<span id="cb111-692"><a href="#cb111-692"></a></span>
<span id="cb111-695"><a href="#cb111-695"></a><span class="in">```{python}</span></span>
<span id="cb111-696"><a href="#cb111-696"></a><span class="co">#| label: fraud-rate-pandas-complex</span></span>
<span id="cb111-697"><a href="#cb111-697"></a></span>
<span id="cb111-698"><a href="#cb111-698"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb111-699"><a href="#cb111-699"></a></span>
<span id="cb111-700"><a href="#cb111-700"></a>df_fraud_pd[<span class="st">'FRAUD_VALUE'</span>] <span class="op">=</span> df_fraud_pd[<span class="st">'TX_AMOUNT'</span>] <span class="op">*</span> df_fraud_pd[<span class="st">'TX_FRAUD'</span>]</span>
<span id="cb111-701"><a href="#cb111-701"></a></span>
<span id="cb111-702"><a href="#cb111-702"></a>fraud_analysis_pandas <span class="op">=</span> (</span>
<span id="cb111-703"><a href="#cb111-703"></a>    df_fraud_pd</span>
<span id="cb111-704"><a href="#cb111-704"></a>    .groupby(<span class="st">"CUSTOMER_ID"</span>, sort<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-705"><a href="#cb111-705"></a>    .agg(</span>
<span id="cb111-706"><a href="#cb111-706"></a>        FRAUD_RATE<span class="op">=</span>(<span class="st">'TX_FRAUD'</span>, <span class="st">'mean'</span>),  <span class="co"># FRAUD_RATE by CUSTOMER_ID</span></span>
<span id="cb111-707"><a href="#cb111-707"></a>        TOTAL_FRAUDS<span class="op">=</span>(<span class="st">'TX_FRAUD'</span>, <span class="st">'sum'</span>),</span>
<span id="cb111-708"><a href="#cb111-708"></a>        AVG_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'mean'</span>),</span>
<span id="cb111-709"><a href="#cb111-709"></a>        STD_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'std'</span>),</span>
<span id="cb111-710"><a href="#cb111-710"></a>        P95_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="kw">lambda</span> x: x.quantile(<span class="fl">0.95</span>)),</span>
<span id="cb111-711"><a href="#cb111-711"></a>        MIN_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'min'</span>),</span>
<span id="cb111-712"><a href="#cb111-712"></a>        MAX_AMOUNT<span class="op">=</span>(<span class="st">'TX_AMOUNT'</span>, <span class="st">'max'</span>),</span>
<span id="cb111-713"><a href="#cb111-713"></a>        TX_COUNT<span class="op">=</span>(<span class="st">'TX_FRAUD'</span>, <span class="st">'size'</span>),</span>
<span id="cb111-714"><a href="#cb111-714"></a>        FRAUD_VALUE<span class="op">=</span>(<span class="st">'FRAUD_VALUE'</span>, <span class="st">'sum'</span>),</span>
<span id="cb111-715"><a href="#cb111-715"></a>        FIRST_TX<span class="op">=</span>(<span class="st">'TX_DATETIME'</span>, <span class="st">'min'</span>),</span>
<span id="cb111-716"><a href="#cb111-716"></a>        LAST_TX<span class="op">=</span>(<span class="st">'TX_DATETIME'</span>, <span class="st">'max'</span>)</span>
<span id="cb111-717"><a href="#cb111-717"></a>    )</span>
<span id="cb111-718"><a href="#cb111-718"></a>    .reset_index()</span>
<span id="cb111-719"><a href="#cb111-719"></a>    .query(<span class="st">"TX_COUNT &gt; 10"</span>)</span>
<span id="cb111-720"><a href="#cb111-720"></a>    .assign(</span>
<span id="cb111-721"><a href="#cb111-721"></a>        AVG_FRAUD_AMOUNT<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'FRAUD_VALUE'</span>] <span class="op">/</span> x[<span class="st">'TX_COUNT'</span>],</span>
<span id="cb111-722"><a href="#cb111-722"></a>        CUSTOMER_TENURE_DAYS<span class="op">=</span><span class="kw">lambda</span> x: (x[<span class="st">'LAST_TX'</span>] <span class="op">-</span> x[<span class="st">'FIRST_TX'</span>]).dt.days</span>
<span id="cb111-723"><a href="#cb111-723"></a>    )</span>
<span id="cb111-724"><a href="#cb111-724"></a>    .sort_values(<span class="st">"FRAUD_RATE"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-725"><a href="#cb111-725"></a>)</span>
<span id="cb111-726"><a href="#cb111-726"></a></span>
<span id="cb111-727"><a href="#cb111-727"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb111-728"><a href="#cb111-728"></a><span class="bu">print</span>(<span class="ss">f"Pandas fraud analysis completed in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb111-729"><a href="#cb111-729"></a></span>
<span id="cb111-730"><a href="#cb111-730"></a><span class="in">```</span></span>
<span id="cb111-731"><a href="#cb111-731"></a></span>
<span id="cb111-734"><a href="#cb111-734"></a><span class="in">```{python}</span></span>
<span id="cb111-735"><a href="#cb111-735"></a><span class="co">#| label: print-pandas-fraud-rate</span></span>
<span id="cb111-736"><a href="#cb111-736"></a></span>
<span id="cb111-737"><a href="#cb111-737"></a>display(fraud_analysis_pandas.head(<span class="dv">10</span>))</span>
<span id="cb111-738"><a href="#cb111-738"></a></span>
<span id="cb111-739"><a href="#cb111-739"></a><span class="in">```</span></span>
<span id="cb111-740"><a href="#cb111-740"></a></span>
<span id="cb111-741"><a href="#cb111-741"></a><span class="fu">## Prequential Data Splitting (using Polars)</span></span>
<span id="cb111-742"><a href="#cb111-742"></a></span>
<span id="cb111-743"><a href="#cb111-743"></a>To properly evaluate fraud detection models, we split the data **chronologically** into training, tuning (calibration), and test sets based on the <span class="in">`TX_DATETIME`</span> column.</span>
<span id="cb111-744"><a href="#cb111-744"></a></span>
<span id="cb111-745"><a href="#cb111-745"></a>Also known as out-of-time validation, prequential data splitting ensures that future transactions do not influence model training or validation.</span>
<span id="cb111-746"><a href="#cb111-746"></a></span>
<span id="cb111-747"><a href="#cb111-747"></a>The lab splits the data into three sets:</span>
<span id="cb111-748"><a href="#cb111-748"></a></span>
<span id="cb111-749"><a href="#cb111-749"></a><span class="ss">-   </span><span class="in">`df_train`</span>: Transactions before <span class="in">`2018-07-31`</span> (inclusive).</span>
<span id="cb111-750"><a href="#cb111-750"></a><span class="ss">-   </span><span class="in">`df_tuning`</span>: Transactions between <span class="in">`2018-08-01`</span> (inclusive) and <span class="in">`2018-08-31`</span> (inclusive).</span>
<span id="cb111-751"><a href="#cb111-751"></a><span class="ss">-   </span><span class="in">`df_test`</span>: Transactions after <span class="in">`2018-09-01`</span> (inclusive).</span>
<span id="cb111-752"><a href="#cb111-752"></a></span>
<span id="cb111-755"><a href="#cb111-755"></a><span class="in">```{python}</span></span>
<span id="cb111-756"><a href="#cb111-756"></a><span class="co"># | label: data-splitting-polars</span></span>
<span id="cb111-757"><a href="#cb111-757"></a><span class="co"># Prequential data splitting using Polars</span></span>
<span id="cb111-758"><a href="#cb111-758"></a></span>
<span id="cb111-759"><a href="#cb111-759"></a><span class="kw">def</span> split_data(df: pl.DataFrame</span>
<span id="cb111-760"><a href="#cb111-760"></a>            , <span class="bu">type</span>: <span class="bu">str</span> <span class="op">=</span> <span class="st">"train"</span>) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb111-761"><a href="#cb111-761"></a>    <span class="co">"""</span></span>
<span id="cb111-762"><a href="#cb111-762"></a><span class="co">    Splits the data into train, tuning, and test sets based on TX_DATETIME.</span></span>
<span id="cb111-763"><a href="#cb111-763"></a><span class="co">    """</span></span>
<span id="cb111-764"><a href="#cb111-764"></a>    <span class="cf">if</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"train"</span>:</span>
<span id="cb111-765"><a href="#cb111-765"></a>        <span class="cf">return</span> df.<span class="bu">filter</span>(pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&lt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">7</span>, <span class="dv">31</span>))</span>
<span id="cb111-766"><a href="#cb111-766"></a>    <span class="cf">elif</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"tuning"</span>:</span>
<span id="cb111-767"><a href="#cb111-767"></a>        <span class="cf">return</span> df.<span class="bu">filter</span>((pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&gt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">8</span>, <span class="dv">1</span>)) </span>
<span id="cb111-768"><a href="#cb111-768"></a>                        <span class="op">&amp;</span> (pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&lt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">8</span>, <span class="dv">31</span>)))</span>
<span id="cb111-769"><a href="#cb111-769"></a>    <span class="cf">elif</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"test"</span>:</span>
<span id="cb111-770"><a href="#cb111-770"></a>        <span class="cf">return</span> df.<span class="bu">filter</span>(pl.col(<span class="st">"TX_DATETIME"</span>) <span class="op">&gt;=</span> pl.date(<span class="dv">2018</span>, <span class="dv">9</span>, <span class="dv">1</span>))</span>
<span id="cb111-771"><a href="#cb111-771"></a>    <span class="cf">else</span>:</span>
<span id="cb111-772"><a href="#cb111-772"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown split type: </span><span class="sc">{</span><span class="bu">type</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-773"><a href="#cb111-773"></a></span>
<span id="cb111-774"><a href="#cb111-774"></a><span class="co"># Split the data into train, tuning, and test sets</span></span>
<span id="cb111-775"><a href="#cb111-775"></a></span>
<span id="cb111-776"><a href="#cb111-776"></a><span class="co"># df_train: Transactions before 2018-07-31 (inclusive)</span></span>
<span id="cb111-777"><a href="#cb111-777"></a>df_train <span class="op">=</span> split_data(df_fraud, <span class="bu">type</span><span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb111-778"><a href="#cb111-778"></a></span>
<span id="cb111-779"><a href="#cb111-779"></a><span class="co"># df_tuning: Transactions between 2018-08-01 (inclusive) and 2018-08-31 (inclusive)</span></span>
<span id="cb111-780"><a href="#cb111-780"></a>df_tuning <span class="op">=</span> split_data(df_fraud, <span class="bu">type</span><span class="op">=</span><span class="st">"tuning"</span>)</span>
<span id="cb111-781"><a href="#cb111-781"></a></span>
<span id="cb111-782"><a href="#cb111-782"></a><span class="co"># df_test: Transactions after 2018-09-01 (inclusive)</span></span>
<span id="cb111-783"><a href="#cb111-783"></a>df_test <span class="op">=</span> split_data(df_fraud, <span class="bu">type</span><span class="op">=</span><span class="st">"test"</span>)</span>
<span id="cb111-784"><a href="#cb111-784"></a></span>
<span id="cb111-785"><a href="#cb111-785"></a><span class="in">```</span></span>
<span id="cb111-786"><a href="#cb111-786"></a></span>
<span id="cb111-789"><a href="#cb111-789"></a><span class="in">```{python}</span></span>
<span id="cb111-790"><a href="#cb111-790"></a><span class="co">#| label: sample-sizes</span></span>
<span id="cb111-791"><a href="#cb111-791"></a></span>
<span id="cb111-792"><a href="#cb111-792"></a>df_train.shape, df_tuning.shape, df_test.shape</span>
<span id="cb111-793"><a href="#cb111-793"></a><span class="in">```</span></span>
<span id="cb111-794"><a href="#cb111-794"></a></span>
<span id="cb111-795"><a href="#cb111-795"></a><span class="fu"># EDA: Compare `df_train` and `df_tuning`</span></span>
<span id="cb111-796"><a href="#cb111-796"></a></span>
<span id="cb111-797"><a href="#cb111-797"></a>Unfortunately, the <span class="in">`ydata_profiling`</span> library does not support polars data frames. The lab will randomly sample 10% of each data frame and then convert to pandas data frames for profiling. This is a workaround to allow us to compare the two datasets using the <span class="in">`ydata_profiling`</span> library.</span>
<span id="cb111-798"><a href="#cb111-798"></a></span>
<span id="cb111-799"><a href="#cb111-799"></a>For the data dictionary, please refer to Chapter 3 of @leborgne2022fraud.</span>
<span id="cb111-800"><a href="#cb111-800"></a></span>
<span id="cb111-803"><a href="#cb111-803"></a><span class="in">```{python}</span></span>
<span id="cb111-804"><a href="#cb111-804"></a><span class="co">#| label: eda-train-tuning-comparison</span></span>
<span id="cb111-805"><a href="#cb111-805"></a></span>
<span id="cb111-806"><a href="#cb111-806"></a>p_frac <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb111-807"><a href="#cb111-807"></a></span>
<span id="cb111-808"><a href="#cb111-808"></a>train_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb111-809"><a href="#cb111-809"></a>            df_train.sample(fraction<span class="op">=</span>p_frac, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb111-810"><a href="#cb111-810"></a>            title<span class="op">=</span><span class="st">"Train"</span>,</span>
<span id="cb111-811"><a href="#cb111-811"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb111-812"><a href="#cb111-812"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb111-813"><a href="#cb111-813"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb111-814"><a href="#cb111-814"></a>            )</span>
<span id="cb111-815"><a href="#cb111-815"></a></span>
<span id="cb111-816"><a href="#cb111-816"></a>tuning_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb111-817"><a href="#cb111-817"></a>            df_tuning.sample(fraction<span class="op">=</span>p_frac<span class="op">*</span><span class="dv">2</span>, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb111-818"><a href="#cb111-818"></a>            title<span class="op">=</span><span class="st">"Tuning"</span>,</span>
<span id="cb111-819"><a href="#cb111-819"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb111-820"><a href="#cb111-820"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb111-821"><a href="#cb111-821"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb111-822"><a href="#cb111-822"></a>            )</span>
<span id="cb111-823"><a href="#cb111-823"></a></span>
<span id="cb111-824"><a href="#cb111-824"></a>compare_profile <span class="op">=</span> train_data_profile.compare(tuning_data_profile)</span>
<span id="cb111-825"><a href="#cb111-825"></a></span>
<span id="cb111-826"><a href="#cb111-826"></a>compare_profile.to_file(<span class="st">"Lab04_eda_compare_train_tuning.html"</span>)</span>
<span id="cb111-827"><a href="#cb111-827"></a></span>
<span id="cb111-828"><a href="#cb111-828"></a><span class="in">```</span></span>
<span id="cb111-829"><a href="#cb111-829"></a></span>
<span id="cb111-830"><a href="#cb111-830"></a><span class="fu"># Feature Engineering</span></span>
<span id="cb111-831"><a href="#cb111-831"></a></span>
<span id="cb111-832"><a href="#cb111-832"></a>The section creates new features that enhance the effectiveness of fraud detection models.</span>
<span id="cb111-833"><a href="#cb111-833"></a></span>
<span id="cb111-834"><a href="#cb111-834"></a>The feature engineering logic is based on Chapter 3 of @leborgne2022fraud, but has been adapted to use Polars expressions for improved speed and efficiency.</span>
<span id="cb111-835"><a href="#cb111-835"></a></span>
<span id="cb111-836"><a href="#cb111-836"></a><span class="fu">## Polars Feature Functions</span></span>
<span id="cb111-837"><a href="#cb111-837"></a></span>
<span id="cb111-838"><a href="#cb111-838"></a>We will create functions to generate the following features. Each function will take a Polars DataFrame as input and return a Polars DataFrame with the new feature(s) added.</span>
<span id="cb111-839"><a href="#cb111-839"></a></span>
<span id="cb111-840"><a href="#cb111-840"></a>Date-related features:</span>
<span id="cb111-841"><a href="#cb111-841"></a></span>
<span id="cb111-842"><a href="#cb111-842"></a><span class="ss">1.  </span>TX_DURING_WEEKEND: whether the transaction occurred on a weekend (1 if weekend, 0 if weekday).</span>
<span id="cb111-843"><a href="#cb111-843"></a></span>
<span id="cb111-844"><a href="#cb111-844"></a><span class="ss">2.  </span>TX_DURING_NIGHT: whether the transaction occurred during the night (1 if night, 0 if day).</span>
<span id="cb111-845"><a href="#cb111-845"></a></span>
<span id="cb111-846"><a href="#cb111-846"></a>Customer features:</span>
<span id="cb111-847"><a href="#cb111-847"></a></span>
<span id="cb111-848"><a href="#cb111-848"></a><span class="ss">3.  </span>CUSTOMER_ID_NB_TX_1DAY_WINDOW: number of transactions for the customer in the last 1 day.</span>
<span id="cb111-849"><a href="#cb111-849"></a></span>
<span id="cb111-850"><a href="#cb111-850"></a><span class="ss">4.  </span>CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW: average transaction amount for the customer in the last 1 day.</span>
<span id="cb111-851"><a href="#cb111-851"></a></span>
<span id="cb111-852"><a href="#cb111-852"></a><span class="ss">5.  </span>CUSTOMER_ID_NB_TX_7DAY_WINDOW: number of transactions for the customer in the last 7 days.</span>
<span id="cb111-853"><a href="#cb111-853"></a></span>
<span id="cb111-854"><a href="#cb111-854"></a><span class="ss">6.  </span>CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW: average transaction amount for the customer in the last 7 days.</span>
<span id="cb111-855"><a href="#cb111-855"></a></span>
<span id="cb111-856"><a href="#cb111-856"></a><span class="ss">7.  </span>CUSTOMER_ID_NB_TX_30DAY_WINDOW: number of transactions for the customer in the last 30 days.</span>
<span id="cb111-857"><a href="#cb111-857"></a></span>
<span id="cb111-858"><a href="#cb111-858"></a><span class="ss">8.  </span>CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW: average transaction amount for the customer in the last 30 days.</span>
<span id="cb111-859"><a href="#cb111-859"></a></span>
<span id="cb111-860"><a href="#cb111-860"></a>Terminal features:</span>
<span id="cb111-861"><a href="#cb111-861"></a></span>
<span id="cb111-862"><a href="#cb111-862"></a><span class="ss">9.  </span>TERMINAL_ID_NB_TX_1DAY_WINDOW: number of transactions for the terminal in the last 1 day. Lagged 7 days to account for a lag in fraud labeling.</span>
<span id="cb111-863"><a href="#cb111-863"></a></span>
<span id="cb111-864"><a href="#cb111-864"></a><span class="ss">10. </span>TERMINAL_ID_RISK_1DAY_WINDOW: proportion of **fraudulent** transactions for the terminal in the last 1 day. Lagged 7 days to account for a lag in fraud labeling.</span>
<span id="cb111-865"><a href="#cb111-865"></a></span>
<span id="cb111-866"><a href="#cb111-866"></a><span class="ss">11. </span>TERMINAL_ID_NB_TX_7DAY_WINDOW: number of transactions for the terminal in the last 7 days. Lagged 7 days to account for a lag in fraud labeling.</span>
<span id="cb111-867"><a href="#cb111-867"></a></span>
<span id="cb111-868"><a href="#cb111-868"></a><span class="ss">12. </span>TERMINAL_ID_RISK_7DAY_WINDOW: proportion of **fraudulent** transactions for the terminal in the last 7 days. Lagged 7 days to account for a lag in fraud labeling.</span>
<span id="cb111-869"><a href="#cb111-869"></a></span>
<span id="cb111-870"><a href="#cb111-870"></a><span class="ss">13. </span>TERMINAL_ID_NB_TX_30DAY_WINDOW: number of transactions for the terminal in the last 30 days. Lagged 7 days to account for a lag in fraud labeling.</span>
<span id="cb111-871"><a href="#cb111-871"></a></span>
<span id="cb111-872"><a href="#cb111-872"></a><span class="ss">14. </span>TERMINAL_ID_RISK_30DAY_WINDOW: proportion of **fraudulent** transactions for the terminal in the last 30 days. Lagged 7 days to account for a lag in fraud labeling.</span>
<span id="cb111-873"><a href="#cb111-873"></a></span>
<span id="cb111-874"><a href="#cb111-874"></a><span class="fu">### Weekend Flag</span></span>
<span id="cb111-875"><a href="#cb111-875"></a></span>
<span id="cb111-876"><a href="#cb111-876"></a>The feature indicates if a transaction occurred on a weekend.</span>
<span id="cb111-877"><a href="#cb111-877"></a></span>
<span id="cb111-880"><a href="#cb111-880"></a><span class="in">```{python}</span></span>
<span id="cb111-881"><a href="#cb111-881"></a><span class="co">#| label: feature-is-weekend</span></span>
<span id="cb111-882"><a href="#cb111-882"></a><span class="co">#| </span></span>
<span id="cb111-883"><a href="#cb111-883"></a><span class="kw">def</span> fe_is_weekend(df: pl.DataFrame) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb111-884"><a href="#cb111-884"></a>    <span class="co">"""Adds IS_WEEKEND feature (1 if weekend, 0 if weekday)."""</span></span>
<span id="cb111-885"><a href="#cb111-885"></a>    <span class="co"># Polars weekday(): Monday=1, Sunday=7. So, Saturday (6) or Sunday (7) are weekends.</span></span>
<span id="cb111-886"><a href="#cb111-886"></a>    <span class="cf">return</span> df.with_columns(</span>
<span id="cb111-887"><a href="#cb111-887"></a>        TX_DURING_WEEKEND <span class="op">=</span> (pl.col(<span class="st">"TX_DATETIME"</span>).dt.weekday()</span>
<span id="cb111-888"><a href="#cb111-888"></a>                                .is_in([<span class="dv">6</span>, <span class="dv">7</span>])</span>
<span id="cb111-889"><a href="#cb111-889"></a>                                .cast(pl.UInt8))</span>
<span id="cb111-890"><a href="#cb111-890"></a>    )</span>
<span id="cb111-891"><a href="#cb111-891"></a></span>
<span id="cb111-892"><a href="#cb111-892"></a></span>
<span id="cb111-893"><a href="#cb111-893"></a><span class="in">```</span></span>
<span id="cb111-894"><a href="#cb111-894"></a></span>
<span id="cb111-895"><a href="#cb111-895"></a><span class="fu">### Night Flag</span></span>
<span id="cb111-896"><a href="#cb111-896"></a></span>
<span id="cb111-897"><a href="#cb111-897"></a>The feature indicates if a transaction occurred during the night (defined as between midnight and 6:00 AM).</span>
<span id="cb111-898"><a href="#cb111-898"></a></span>
<span id="cb111-901"><a href="#cb111-901"></a><span class="in">```{python}</span></span>
<span id="cb111-902"><a href="#cb111-902"></a><span class="co">#| label: feature-is-night</span></span>
<span id="cb111-903"><a href="#cb111-903"></a></span>
<span id="cb111-904"><a href="#cb111-904"></a><span class="kw">def</span> fe_is_night(df: pl.DataFrame) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb111-905"><a href="#cb111-905"></a>    <span class="co">"""Adds IS_NIGHT feature (1 if hour &lt; 6, 0 otherwise)."""</span></span>
<span id="cb111-906"><a href="#cb111-906"></a>    <span class="cf">return</span> df.with_columns(</span>
<span id="cb111-907"><a href="#cb111-907"></a>        TX_DURING_NIGHT <span class="op">=</span> pl.when(pl.col(<span class="st">"TX_DATETIME"</span>).dt.hour() <span class="op">&lt;</span> <span class="dv">6</span>)</span>
<span id="cb111-908"><a href="#cb111-908"></a>                            .then(<span class="dv">1</span>)</span>
<span id="cb111-909"><a href="#cb111-909"></a>                            .otherwise(<span class="dv">0</span>)</span>
<span id="cb111-910"><a href="#cb111-910"></a>                            .cast(pl.UInt8)</span>
<span id="cb111-911"><a href="#cb111-911"></a>    )</span>
<span id="cb111-912"><a href="#cb111-912"></a></span>
<span id="cb111-913"><a href="#cb111-913"></a><span class="in">```</span></span>
<span id="cb111-914"><a href="#cb111-914"></a></span>
<span id="cb111-915"><a href="#cb111-915"></a><span class="fu">### Customer Features</span></span>
<span id="cb111-916"><a href="#cb111-916"></a></span>
<span id="cb111-917"><a href="#cb111-917"></a>The features describe a customer's recent transaction count and average transaction amount over different rolling time windows (1, 7, and 30 days).</span>
<span id="cb111-918"><a href="#cb111-918"></a></span>
<span id="cb111-921"><a href="#cb111-921"></a><span class="in">```{python}</span></span>
<span id="cb111-922"><a href="#cb111-922"></a><span class="co">#| label: feature-customer-spending</span></span>
<span id="cb111-923"><a href="#cb111-923"></a><span class="kw">def</span> fe_customer_spending(df: pl.DataFrame, window_sizes_in_days<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>]) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb111-924"><a href="#cb111-924"></a>    <span class="co">"""</span></span>
<span id="cb111-925"><a href="#cb111-925"></a><span class="co">    Calculates customer spending features:</span></span>
<span id="cb111-926"><a href="#cb111-926"></a><span class="co">    - Count of transactions per customer over different window_sizes.</span></span>
<span id="cb111-927"><a href="#cb111-927"></a><span class="co">    - Average transaction amount per customer over different window_sizes.</span></span>
<span id="cb111-928"><a href="#cb111-928"></a><span class="co">    """</span></span>
<span id="cb111-929"><a href="#cb111-929"></a></span>
<span id="cb111-930"><a href="#cb111-930"></a>    df_int <span class="op">=</span> (</span>
<span id="cb111-931"><a href="#cb111-931"></a>        df</span>
<span id="cb111-932"><a href="#cb111-932"></a>        .sort(pl.col(<span class="st">"CUSTOMER_ID"</span>), pl.col(<span class="st">"TX_DATETIME"</span>)) <span class="co"># very important to sort</span></span>
<span id="cb111-933"><a href="#cb111-933"></a>        .with_columns(</span>
<span id="cb111-934"><a href="#cb111-934"></a>            pl.col(<span class="st">"CUSTOMER_ID"</span>).cast(pl.UInt64),</span>
<span id="cb111-935"><a href="#cb111-935"></a>            pl.lit(<span class="dv">1</span>).alias(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb111-936"><a href="#cb111-936"></a>        )</span>
<span id="cb111-937"><a href="#cb111-937"></a>    )</span>
<span id="cb111-938"><a href="#cb111-938"></a></span>
<span id="cb111-939"><a href="#cb111-939"></a>    result_df <span class="op">=</span> df_int</span>
<span id="cb111-940"><a href="#cb111-940"></a>    <span class="cf">for</span> window <span class="kw">in</span> window_sizes_in_days:</span>
<span id="cb111-941"><a href="#cb111-941"></a>        result_df <span class="op">=</span> (</span>
<span id="cb111-942"><a href="#cb111-942"></a>            result_df</span>
<span id="cb111-943"><a href="#cb111-943"></a>            .with_columns(</span>
<span id="cb111-944"><a href="#cb111-944"></a>                pl.col(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb111-945"><a href="#cb111-945"></a>                    .rolling_sum_by(by<span class="op">=</span>pl.col(<span class="st">"TX_DATETIME"</span>)</span>
<span id="cb111-946"><a href="#cb111-946"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb111-947"><a href="#cb111-947"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb111-948"><a href="#cb111-948"></a>                        )</span>
<span id="cb111-949"><a href="#cb111-949"></a>                    .over(<span class="st">"CUSTOMER_ID"</span>)</span>
<span id="cb111-950"><a href="#cb111-950"></a>                .alias(<span class="ss">f"CID_NB_TX_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb111-951"><a href="#cb111-951"></a></span>
<span id="cb111-952"><a href="#cb111-952"></a>                pl.col(<span class="st">"TX_AMOUNT"</span>)</span>
<span id="cb111-953"><a href="#cb111-953"></a>                    .rolling_mean_by(by<span class="op">=</span>pl.col(<span class="st">"TX_DATETIME"</span>)</span>
<span id="cb111-954"><a href="#cb111-954"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb111-955"><a href="#cb111-955"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb111-956"><a href="#cb111-956"></a>                        )</span>
<span id="cb111-957"><a href="#cb111-957"></a>                    .over(<span class="st">"CUSTOMER_ID"</span>)</span>
<span id="cb111-958"><a href="#cb111-958"></a>                .alias(<span class="ss">f"CID_AVG_AMOUNT_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>)</span>
<span id="cb111-959"><a href="#cb111-959"></a>            )</span>
<span id="cb111-960"><a href="#cb111-960"></a>        )</span>
<span id="cb111-961"><a href="#cb111-961"></a></span>
<span id="cb111-962"><a href="#cb111-962"></a>    <span class="cf">return</span> result_df</span>
<span id="cb111-963"><a href="#cb111-963"></a><span class="in">```</span></span>
<span id="cb111-964"><a href="#cb111-964"></a></span>
<span id="cb111-965"><a href="#cb111-965"></a><span class="fu">### Terminal Features</span></span>
<span id="cb111-966"><a href="#cb111-966"></a></span>
<span id="cb111-967"><a href="#cb111-967"></a>The features describe a point-of-sale terminal's recent transactions count and the proportion of fraudulent transactions over several rolling time windows (1, 7, 30 days). A 7-day delay period is introduced because fraud labels are not be available immediately.</span>
<span id="cb111-968"><a href="#cb111-968"></a></span>
<span id="cb111-971"><a href="#cb111-971"></a><span class="in">```{python}</span></span>
<span id="cb111-972"><a href="#cb111-972"></a><span class="co">#| label: feature-terminal-risk</span></span>
<span id="cb111-973"><a href="#cb111-973"></a><span class="kw">def</span> fe_terminal_risk(</span>
<span id="cb111-974"><a href="#cb111-974"></a>    df: pl.DataFrame, </span>
<span id="cb111-975"><a href="#cb111-975"></a>    delay_period_days: <span class="bu">int</span> <span class="op">=</span> <span class="dv">7</span>, </span>
<span id="cb111-976"><a href="#cb111-976"></a>    window_sizes_in_days: <span class="bu">list</span> <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>]</span>
<span id="cb111-977"><a href="#cb111-977"></a>) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb111-978"><a href="#cb111-978"></a>    <span class="co">"""</span></span>
<span id="cb111-979"><a href="#cb111-979"></a><span class="co">    Adds terminal risk features for various window sizes, considering a 7-day delay in fraud labeling.</span></span>
<span id="cb111-980"><a href="#cb111-980"></a><span class="co">    For each window, computes:</span></span>
<span id="cb111-981"><a href="#cb111-981"></a><span class="co">        - Number of transactions at the terminal in the window (lagged by delay_period_days)</span></span>
<span id="cb111-982"><a href="#cb111-982"></a><span class="co">        - Proportion of fraudulent transactions at the terminal in the window (lagged)</span></span>
<span id="cb111-983"><a href="#cb111-983"></a><span class="co">    """</span></span>
<span id="cb111-984"><a href="#cb111-984"></a>    <span class="co"># Sort by TERMINAL_ID and TX_DATETIME for correct rolling calculations</span></span>
<span id="cb111-985"><a href="#cb111-985"></a>    df_int <span class="op">=</span> (</span>
<span id="cb111-986"><a href="#cb111-986"></a>        df</span>
<span id="cb111-987"><a href="#cb111-987"></a>        .sort(pl.col(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb111-988"><a href="#cb111-988"></a>            , pl.col(<span class="st">"TX_DATETIME"</span>)</span>
<span id="cb111-989"><a href="#cb111-989"></a>        )</span>
<span id="cb111-990"><a href="#cb111-990"></a>        .with_columns(</span>
<span id="cb111-991"><a href="#cb111-991"></a>            pl.col(<span class="st">"TERMINAL_ID"</span>).cast(pl.UInt64),</span>
<span id="cb111-992"><a href="#cb111-992"></a>            pl.lit(<span class="dv">1</span>).alias(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb111-993"><a href="#cb111-993"></a>        )</span>
<span id="cb111-994"><a href="#cb111-994"></a>    )</span>
<span id="cb111-995"><a href="#cb111-995"></a></span>
<span id="cb111-996"><a href="#cb111-996"></a>    result_df <span class="op">=</span> df_int</span>
<span id="cb111-997"><a href="#cb111-997"></a>    <span class="cf">for</span> window <span class="kw">in</span> window_sizes_in_days:</span>
<span id="cb111-998"><a href="#cb111-998"></a></span>
<span id="cb111-999"><a href="#cb111-999"></a>        full_offset <span class="op">=</span> window <span class="op">+</span> delay_period_days</span>
<span id="cb111-1000"><a href="#cb111-1000"></a></span>
<span id="cb111-1001"><a href="#cb111-1001"></a>        <span class="co"># Rolling window with delay (offset)</span></span>
<span id="cb111-1002"><a href="#cb111-1002"></a>        result_df <span class="op">=</span> (</span>
<span id="cb111-1003"><a href="#cb111-1003"></a>            result_df</span>
<span id="cb111-1004"><a href="#cb111-1004"></a>            .with_columns(</span>
<span id="cb111-1005"><a href="#cb111-1005"></a>                pl.col(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb111-1006"><a href="#cb111-1006"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb111-1007"><a href="#cb111-1007"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb111-1008"><a href="#cb111-1008"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb111-1009"><a href="#cb111-1009"></a>                        )</span>
<span id="cb111-1010"><a href="#cb111-1010"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb111-1011"><a href="#cb111-1011"></a>                .alias(<span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb111-1012"><a href="#cb111-1012"></a></span>
<span id="cb111-1013"><a href="#cb111-1013"></a>                pl.col(<span class="st">"TX_COUNT"</span>)</span>
<span id="cb111-1014"><a href="#cb111-1014"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb111-1015"><a href="#cb111-1015"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb111-1016"><a href="#cb111-1016"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb111-1017"><a href="#cb111-1017"></a>                        )</span>
<span id="cb111-1018"><a href="#cb111-1018"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb111-1019"><a href="#cb111-1019"></a>                .alias(<span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb111-1020"><a href="#cb111-1020"></a></span>
<span id="cb111-1021"><a href="#cb111-1021"></a></span>
<span id="cb111-1022"><a href="#cb111-1022"></a>                pl.col(<span class="st">"TX_FRAUD"</span>)</span>
<span id="cb111-1023"><a href="#cb111-1023"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb111-1024"><a href="#cb111-1024"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb111-1025"><a href="#cb111-1025"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb111-1026"><a href="#cb111-1026"></a>                        )  </span>
<span id="cb111-1027"><a href="#cb111-1027"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb111-1028"><a href="#cb111-1028"></a>                .alias(<span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>),</span>
<span id="cb111-1029"><a href="#cb111-1029"></a></span>
<span id="cb111-1030"><a href="#cb111-1030"></a>                pl.col(<span class="st">"TX_FRAUD"</span>)</span>
<span id="cb111-1031"><a href="#cb111-1031"></a>                    .rolling_sum_by(<span class="st">"TX_DATETIME"</span></span>
<span id="cb111-1032"><a href="#cb111-1032"></a>                        , window_size<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">d"</span></span>
<span id="cb111-1033"><a href="#cb111-1033"></a>                        , closed<span class="op">=</span><span class="st">"both"</span></span>
<span id="cb111-1034"><a href="#cb111-1034"></a>                        )  </span>
<span id="cb111-1035"><a href="#cb111-1035"></a>                    .over(<span class="st">"TERMINAL_ID"</span>)</span>
<span id="cb111-1036"><a href="#cb111-1036"></a>                .alias(<span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span>)</span>
<span id="cb111-1037"><a href="#cb111-1037"></a>            )</span>
<span id="cb111-1038"><a href="#cb111-1038"></a></span>
<span id="cb111-1039"><a href="#cb111-1039"></a>        )</span>
<span id="cb111-1040"><a href="#cb111-1040"></a></span>
<span id="cb111-1041"><a href="#cb111-1041"></a>        <span class="co"># Compute risk (proportion of frauds)</span></span>
<span id="cb111-1042"><a href="#cb111-1042"></a>        risk_col <span class="op">=</span> <span class="ss">f"TID_RISK_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb111-1043"><a href="#cb111-1043"></a></span>
<span id="cb111-1044"><a href="#cb111-1044"></a>        nb_tx_col <span class="op">=</span> <span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb111-1045"><a href="#cb111-1045"></a>        nb_fraud_col <span class="op">=</span> <span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>window<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb111-1046"><a href="#cb111-1046"></a></span>
<span id="cb111-1047"><a href="#cb111-1047"></a>        nb_tx_col_fulloffset <span class="op">=</span> <span class="ss">f"TID_NB_TX_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb111-1048"><a href="#cb111-1048"></a>        nb_fraud_col_fulloffset <span class="op">=</span> <span class="ss">f"TID_NB_FRAUD_</span><span class="sc">{</span>full_offset<span class="sc">}</span><span class="ss">DAY_WINDOW"</span></span>
<span id="cb111-1049"><a href="#cb111-1049"></a></span>
<span id="cb111-1050"><a href="#cb111-1050"></a>        result_df <span class="op">=</span> (</span>
<span id="cb111-1051"><a href="#cb111-1051"></a>            result_df</span>
<span id="cb111-1052"><a href="#cb111-1052"></a>            .with_columns(</span>
<span id="cb111-1053"><a href="#cb111-1053"></a>                (pl.col(nb_tx_col_fulloffset) <span class="op">-</span> pl.col(nb_tx_col)).alias(nb_tx_col),</span>
<span id="cb111-1054"><a href="#cb111-1054"></a>                (pl.col(nb_fraud_col_fulloffset) <span class="op">-</span> pl.col(nb_fraud_col)).alias(nb_fraud_col)</span>
<span id="cb111-1055"><a href="#cb111-1055"></a>            )</span>
<span id="cb111-1056"><a href="#cb111-1056"></a>            .select(pl.col(<span class="st">"*"</span>)</span>
<span id="cb111-1057"><a href="#cb111-1057"></a>                .exclude([nb_tx_col_fulloffset, nb_fraud_col_fulloffset])</span>
<span id="cb111-1058"><a href="#cb111-1058"></a>                )</span>
<span id="cb111-1059"><a href="#cb111-1059"></a>            .with_columns(</span>
<span id="cb111-1060"><a href="#cb111-1060"></a>                pl.when(pl.col(nb_tx_col) <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb111-1061"><a href="#cb111-1061"></a>                    .then(pl.col(nb_fraud_col) <span class="op">/</span> (pl.col(nb_tx_col)))</span>
<span id="cb111-1062"><a href="#cb111-1062"></a>                    .otherwise(<span class="fl">0.0</span>)</span>
<span id="cb111-1063"><a href="#cb111-1063"></a>                .alias(risk_col)</span>
<span id="cb111-1064"><a href="#cb111-1064"></a>            )</span>
<span id="cb111-1065"><a href="#cb111-1065"></a></span>
<span id="cb111-1066"><a href="#cb111-1066"></a>        )</span>
<span id="cb111-1067"><a href="#cb111-1067"></a></span>
<span id="cb111-1068"><a href="#cb111-1068"></a>        <span class="co"># Drop the intermediate fraud count column</span></span>
<span id="cb111-1069"><a href="#cb111-1069"></a>        result_df <span class="op">=</span> result_df.drop(nb_fraud_col)</span>
<span id="cb111-1070"><a href="#cb111-1070"></a></span>
<span id="cb111-1071"><a href="#cb111-1071"></a>    <span class="cf">return</span> result_df</span>
<span id="cb111-1072"><a href="#cb111-1072"></a><span class="in">```</span></span>
<span id="cb111-1073"><a href="#cb111-1073"></a></span>
<span id="cb111-1074"><a href="#cb111-1074"></a><span class="fu">## Data Pipeline</span></span>
<span id="cb111-1075"><a href="#cb111-1075"></a></span>
<span id="cb111-1076"><a href="#cb111-1076"></a>The function applies each data transformation step in sequence using the <span class="in">`pipe`</span> method from Polars. This allows for a clean and readable feature engineering pipeline.</span>
<span id="cb111-1077"><a href="#cb111-1077"></a></span>
<span id="cb111-1080"><a href="#cb111-1080"></a><span class="in">```{python}</span></span>
<span id="cb111-1081"><a href="#cb111-1081"></a><span class="co">#| label: feature-engineering-pipeline-function</span></span>
<span id="cb111-1082"><a href="#cb111-1082"></a></span>
<span id="cb111-1083"><a href="#cb111-1083"></a><span class="kw">def</span> polars_feature_pipeline(df: pl.DataFrame) <span class="op">-&gt;</span> pl.DataFrame:</span>
<span id="cb111-1084"><a href="#cb111-1084"></a>    <span class="co">"""</span></span>
<span id="cb111-1085"><a href="#cb111-1085"></a><span class="co">    Apply all feature engineering steps in sequence using Polars pipe</span></span>
<span id="cb111-1086"><a href="#cb111-1086"></a><span class="co">    """</span></span>
<span id="cb111-1087"><a href="#cb111-1087"></a>    <span class="cf">return</span> (df.lazy()</span>
<span id="cb111-1088"><a href="#cb111-1088"></a>            .pipe(fe_is_weekend)</span>
<span id="cb111-1089"><a href="#cb111-1089"></a>            .pipe(fe_is_night)</span>
<span id="cb111-1090"><a href="#cb111-1090"></a>            .pipe(fe_customer_spending</span>
<span id="cb111-1091"><a href="#cb111-1091"></a>                ,window_sizes_in_days<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>])</span>
<span id="cb111-1092"><a href="#cb111-1092"></a>            .pipe(fe_terminal_risk</span>
<span id="cb111-1093"><a href="#cb111-1093"></a>                ,delay_period_days<span class="op">=</span><span class="dv">7</span></span>
<span id="cb111-1094"><a href="#cb111-1094"></a>                ,window_sizes_in_days<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">30</span>])</span>
<span id="cb111-1095"><a href="#cb111-1095"></a>            ) </span>
<span id="cb111-1096"><a href="#cb111-1096"></a><span class="in">```</span></span>
<span id="cb111-1097"><a href="#cb111-1097"></a></span>
<span id="cb111-1098"><a href="#cb111-1098"></a>Apply the data pipeline to <span class="in">`df_fraud`</span> and then split the data into training and calibration sets.</span>
<span id="cb111-1099"><a href="#cb111-1099"></a></span>
<span id="cb111-1102"><a href="#cb111-1102"></a><span class="in">```{python}</span></span>
<span id="cb111-1103"><a href="#cb111-1103"></a><span class="co">#| label: apply-feature-engineering</span></span>
<span id="cb111-1104"><a href="#cb111-1104"></a></span>
<span id="cb111-1105"><a href="#cb111-1105"></a>df_fraud_ft <span class="op">=</span> polars_feature_pipeline(df_fraud).collect()</span>
<span id="cb111-1106"><a href="#cb111-1106"></a></span>
<span id="cb111-1107"><a href="#cb111-1107"></a>df_train_ft <span class="op">=</span> split_data(df_fraud_ft, <span class="bu">type</span><span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb111-1108"><a href="#cb111-1108"></a>df_tuning_ft <span class="op">=</span> split_data(df_fraud_ft, <span class="bu">type</span><span class="op">=</span><span class="st">"tuning"</span>)</span>
<span id="cb111-1109"><a href="#cb111-1109"></a>df_test_ft <span class="op">=</span> split_data(df_fraud_ft, <span class="bu">type</span><span class="op">=</span><span class="st">"test"</span>)</span>
<span id="cb111-1110"><a href="#cb111-1110"></a><span class="in">```</span></span>
<span id="cb111-1111"><a href="#cb111-1111"></a></span>
<span id="cb111-1112"><a href="#cb111-1112"></a><span class="fu"># EDA: Compare `df_train_ft` and `df_tuning_ft`</span></span>
<span id="cb111-1113"><a href="#cb111-1113"></a></span>
<span id="cb111-1116"><a href="#cb111-1116"></a><span class="in">```{python}</span></span>
<span id="cb111-1117"><a href="#cb111-1117"></a><span class="co">#| label: eda-train-tuning-comparison-ft</span></span>
<span id="cb111-1118"><a href="#cb111-1118"></a></span>
<span id="cb111-1119"><a href="#cb111-1119"></a>p_frac <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb111-1120"><a href="#cb111-1120"></a></span>
<span id="cb111-1121"><a href="#cb111-1121"></a>ft_train_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb111-1122"><a href="#cb111-1122"></a>            df_train_ft.sample(fraction<span class="op">=</span>p_frac, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb111-1123"><a href="#cb111-1123"></a>            title<span class="op">=</span><span class="st">"Train-FT"</span>,</span>
<span id="cb111-1124"><a href="#cb111-1124"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb111-1125"><a href="#cb111-1125"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb111-1126"><a href="#cb111-1126"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb111-1127"><a href="#cb111-1127"></a>            )</span>
<span id="cb111-1128"><a href="#cb111-1128"></a></span>
<span id="cb111-1129"><a href="#cb111-1129"></a>ft_tuning_data_profile <span class="op">=</span> ProfileReport(</span>
<span id="cb111-1130"><a href="#cb111-1130"></a>            df_tuning_ft.sample(fraction<span class="op">=</span>p_frac<span class="op">*</span><span class="dv">2</span>, seed<span class="op">=</span><span class="dv">2025</span>).to_pandas(), </span>
<span id="cb111-1131"><a href="#cb111-1131"></a>            title<span class="op">=</span><span class="st">"Tuning-FT"</span>,</span>
<span id="cb111-1132"><a href="#cb111-1132"></a>            progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb111-1133"><a href="#cb111-1133"></a>            duplicates<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb111-1134"><a href="#cb111-1134"></a>            interactions<span class="op">=</span><span class="va">None</span></span>
<span id="cb111-1135"><a href="#cb111-1135"></a>            )</span>
<span id="cb111-1136"><a href="#cb111-1136"></a></span>
<span id="cb111-1137"><a href="#cb111-1137"></a>ft_compare_profile <span class="op">=</span> ft_train_data_profile.compare(ft_tuning_data_profile)</span>
<span id="cb111-1138"><a href="#cb111-1138"></a></span>
<span id="cb111-1139"><a href="#cb111-1139"></a>ft_compare_profile.to_file(<span class="st">"Lab04_eda_compare_train_tuning_ft.html"</span>)</span>
<span id="cb111-1140"><a href="#cb111-1140"></a><span class="in">```</span></span>
<span id="cb111-1141"><a href="#cb111-1141"></a></span>
<span id="cb111-1142"><a href="#cb111-1142"></a><span class="fu"># Modeling and Evaluation</span></span>
<span id="cb111-1143"><a href="#cb111-1143"></a></span>
<span id="cb111-1144"><a href="#cb111-1144"></a>The section implements and compares different strategies for handling imbalanced datasets.</span>
<span id="cb111-1145"><a href="#cb111-1145"></a></span>
<span id="cb111-1146"><a href="#cb111-1146"></a><span class="ss">-   </span>**Do-Nothing Pipeline**: No resampling, just feature engineering and model training.</span>
<span id="cb111-1147"><a href="#cb111-1147"></a><span class="ss">-   </span>**Class-Sensitive Evaluation Pipeline**: No resampling, but uses PR-AUC (average precision)) to select the best model.</span>
<span id="cb111-1148"><a href="#cb111-1148"></a><span class="ss">-   </span>**Cost-Sensitive Learning Pipeline**: Uses sample weights to handle class imbalance during model training.</span>
<span id="cb111-1149"><a href="#cb111-1149"></a><span class="ss">-   </span>**Undersampling Pipeline**: Undersamples the majority class to balance the training set before model training.</span>
<span id="cb111-1150"><a href="#cb111-1150"></a><span class="ss">-   </span>**Oversampling Pipeline**: Oversamples the minority class to balance the training set before model training.</span>
<span id="cb111-1151"><a href="#cb111-1151"></a><span class="ss">-   </span>**SMOTE Pipeline**: Applies SMOTE to generate synthetic samples for the minority class before model training.</span>
<span id="cb111-1152"><a href="#cb111-1152"></a><span class="ss">-   </span>**Hybrid Pipeline**: Combines oversampling and SMOTE to balance the training set before model training.</span>
<span id="cb111-1153"><a href="#cb111-1153"></a></span>
<span id="cb111-1154"><a href="#cb111-1154"></a>The section evalutes each strategy by using the tuning set and test set.</span>
<span id="cb111-1155"><a href="#cb111-1155"></a></span>
<span id="cb111-1156"><a href="#cb111-1156"></a>If the predicted probabilities are not well calibrated, we will calibrate them using isotonic regression.</span>
<span id="cb111-1157"><a href="#cb111-1157"></a></span>
<span id="cb111-1158"><a href="#cb111-1158"></a>Finally, we will select the optimal decision threshold based on the tuning set and evaluate the F1-score on the test set.</span>
<span id="cb111-1159"><a href="#cb111-1159"></a></span>
<span id="cb111-1160"><a href="#cb111-1160"></a><span class="fu">## Data</span></span>
<span id="cb111-1161"><a href="#cb111-1161"></a></span>
<span id="cb111-1162"><a href="#cb111-1162"></a><span class="ss">-   </span>The target label is <span class="in">`TX_FRAUD`</span>, which indicates whether a transaction is fraudulent (1) or not (0).</span>
<span id="cb111-1163"><a href="#cb111-1163"></a></span>
<span id="cb111-1164"><a href="#cb111-1164"></a><span class="ss">-   </span>The list of final features exclude features that are not relevant for modeling, such as IDs and datetime columns.</span>
<span id="cb111-1165"><a href="#cb111-1165"></a></span>
<span id="cb111-1168"><a href="#cb111-1168"></a><span class="in">```{python}</span></span>
<span id="cb111-1169"><a href="#cb111-1169"></a><span class="co">#| label: define-modeling-features</span></span>
<span id="cb111-1170"><a href="#cb111-1170"></a></span>
<span id="cb111-1171"><a href="#cb111-1171"></a>target_label <span class="op">=</span> <span class="st">"TX_FRAUD"</span></span>
<span id="cb111-1172"><a href="#cb111-1172"></a></span>
<span id="cb111-1173"><a href="#cb111-1173"></a>final_features <span class="op">=</span> [</span>
<span id="cb111-1174"><a href="#cb111-1174"></a>    <span class="st">'TX_AMOUNT'</span>,</span>
<span id="cb111-1175"><a href="#cb111-1175"></a>    <span class="st">'TX_DURING_WEEKEND'</span>, </span>
<span id="cb111-1176"><a href="#cb111-1176"></a>    <span class="st">'TX_DURING_NIGHT'</span>, </span>
<span id="cb111-1177"><a href="#cb111-1177"></a>    <span class="st">'CID_NB_TX_1DAY_WINDOW'</span>,</span>
<span id="cb111-1178"><a href="#cb111-1178"></a>    <span class="st">'CID_AVG_AMOUNT_1DAY_WINDOW'</span>, </span>
<span id="cb111-1179"><a href="#cb111-1179"></a>    <span class="st">'CID_NB_TX_7DAY_WINDOW'</span>,</span>
<span id="cb111-1180"><a href="#cb111-1180"></a>    <span class="st">'CID_AVG_AMOUNT_7DAY_WINDOW'</span>, </span>
<span id="cb111-1181"><a href="#cb111-1181"></a>    <span class="st">'CID_NB_TX_30DAY_WINDOW'</span>,</span>
<span id="cb111-1182"><a href="#cb111-1182"></a>    <span class="st">'CID_AVG_AMOUNT_30DAY_WINDOW'</span>, </span>
<span id="cb111-1183"><a href="#cb111-1183"></a>    <span class="st">'TID_NB_TX_1DAY_WINDOW'</span>,</span>
<span id="cb111-1184"><a href="#cb111-1184"></a>    <span class="st">'TID_RISK_1DAY_WINDOW'</span>, </span>
<span id="cb111-1185"><a href="#cb111-1185"></a>    <span class="st">'TID_NB_TX_7DAY_WINDOW'</span>,</span>
<span id="cb111-1186"><a href="#cb111-1186"></a>    <span class="st">'TID_RISK_7DAY_WINDOW'</span>, </span>
<span id="cb111-1187"><a href="#cb111-1187"></a>    <span class="st">'TID_NB_TX_30DAY_WINDOW'</span>,</span>
<span id="cb111-1188"><a href="#cb111-1188"></a>    <span class="st">'TID_RISK_30DAY_WINDOW'</span></span>
<span id="cb111-1189"><a href="#cb111-1189"></a>]</span>
<span id="cb111-1190"><a href="#cb111-1190"></a><span class="in">```</span></span>
<span id="cb111-1191"><a href="#cb111-1191"></a></span>
<span id="cb111-1192"><a href="#cb111-1192"></a>Setup features data frame and target series for training, tuning, and test sets. The data frames are converted to pandas data frames for compatibility with AutoGluon.</span>
<span id="cb111-1193"><a href="#cb111-1193"></a></span>
<span id="cb111-1196"><a href="#cb111-1196"></a><span class="in">```{python}</span></span>
<span id="cb111-1197"><a href="#cb111-1197"></a>X_train <span class="op">=</span> df_train_ft[final_features].to_pandas()</span>
<span id="cb111-1198"><a href="#cb111-1198"></a>y_train <span class="op">=</span> df_train_ft[target_label].to_pandas()</span>
<span id="cb111-1199"><a href="#cb111-1199"></a></span>
<span id="cb111-1200"><a href="#cb111-1200"></a>X_tuning <span class="op">=</span> df_tuning_ft[final_features].to_pandas()</span>
<span id="cb111-1201"><a href="#cb111-1201"></a>y_tuning <span class="op">=</span> df_tuning_ft[target_label].to_pandas()</span>
<span id="cb111-1202"><a href="#cb111-1202"></a></span>
<span id="cb111-1203"><a href="#cb111-1203"></a>X_test <span class="op">=</span> df_test_ft[final_features].to_pandas()</span>
<span id="cb111-1204"><a href="#cb111-1204"></a>y_test <span class="op">=</span> df_test_ft[target_label].to_pandas()</span>
<span id="cb111-1205"><a href="#cb111-1205"></a></span>
<span id="cb111-1206"><a href="#cb111-1206"></a>comparison_results <span class="op">=</span> []</span>
<span id="cb111-1207"><a href="#cb111-1207"></a><span class="in">```</span></span>
<span id="cb111-1208"><a href="#cb111-1208"></a></span>
<span id="cb111-1209"><a href="#cb111-1209"></a><span class="fu">## Do-Nothing Approach</span></span>
<span id="cb111-1210"><a href="#cb111-1210"></a></span>
<span id="cb111-1211"><a href="#cb111-1211"></a>**Concept Recap:** Train the model on the original, imbalanced training data. We will use <span class="in">`log_loss`</span> as the <span class="in">`eval_metric`</span> for AutoGluon to select the best base models.</span>
<span id="cb111-1212"><a href="#cb111-1212"></a></span>
<span id="cb111-1213"><a href="#cb111-1213"></a>Setup AutoGluon parameters.</span>
<span id="cb111-1214"><a href="#cb111-1214"></a></span>
<span id="cb111-1217"><a href="#cb111-1217"></a><span class="in">```{python}</span></span>
<span id="cb111-1218"><a href="#cb111-1218"></a><span class="co">#| label: setup-autogluon-do-nothing</span></span>
<span id="cb111-1219"><a href="#cb111-1219"></a></span>
<span id="cb111-1220"><a href="#cb111-1220"></a>strategy_name_1 <span class="op">=</span> <span class="st">"1. Do Nothing"</span></span>
<span id="cb111-1221"><a href="#cb111-1221"></a>model_folder_s1 <span class="op">=</span> <span class="st">"Lab04_ag_models_s1_do_nothing"</span></span>
<span id="cb111-1222"><a href="#cb111-1222"></a>remove_ag_folder(model_folder_s1)</span>
<span id="cb111-1223"><a href="#cb111-1223"></a></span>
<span id="cb111-1224"><a href="#cb111-1224"></a>predictor_args_s1 <span class="op">=</span> {</span>
<span id="cb111-1225"><a href="#cb111-1225"></a>    <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb111-1226"><a href="#cb111-1226"></a>    <span class="st">'eval_metric'</span>: <span class="st">'log_loss'</span>, </span>
<span id="cb111-1227"><a href="#cb111-1227"></a>    <span class="st">'path'</span>: model_folder_s1</span>
<span id="cb111-1228"><a href="#cb111-1228"></a>}</span>
<span id="cb111-1229"><a href="#cb111-1229"></a></span>
<span id="cb111-1230"><a href="#cb111-1230"></a>fit_args_s1 <span class="op">=</span> {<span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb111-1231"><a href="#cb111-1231"></a>            <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb111-1232"><a href="#cb111-1232"></a>            <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb111-1233"><a href="#cb111-1233"></a>            <span class="st">'time_limit'</span>: <span class="dv">300</span>}</span>
<span id="cb111-1234"><a href="#cb111-1234"></a></span>
<span id="cb111-1235"><a href="#cb111-1235"></a>ag_wrapper_s1 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb111-1236"><a href="#cb111-1236"></a>    label<span class="op">=</span>target_label,</span>
<span id="cb111-1237"><a href="#cb111-1237"></a>    predictor_args<span class="op">=</span>predictor_args_s1,</span>
<span id="cb111-1238"><a href="#cb111-1238"></a>    fit_args<span class="op">=</span>fit_args_s1</span>
<span id="cb111-1239"><a href="#cb111-1239"></a>)</span>
<span id="cb111-1240"><a href="#cb111-1240"></a><span class="in">```</span></span>
<span id="cb111-1241"><a href="#cb111-1241"></a></span>
<span id="cb111-1242"><a href="#cb111-1242"></a>Fit the model using AutoGluon.</span>
<span id="cb111-1243"><a href="#cb111-1243"></a></span>
<span id="cb111-1246"><a href="#cb111-1246"></a><span class="in">```{python}</span></span>
<span id="cb111-1247"><a href="#cb111-1247"></a>ag_model_s1 <span class="op">=</span> ag_wrapper_s1.fit(X_train, y_train)</span>
<span id="cb111-1248"><a href="#cb111-1248"></a></span>
<span id="cb111-1249"><a href="#cb111-1249"></a>ag_model_s1.predictor.save()  <span class="co"># Save the predictor for later use</span></span>
<span id="cb111-1250"><a href="#cb111-1250"></a><span class="in">```</span></span>
<span id="cb111-1251"><a href="#cb111-1251"></a></span>
<span id="cb111-1252"><a href="#cb111-1252"></a>Access the AutoGluon predictor object.</span>
<span id="cb111-1255"><a href="#cb111-1255"></a><span class="in">```{python}</span></span>
<span id="cb111-1256"><a href="#cb111-1256"></a><span class="co">#| label: access-autogluon-predictor-s1</span></span>
<span id="cb111-1257"><a href="#cb111-1257"></a></span>
<span id="cb111-1258"><a href="#cb111-1258"></a>ag_model_s1_predictor <span class="op">=</span> ag_model_s1.predictor</span>
<span id="cb111-1259"><a href="#cb111-1259"></a></span>
<span id="cb111-1260"><a href="#cb111-1260"></a><span class="in">```</span></span>
<span id="cb111-1261"><a href="#cb111-1261"></a></span>
<span id="cb111-1262"><a href="#cb111-1262"></a>Check the leaderboard.</span>
<span id="cb111-1263"><a href="#cb111-1263"></a></span>
<span id="cb111-1266"><a href="#cb111-1266"></a><span class="in">```{python}</span></span>
<span id="cb111-1267"><a href="#cb111-1267"></a><span class="co">#| label: leaderboard-s1</span></span>
<span id="cb111-1268"><a href="#cb111-1268"></a>leaderboard_s1 <span class="op">=</span> ag_model_s1_predictor.leaderboard(</span>
<span id="cb111-1269"><a href="#cb111-1269"></a>    df_tuning_ft.to_pandas()</span>
<span id="cb111-1270"><a href="#cb111-1270"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>]</span>
<span id="cb111-1271"><a href="#cb111-1271"></a>)</span>
<span id="cb111-1272"><a href="#cb111-1272"></a>display(leaderboard_s1)</span>
<span id="cb111-1273"><a href="#cb111-1273"></a><span class="in">```</span></span>
<span id="cb111-1274"><a href="#cb111-1274"></a></span>
<span id="cb111-1275"><a href="#cb111-1275"></a>Set the best model to CatBoost due to inference speed and performance.</span>
<span id="cb111-1276"><a href="#cb111-1276"></a></span>
<span id="cb111-1279"><a href="#cb111-1279"></a><span class="in">```{python}</span></span>
<span id="cb111-1280"><a href="#cb111-1280"></a><span class="co">#| label: set-best-model-s1</span></span>
<span id="cb111-1281"><a href="#cb111-1281"></a></span>
<span id="cb111-1282"><a href="#cb111-1282"></a>ag_model_s1_predictor.set_model_best(<span class="st">'CatBoost'</span>)</span>
<span id="cb111-1283"><a href="#cb111-1283"></a></span>
<span id="cb111-1284"><a href="#cb111-1284"></a>ag_model_s1.predictor.save()  <span class="co"># Save the predictor for later use</span></span>
<span id="cb111-1285"><a href="#cb111-1285"></a></span>
<span id="cb111-1286"><a href="#cb111-1286"></a><span class="in">```</span></span>
<span id="cb111-1287"><a href="#cb111-1287"></a></span>
<span id="cb111-1288"><a href="#cb111-1288"></a>Check feature importance.</span>
<span id="cb111-1289"><a href="#cb111-1289"></a></span>
<span id="cb111-1292"><a href="#cb111-1292"></a><span class="in">```{python}</span></span>
<span id="cb111-1293"><a href="#cb111-1293"></a><span class="co">#| label: feature-importance-s1</span></span>
<span id="cb111-1294"><a href="#cb111-1294"></a></span>
<span id="cb111-1295"><a href="#cb111-1295"></a>feature_importance_s1 <span class="op">=</span> ag_model_s1_predictor.feature_importance(</span>
<span id="cb111-1296"><a href="#cb111-1296"></a>    df_tuning_ft.to_pandas(),</span>
<span id="cb111-1297"><a href="#cb111-1297"></a>    subsample_size <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb111-1298"><a href="#cb111-1298"></a>    num_shuffle_sets <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb111-1299"><a href="#cb111-1299"></a>)</span>
<span id="cb111-1300"><a href="#cb111-1300"></a></span>
<span id="cb111-1301"><a href="#cb111-1301"></a>display(feature_importance_s1)</span>
<span id="cb111-1302"><a href="#cb111-1302"></a><span class="in">```</span></span>
<span id="cb111-1303"><a href="#cb111-1303"></a></span>
<span id="cb111-1304"><a href="#cb111-1304"></a>Check probability calibration using the tuning set.</span>
<span id="cb111-1305"><a href="#cb111-1305"></a></span>
<span id="cb111-1308"><a href="#cb111-1308"></a><span class="in">```{python}</span></span>
<span id="cb111-1309"><a href="#cb111-1309"></a><span class="co">#| label: calibration-s1</span></span>
<span id="cb111-1310"><a href="#cb111-1310"></a><span class="co">#| </span></span>
<span id="cb111-1311"><a href="#cb111-1311"></a></span>
<span id="cb111-1312"><a href="#cb111-1312"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb111-1313"><a href="#cb111-1313"></a></span>
<span id="cb111-1314"><a href="#cb111-1314"></a>pre_cal_disp_s1 <span class="op">=</span> CalibrationDisplay.from_estimator(</span>
<span id="cb111-1315"><a href="#cb111-1315"></a>        estimator <span class="op">=</span> ag_model_s1,</span>
<span id="cb111-1316"><a href="#cb111-1316"></a>        X <span class="op">=</span> X_tuning,</span>
<span id="cb111-1317"><a href="#cb111-1317"></a>        y <span class="op">=</span> y_tuning,</span>
<span id="cb111-1318"><a href="#cb111-1318"></a>        n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb111-1319"><a href="#cb111-1319"></a>        name <span class="op">=</span> <span class="st">'Pre-Calib Curve: Do Nothing Strategy'</span>,</span>
<span id="cb111-1320"><a href="#cb111-1320"></a>        color <span class="op">=</span> <span class="st">'orange'</span></span>
<span id="cb111-1321"><a href="#cb111-1321"></a>    )</span>
<span id="cb111-1322"><a href="#cb111-1322"></a></span>
<span id="cb111-1323"><a href="#cb111-1323"></a>pre_cal_disp_s1.ax_.set_title(<span class="st">"Calibration Plot (Tuning Set)"</span>)</span>
<span id="cb111-1324"><a href="#cb111-1324"></a><span class="in">```</span></span>
<span id="cb111-1325"><a href="#cb111-1325"></a></span>
<span id="cb111-1326"><a href="#cb111-1326"></a>Fit a calibration model (isotonic regression) to the predicted probabilities from the tuning set. After fitting, we can no longer use the tuning set for calibration evaluation due to potential overfitting on the tuning set.</span>
<span id="cb111-1327"><a href="#cb111-1327"></a></span>
<span id="cb111-1330"><a href="#cb111-1330"></a><span class="in">```{python}</span></span>
<span id="cb111-1331"><a href="#cb111-1331"></a>cal_model_s1 <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb111-1332"><a href="#cb111-1332"></a>    estimator <span class="op">=</span> ag_model_s1,</span>
<span id="cb111-1333"><a href="#cb111-1333"></a>    method<span class="op">=</span><span class="st">'isotonic'</span>,</span>
<span id="cb111-1334"><a href="#cb111-1334"></a>    cv<span class="op">=</span><span class="st">"prefit"</span> <span class="co"># Use the fitted model from ag_model</span></span>
<span id="cb111-1335"><a href="#cb111-1335"></a>)</span>
<span id="cb111-1336"><a href="#cb111-1336"></a></span>
<span id="cb111-1337"><a href="#cb111-1337"></a>global_set_seed()</span>
<span id="cb111-1338"><a href="#cb111-1338"></a></span>
<span id="cb111-1339"><a href="#cb111-1339"></a>cal_model_s1.fit(X <span class="op">=</span> X_tuning,</span>
<span id="cb111-1340"><a href="#cb111-1340"></a>            y <span class="op">=</span> y_tuning)</span>
<span id="cb111-1341"><a href="#cb111-1341"></a><span class="in">```</span></span>
<span id="cb111-1342"><a href="#cb111-1342"></a></span>
<span id="cb111-1343"><a href="#cb111-1343"></a>Since the isotonic regression model was fitted on the tuning set, we can no longer use the tuning set for calibration evaluation. We will use the test set for calibration evaluation.</span>
<span id="cb111-1344"><a href="#cb111-1344"></a></span>
<span id="cb111-1347"><a href="#cb111-1347"></a><span class="in">```{python}</span></span>
<span id="cb111-1348"><a href="#cb111-1348"></a><span class="co">#| label: calibration-s1-test</span></span>
<span id="cb111-1349"><a href="#cb111-1349"></a></span>
<span id="cb111-1350"><a href="#cb111-1350"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb111-1351"><a href="#cb111-1351"></a></span>
<span id="cb111-1352"><a href="#cb111-1352"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb111-1353"><a href="#cb111-1353"></a></span>
<span id="cb111-1354"><a href="#cb111-1354"></a><span class="cf">for</span> estimator, name, color <span class="kw">in</span> [(ag_model_s1, <span class="st">'Uncalib_CatBoost'</span>, <span class="st">'orange'</span>),</span>
<span id="cb111-1355"><a href="#cb111-1355"></a>          (cal_model_s1, <span class="st">'Calib_CatBoost'</span>, <span class="st">'blue'</span>)]:</span>
<span id="cb111-1356"><a href="#cb111-1356"></a></span>
<span id="cb111-1357"><a href="#cb111-1357"></a>  CalibrationDisplay.from_estimator(</span>
<span id="cb111-1358"><a href="#cb111-1358"></a>      estimator <span class="op">=</span> estimator,</span>
<span id="cb111-1359"><a href="#cb111-1359"></a>      X <span class="op">=</span> X_test,</span>
<span id="cb111-1360"><a href="#cb111-1360"></a>      y <span class="op">=</span> y_test,</span>
<span id="cb111-1361"><a href="#cb111-1361"></a>      n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb111-1362"><a href="#cb111-1362"></a>      name <span class="op">=</span> name,</span>
<span id="cb111-1363"><a href="#cb111-1363"></a>      color <span class="op">=</span> color,</span>
<span id="cb111-1364"><a href="#cb111-1364"></a>      ax <span class="op">=</span> ax</span>
<span id="cb111-1365"><a href="#cb111-1365"></a>    )</span>
<span id="cb111-1366"><a href="#cb111-1366"></a>    </span>
<span id="cb111-1367"><a href="#cb111-1367"></a>ax.set_title(<span class="st">"Calibration Plot (Test Set)"</span>)</span>
<span id="cb111-1368"><a href="#cb111-1368"></a>plt.show()</span>
<span id="cb111-1369"><a href="#cb111-1369"></a><span class="in">```</span></span>
<span id="cb111-1370"><a href="#cb111-1370"></a></span>
<span id="cb111-1371"><a href="#cb111-1371"></a>The uncalibrated CatBoost model shows **better** calibration than the calibrated model. This is likely due to the isotonic regression model overfitting to the tuning set. We will use the uncalibrated model to set the optimal decision threshold.</span>
<span id="cb111-1372"><a href="#cb111-1372"></a></span>
<span id="cb111-1373"><a href="#cb111-1373"></a>Evalulate the original decision threshold of 0.5 on the test set.</span>
<span id="cb111-1374"><a href="#cb111-1374"></a></span>
<span id="cb111-1377"><a href="#cb111-1377"></a><span class="in">```{python}</span></span>
<span id="cb111-1378"><a href="#cb111-1378"></a><span class="co">#| label: evaluate-default-threshold-s1</span></span>
<span id="cb111-1379"><a href="#cb111-1379"></a></span>
<span id="cb111-1380"><a href="#cb111-1380"></a>leaderboard_s1_default <span class="op">=</span> ag_model_s1_predictor.leaderboard(</span>
<span id="cb111-1381"><a href="#cb111-1381"></a>    df_test_ft.to_pandas()</span>
<span id="cb111-1382"><a href="#cb111-1382"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb111-1383"><a href="#cb111-1383"></a>)</span>
<span id="cb111-1384"><a href="#cb111-1384"></a></span>
<span id="cb111-1385"><a href="#cb111-1385"></a>display(leaderboard_s1_default)</span>
<span id="cb111-1386"><a href="#cb111-1386"></a></span>
<span id="cb111-1387"><a href="#cb111-1387"></a><span class="in">```</span></span>
<span id="cb111-1388"><a href="#cb111-1388"></a></span>
<span id="cb111-1389"><a href="#cb111-1389"></a>Since the tuning set is no longer being used for probability calibration, we will use it to find the optimal decision threshold that maximizes the F1-score.</span>
<span id="cb111-1390"><a href="#cb111-1390"></a></span>
<span id="cb111-1393"><a href="#cb111-1393"></a><span class="in">```{python}</span></span>
<span id="cb111-1394"><a href="#cb111-1394"></a><span class="co">#| label: threshold-tuning-s1</span></span>
<span id="cb111-1395"><a href="#cb111-1395"></a></span>
<span id="cb111-1396"><a href="#cb111-1396"></a>best_threshold_s1 <span class="op">=</span> (ag_model_s1_predictor</span>
<span id="cb111-1397"><a href="#cb111-1397"></a>                .calibrate_decision_threshold(</span>
<span id="cb111-1398"><a href="#cb111-1398"></a>                data <span class="op">=</span> df_tuning_ft.to_pandas(),</span>
<span id="cb111-1399"><a href="#cb111-1399"></a>                metric <span class="op">=</span> <span class="st">'f1'</span>,</span>
<span id="cb111-1400"><a href="#cb111-1400"></a>                decision_thresholds <span class="op">=</span> <span class="dv">200</span>)</span>
<span id="cb111-1401"><a href="#cb111-1401"></a>                )</span>
<span id="cb111-1402"><a href="#cb111-1402"></a></span>
<span id="cb111-1403"><a href="#cb111-1403"></a>ag_model_s1_predictor.set_decision_threshold(best_threshold_s1)</span>
<span id="cb111-1404"><a href="#cb111-1404"></a></span>
<span id="cb111-1405"><a href="#cb111-1405"></a>ag_model_s1_predictor.save()  <span class="co"># Save the predictor with the new threshold</span></span>
<span id="cb111-1406"><a href="#cb111-1406"></a><span class="in">```</span></span>
<span id="cb111-1407"><a href="#cb111-1407"></a></span>
<span id="cb111-1408"><a href="#cb111-1408"></a>Use the test set to evaluate the effectivness of the decision threshold.</span>
<span id="cb111-1409"><a href="#cb111-1409"></a></span>
<span id="cb111-1412"><a href="#cb111-1412"></a><span class="in">```{python}</span></span>
<span id="cb111-1413"><a href="#cb111-1413"></a><span class="co">#| label: evaluate-threshold-s1</span></span>
<span id="cb111-1414"><a href="#cb111-1414"></a></span>
<span id="cb111-1415"><a href="#cb111-1415"></a>leaderboard_s1_optimized <span class="op">=</span> ag_model_s1_predictor.leaderboard(</span>
<span id="cb111-1416"><a href="#cb111-1416"></a>    df_test_ft.to_pandas()</span>
<span id="cb111-1417"><a href="#cb111-1417"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb111-1418"><a href="#cb111-1418"></a>)</span>
<span id="cb111-1419"><a href="#cb111-1419"></a></span>
<span id="cb111-1420"><a href="#cb111-1420"></a>display(leaderboard_s1_optimized)</span>
<span id="cb111-1421"><a href="#cb111-1421"></a><span class="in">```</span></span>
<span id="cb111-1422"><a href="#cb111-1422"></a></span>
<span id="cb111-1423"><a href="#cb111-1423"></a>Tuning the decision threshold does not appear to substantially improve the F1-score on the test set. The default threshold of 0.5 yields a similar F1-score.</span>
<span id="cb111-1424"><a href="#cb111-1424"></a></span>
<span id="cb111-1425"><a href="#cb111-1425"></a></span>
<span id="cb111-1426"><a href="#cb111-1426"></a><span class="fu">## Class-Sensitive Evaluation Approach</span></span>
<span id="cb111-1427"><a href="#cb111-1427"></a></span>
<span id="cb111-1428"><a href="#cb111-1428"></a>**Concept Recap:** Train the model on the original, imbalanced training data. We will use <span class="in">`average_precision`</span> (aka PR-AUC) as the <span class="in">`eval_metric`</span> for AutoGluon to select the best base models.</span>
<span id="cb111-1429"><a href="#cb111-1429"></a></span>
<span id="cb111-1430"><a href="#cb111-1430"></a></span>
<span id="cb111-1431"><a href="#cb111-1431"></a>Setup AutoGluon parameters.</span>
<span id="cb111-1432"><a href="#cb111-1432"></a></span>
<span id="cb111-1435"><a href="#cb111-1435"></a><span class="in">```{python}</span></span>
<span id="cb111-1436"><a href="#cb111-1436"></a><span class="co">#| label: setup-autogluon-class-sensitive-evaluation</span></span>
<span id="cb111-1437"><a href="#cb111-1437"></a></span>
<span id="cb111-1438"><a href="#cb111-1438"></a>strategy_name_2 <span class="op">=</span> <span class="st">"2. Class Sensitive Evaluation"</span></span>
<span id="cb111-1439"><a href="#cb111-1439"></a>model_folder_s2 <span class="op">=</span> <span class="st">"Lab04_ag_models_s2_class_sensitive"</span></span>
<span id="cb111-1440"><a href="#cb111-1440"></a>remove_ag_folder(model_folder_s2)</span>
<span id="cb111-1441"><a href="#cb111-1441"></a></span>
<span id="cb111-1442"><a href="#cb111-1442"></a>predictor_args_s2 <span class="op">=</span> {</span>
<span id="cb111-1443"><a href="#cb111-1443"></a>    <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb111-1444"><a href="#cb111-1444"></a>    <span class="st">'eval_metric'</span>: <span class="st">'average_precision'</span>, </span>
<span id="cb111-1445"><a href="#cb111-1445"></a>    <span class="st">'path'</span>: model_folder_s2</span>
<span id="cb111-1446"><a href="#cb111-1446"></a>}</span>
<span id="cb111-1447"><a href="#cb111-1447"></a></span>
<span id="cb111-1448"><a href="#cb111-1448"></a>fit_args_s2 <span class="op">=</span> {<span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb111-1449"><a href="#cb111-1449"></a>            <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb111-1450"><a href="#cb111-1450"></a>            <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb111-1451"><a href="#cb111-1451"></a>            <span class="st">'time_limit'</span>: <span class="dv">300</span>}</span>
<span id="cb111-1452"><a href="#cb111-1452"></a></span>
<span id="cb111-1453"><a href="#cb111-1453"></a>ag_wrapper_s2 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb111-1454"><a href="#cb111-1454"></a>    label<span class="op">=</span>target_label,</span>
<span id="cb111-1455"><a href="#cb111-1455"></a>    predictor_args<span class="op">=</span>predictor_args_s2,</span>
<span id="cb111-1456"><a href="#cb111-1456"></a>    fit_args<span class="op">=</span>fit_args_s2</span>
<span id="cb111-1457"><a href="#cb111-1457"></a>)</span>
<span id="cb111-1458"><a href="#cb111-1458"></a><span class="in">```</span></span>
<span id="cb111-1459"><a href="#cb111-1459"></a></span>
<span id="cb111-1460"><a href="#cb111-1460"></a>Fit the model using AutoGluon.</span>
<span id="cb111-1461"><a href="#cb111-1461"></a></span>
<span id="cb111-1464"><a href="#cb111-1464"></a><span class="in">```{python}</span></span>
<span id="cb111-1465"><a href="#cb111-1465"></a><span class="co">#| label: fit-autogluon-class-sensitive-evaluation</span></span>
<span id="cb111-1466"><a href="#cb111-1466"></a><span class="co">#| </span></span>
<span id="cb111-1467"><a href="#cb111-1467"></a>ag_model_s2 <span class="op">=</span> ag_wrapper_s2.fit(X_train, y_train)</span>
<span id="cb111-1468"><a href="#cb111-1468"></a></span>
<span id="cb111-1469"><a href="#cb111-1469"></a>ag_model_s2.predictor.save()  <span class="co"># Save the predictor for later use</span></span>
<span id="cb111-1470"><a href="#cb111-1470"></a><span class="in">```</span></span>
<span id="cb111-1471"><a href="#cb111-1471"></a></span>
<span id="cb111-1472"><a href="#cb111-1472"></a>Access the AutoGluon predictor object.</span>
<span id="cb111-1475"><a href="#cb111-1475"></a><span class="in">```{python}</span></span>
<span id="cb111-1476"><a href="#cb111-1476"></a><span class="co">#| label: access-autogluon-predictor-s2</span></span>
<span id="cb111-1477"><a href="#cb111-1477"></a></span>
<span id="cb111-1478"><a href="#cb111-1478"></a>ag_model_s2_predictor <span class="op">=</span> ag_model_s2.predictor</span>
<span id="cb111-1479"><a href="#cb111-1479"></a></span>
<span id="cb111-1480"><a href="#cb111-1480"></a><span class="in">```</span></span>
<span id="cb111-1481"><a href="#cb111-1481"></a></span>
<span id="cb111-1482"><a href="#cb111-1482"></a>Check the leaderboard.</span>
<span id="cb111-1483"><a href="#cb111-1483"></a></span>
<span id="cb111-1486"><a href="#cb111-1486"></a><span class="in">```{python}</span></span>
<span id="cb111-1487"><a href="#cb111-1487"></a><span class="co">#| label: leaderboard-s2</span></span>
<span id="cb111-1488"><a href="#cb111-1488"></a><span class="co">#| </span></span>
<span id="cb111-1489"><a href="#cb111-1489"></a>leaderboard_s2 <span class="op">=</span> ag_model_s2_predictor.leaderboard(</span>
<span id="cb111-1490"><a href="#cb111-1490"></a>    df_tuning_ft.to_pandas()</span>
<span id="cb111-1491"><a href="#cb111-1491"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>]</span>
<span id="cb111-1492"><a href="#cb111-1492"></a>)</span>
<span id="cb111-1493"><a href="#cb111-1493"></a>display(leaderboard_s2)</span>
<span id="cb111-1494"><a href="#cb111-1494"></a><span class="in">```</span></span>
<span id="cb111-1495"><a href="#cb111-1495"></a></span>
<span id="cb111-1496"><a href="#cb111-1496"></a>Set the best model to CatBoost due to inference speed and performance.</span>
<span id="cb111-1497"><a href="#cb111-1497"></a></span>
<span id="cb111-1500"><a href="#cb111-1500"></a><span class="in">```{python}</span></span>
<span id="cb111-1501"><a href="#cb111-1501"></a><span class="co">#| label: set-best-model-s2</span></span>
<span id="cb111-1502"><a href="#cb111-1502"></a></span>
<span id="cb111-1503"><a href="#cb111-1503"></a>ag_model_s2_predictor.set_model_best(<span class="st">'CatBoost'</span>)</span>
<span id="cb111-1504"><a href="#cb111-1504"></a></span>
<span id="cb111-1505"><a href="#cb111-1505"></a>ag_model_s2.predictor.save()  <span class="co"># Save the predictor for later use</span></span>
<span id="cb111-1506"><a href="#cb111-1506"></a></span>
<span id="cb111-1507"><a href="#cb111-1507"></a><span class="in">```</span></span>
<span id="cb111-1508"><a href="#cb111-1508"></a></span>
<span id="cb111-1509"><a href="#cb111-1509"></a>Check feature importance.</span>
<span id="cb111-1510"><a href="#cb111-1510"></a></span>
<span id="cb111-1513"><a href="#cb111-1513"></a><span class="in">```{python}</span></span>
<span id="cb111-1514"><a href="#cb111-1514"></a><span class="co">#| label: feature-importance-s2</span></span>
<span id="cb111-1515"><a href="#cb111-1515"></a></span>
<span id="cb111-1516"><a href="#cb111-1516"></a>feature_importance_s2 <span class="op">=</span> ag_model_s2_predictor.feature_importance(</span>
<span id="cb111-1517"><a href="#cb111-1517"></a>    df_tuning_ft.to_pandas(),</span>
<span id="cb111-1518"><a href="#cb111-1518"></a>    subsample_size <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb111-1519"><a href="#cb111-1519"></a>    num_shuffle_sets <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb111-1520"><a href="#cb111-1520"></a>)</span>
<span id="cb111-1521"><a href="#cb111-1521"></a></span>
<span id="cb111-1522"><a href="#cb111-1522"></a>display(feature_importance_s2)</span>
<span id="cb111-1523"><a href="#cb111-1523"></a><span class="in">```</span></span>
<span id="cb111-1524"><a href="#cb111-1524"></a></span>
<span id="cb111-1525"><a href="#cb111-1525"></a>Check probability calibration using the tuning set.</span>
<span id="cb111-1526"><a href="#cb111-1526"></a></span>
<span id="cb111-1529"><a href="#cb111-1529"></a><span class="in">```{python}</span></span>
<span id="cb111-1530"><a href="#cb111-1530"></a><span class="co">#| label: calibration-s2</span></span>
<span id="cb111-1531"><a href="#cb111-1531"></a><span class="co">#| </span></span>
<span id="cb111-1532"><a href="#cb111-1532"></a></span>
<span id="cb111-1533"><a href="#cb111-1533"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb111-1534"><a href="#cb111-1534"></a></span>
<span id="cb111-1535"><a href="#cb111-1535"></a>pre_cal_disp_s2 <span class="op">=</span> CalibrationDisplay.from_estimator(</span>
<span id="cb111-1536"><a href="#cb111-1536"></a>        estimator <span class="op">=</span> ag_model_s2,</span>
<span id="cb111-1537"><a href="#cb111-1537"></a>        X <span class="op">=</span> X_tuning,</span>
<span id="cb111-1538"><a href="#cb111-1538"></a>        y <span class="op">=</span> y_tuning,</span>
<span id="cb111-1539"><a href="#cb111-1539"></a>        n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb111-1540"><a href="#cb111-1540"></a>        name <span class="op">=</span> <span class="st">'Pre-Calib Curve: Do Nothing Strategy'</span>,</span>
<span id="cb111-1541"><a href="#cb111-1541"></a>        color <span class="op">=</span> <span class="st">'orange'</span></span>
<span id="cb111-1542"><a href="#cb111-1542"></a>    )</span>
<span id="cb111-1543"><a href="#cb111-1543"></a></span>
<span id="cb111-1544"><a href="#cb111-1544"></a>pre_cal_disp_s2.ax_.set_title(<span class="st">"Calibration Plot (Tuning Set)"</span>)</span>
<span id="cb111-1545"><a href="#cb111-1545"></a><span class="in">```</span></span>
<span id="cb111-1546"><a href="#cb111-1546"></a></span>
<span id="cb111-1547"><a href="#cb111-1547"></a>Fit a calibration model (isotonic regression) to the predicted probabilities from the tuning set. After fitting, we can no longer use the tuning set for calibration evaluation due to potential overfitting on the tuning set.</span>
<span id="cb111-1548"><a href="#cb111-1548"></a></span>
<span id="cb111-1551"><a href="#cb111-1551"></a><span class="in">```{python}</span></span>
<span id="cb111-1552"><a href="#cb111-1552"></a>cal_model_s2 <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb111-1553"><a href="#cb111-1553"></a>    estimator <span class="op">=</span> ag_model_s2,</span>
<span id="cb111-1554"><a href="#cb111-1554"></a>    method<span class="op">=</span><span class="st">'isotonic'</span>,</span>
<span id="cb111-1555"><a href="#cb111-1555"></a>    cv<span class="op">=</span><span class="st">"prefit"</span> <span class="co"># Use the fitted model from ag_model</span></span>
<span id="cb111-1556"><a href="#cb111-1556"></a>)</span>
<span id="cb111-1557"><a href="#cb111-1557"></a></span>
<span id="cb111-1558"><a href="#cb111-1558"></a>global_set_seed()</span>
<span id="cb111-1559"><a href="#cb111-1559"></a></span>
<span id="cb111-1560"><a href="#cb111-1560"></a>cal_model_s2.fit(X <span class="op">=</span> X_tuning,</span>
<span id="cb111-1561"><a href="#cb111-1561"></a>            y <span class="op">=</span> y_tuning)</span>
<span id="cb111-1562"><a href="#cb111-1562"></a><span class="in">```</span></span>
<span id="cb111-1563"><a href="#cb111-1563"></a></span>
<span id="cb111-1564"><a href="#cb111-1564"></a>Since the isotonic regression model was fitted on the tuning set, we can no longer use the tuning set for calibration evaluation. We will use the test set for calibration evaluation.</span>
<span id="cb111-1565"><a href="#cb111-1565"></a></span>
<span id="cb111-1568"><a href="#cb111-1568"></a><span class="in">```{python}</span></span>
<span id="cb111-1569"><a href="#cb111-1569"></a><span class="co">#| label: calibration-s2-test</span></span>
<span id="cb111-1570"><a href="#cb111-1570"></a></span>
<span id="cb111-1571"><a href="#cb111-1571"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb111-1572"><a href="#cb111-1572"></a></span>
<span id="cb111-1573"><a href="#cb111-1573"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb111-1574"><a href="#cb111-1574"></a></span>
<span id="cb111-1575"><a href="#cb111-1575"></a><span class="cf">for</span> estimator, name, color <span class="kw">in</span> [(ag_model_s2, <span class="st">'Uncalib_CatBoost'</span>, <span class="st">'orange'</span>),</span>
<span id="cb111-1576"><a href="#cb111-1576"></a>          (cal_model_s2, <span class="st">'Calib_CatBoost'</span>, <span class="st">'blue'</span>)]:</span>
<span id="cb111-1577"><a href="#cb111-1577"></a></span>
<span id="cb111-1578"><a href="#cb111-1578"></a>  CalibrationDisplay.from_estimator(</span>
<span id="cb111-1579"><a href="#cb111-1579"></a>      estimator <span class="op">=</span> estimator,</span>
<span id="cb111-1580"><a href="#cb111-1580"></a>      X <span class="op">=</span> X_test,</span>
<span id="cb111-1581"><a href="#cb111-1581"></a>      y <span class="op">=</span> y_test,</span>
<span id="cb111-1582"><a href="#cb111-1582"></a>      n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb111-1583"><a href="#cb111-1583"></a>      name <span class="op">=</span> name,</span>
<span id="cb111-1584"><a href="#cb111-1584"></a>      color <span class="op">=</span> color,</span>
<span id="cb111-1585"><a href="#cb111-1585"></a>      ax <span class="op">=</span> ax</span>
<span id="cb111-1586"><a href="#cb111-1586"></a>    )</span>
<span id="cb111-1587"><a href="#cb111-1587"></a>    </span>
<span id="cb111-1588"><a href="#cb111-1588"></a>ax.set_title(<span class="st">"Calibration Plot (Test Set)"</span>)</span>
<span id="cb111-1589"><a href="#cb111-1589"></a>plt.show()</span>
<span id="cb111-1590"><a href="#cb111-1590"></a><span class="in">```</span></span>
<span id="cb111-1591"><a href="#cb111-1591"></a></span>
<span id="cb111-1592"><a href="#cb111-1592"></a>The uncalibrated CatBoost model shows **better** calibration than the calibrated model. This is likely due to the isotonic regression model overfitting to the tuning set. We will use the uncalibrated model to set the optimal decision threshold.</span>
<span id="cb111-1593"><a href="#cb111-1593"></a></span>
<span id="cb111-1594"><a href="#cb111-1594"></a>Evalulate the original decision threshold of 0.5 on the test set.</span>
<span id="cb111-1595"><a href="#cb111-1595"></a></span>
<span id="cb111-1598"><a href="#cb111-1598"></a><span class="in">```{python}</span></span>
<span id="cb111-1599"><a href="#cb111-1599"></a><span class="co">#| label: evaluate-default-threshold-s2</span></span>
<span id="cb111-1600"><a href="#cb111-1600"></a></span>
<span id="cb111-1601"><a href="#cb111-1601"></a>leaderboard_s2_default <span class="op">=</span> ag_model_s2_predictor.leaderboard(</span>
<span id="cb111-1602"><a href="#cb111-1602"></a>    df_test_ft.to_pandas()</span>
<span id="cb111-1603"><a href="#cb111-1603"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb111-1604"><a href="#cb111-1604"></a>)</span>
<span id="cb111-1605"><a href="#cb111-1605"></a></span>
<span id="cb111-1606"><a href="#cb111-1606"></a>display(leaderboard_s2_default)</span>
<span id="cb111-1607"><a href="#cb111-1607"></a></span>
<span id="cb111-1608"><a href="#cb111-1608"></a><span class="in">```</span></span>
<span id="cb111-1609"><a href="#cb111-1609"></a></span>
<span id="cb111-1610"><a href="#cb111-1610"></a>Since the tuning set is no longer being used for probability calibration, we will use it to find the optimal decision threshold that maximizes the F1-score.</span>
<span id="cb111-1611"><a href="#cb111-1611"></a></span>
<span id="cb111-1614"><a href="#cb111-1614"></a><span class="in">```{python}</span></span>
<span id="cb111-1615"><a href="#cb111-1615"></a><span class="co">#| label: threshold-tuning-s2</span></span>
<span id="cb111-1616"><a href="#cb111-1616"></a></span>
<span id="cb111-1617"><a href="#cb111-1617"></a>best_threshold_s2 <span class="op">=</span> (ag_model_s2_predictor</span>
<span id="cb111-1618"><a href="#cb111-1618"></a>                .calibrate_decision_threshold(</span>
<span id="cb111-1619"><a href="#cb111-1619"></a>                data <span class="op">=</span> df_tuning_ft.to_pandas(),</span>
<span id="cb111-1620"><a href="#cb111-1620"></a>                metric <span class="op">=</span> <span class="st">'f1'</span>,</span>
<span id="cb111-1621"><a href="#cb111-1621"></a>                decision_thresholds <span class="op">=</span> <span class="dv">200</span>)</span>
<span id="cb111-1622"><a href="#cb111-1622"></a>                )</span>
<span id="cb111-1623"><a href="#cb111-1623"></a></span>
<span id="cb111-1624"><a href="#cb111-1624"></a>ag_model_s2_predictor.set_decision_threshold(best_threshold_s2)</span>
<span id="cb111-1625"><a href="#cb111-1625"></a></span>
<span id="cb111-1626"><a href="#cb111-1626"></a>ag_model_s2_predictor.save()  <span class="co"># Save the predictor with the new threshold</span></span>
<span id="cb111-1627"><a href="#cb111-1627"></a><span class="in">```</span></span>
<span id="cb111-1628"><a href="#cb111-1628"></a></span>
<span id="cb111-1629"><a href="#cb111-1629"></a>Use the test set to evaluate the effectivness of the decision threshold.</span>
<span id="cb111-1630"><a href="#cb111-1630"></a></span>
<span id="cb111-1633"><a href="#cb111-1633"></a><span class="in">```{python}</span></span>
<span id="cb111-1634"><a href="#cb111-1634"></a><span class="co">#| label: evaluate-threshold-s2</span></span>
<span id="cb111-1635"><a href="#cb111-1635"></a></span>
<span id="cb111-1636"><a href="#cb111-1636"></a>leaderboard_s2_optimized <span class="op">=</span> ag_model_s2_predictor.leaderboard(</span>
<span id="cb111-1637"><a href="#cb111-1637"></a>    df_test_ft.to_pandas()</span>
<span id="cb111-1638"><a href="#cb111-1638"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb111-1639"><a href="#cb111-1639"></a>)</span>
<span id="cb111-1640"><a href="#cb111-1640"></a></span>
<span id="cb111-1641"><a href="#cb111-1641"></a>display(leaderboard_s2_optimized)</span>
<span id="cb111-1642"><a href="#cb111-1642"></a><span class="in">```</span></span>
<span id="cb111-1643"><a href="#cb111-1643"></a></span>
<span id="cb111-1644"><a href="#cb111-1644"></a>Tuning the decision threshold does not appear to substantially improve the F1-score on the test set. The default threshold of 0.5 yields a similar F1-score.</span>
<span id="cb111-1645"><a href="#cb111-1645"></a></span>
<span id="cb111-1646"><a href="#cb111-1646"></a></span>
<span id="cb111-1647"><a href="#cb111-1647"></a><span class="fu">## Cost-Sensitive Learning Approach</span></span>
<span id="cb111-1648"><a href="#cb111-1648"></a></span>
<span id="cb111-1649"><a href="#cb111-1649"></a>**Concept Recap:** Cost-sensitive learning is achieved by assigning higher weights to the minority class (fraud) instances during training. AutoGluon handles this internally when <span class="in">`sample_weight='balance_weight'`</span> is specified. We will use <span class="in">`average_precision`</span> as the evaluation metric.</span>
<span id="cb111-1650"><a href="#cb111-1650"></a></span>
<span id="cb111-1651"><a href="#cb111-1651"></a>Setup AutoGluon parameters.</span>
<span id="cb111-1652"><a href="#cb111-1652"></a></span>
<span id="cb111-1655"><a href="#cb111-1655"></a><span class="in">```{python}</span></span>
<span id="cb111-1656"><a href="#cb111-1656"></a><span class="co">#| label: setup-autogluon-cost-sensitive</span></span>
<span id="cb111-1657"><a href="#cb111-1657"></a></span>
<span id="cb111-1658"><a href="#cb111-1658"></a>strategy_name_3 <span class="op">=</span> <span class="st">"3. Cost Sensitive Learning"</span></span>
<span id="cb111-1659"><a href="#cb111-1659"></a>model_folder_s3 <span class="op">=</span> <span class="st">"Lab04_ag_models_s3_cost_sensitive"</span></span>
<span id="cb111-1660"><a href="#cb111-1660"></a>remove_ag_folder(model_folder_s3)</span>
<span id="cb111-1661"><a href="#cb111-1661"></a></span>
<span id="cb111-1662"><a href="#cb111-1662"></a>predictor_args_s3 <span class="op">=</span> {</span>
<span id="cb111-1663"><a href="#cb111-1663"></a>    <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb111-1664"><a href="#cb111-1664"></a>    <span class="st">'eval_metric'</span>: <span class="st">'average_precision'</span>, </span>
<span id="cb111-1665"><a href="#cb111-1665"></a>    <span class="st">'path'</span>: model_folder_s3,</span>
<span id="cb111-1666"><a href="#cb111-1666"></a>    <span class="st">'sample_weight'</span>: <span class="st">'balance_weight'</span> <span class="co"># Use balance weights for cost-sensitive learning</span></span>
<span id="cb111-1667"><a href="#cb111-1667"></a>}</span>
<span id="cb111-1668"><a href="#cb111-1668"></a></span>
<span id="cb111-1669"><a href="#cb111-1669"></a>fit_args_s3 <span class="op">=</span> {<span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb111-1670"><a href="#cb111-1670"></a>            <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb111-1671"><a href="#cb111-1671"></a>            <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb111-1672"><a href="#cb111-1672"></a>            <span class="st">'time_limit'</span>: <span class="dv">300</span>}  </span>
<span id="cb111-1673"><a href="#cb111-1673"></a></span>
<span id="cb111-1674"><a href="#cb111-1674"></a>ag_wrapper_s3 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb111-1675"><a href="#cb111-1675"></a>    label<span class="op">=</span>target_label,</span>
<span id="cb111-1676"><a href="#cb111-1676"></a>    predictor_args<span class="op">=</span>predictor_args_s3,</span>
<span id="cb111-1677"><a href="#cb111-1677"></a>    fit_args<span class="op">=</span>fit_args_s3</span>
<span id="cb111-1678"><a href="#cb111-1678"></a>)</span>
<span id="cb111-1679"><a href="#cb111-1679"></a><span class="in">```</span></span>
<span id="cb111-1680"><a href="#cb111-1680"></a></span>
<span id="cb111-1681"><a href="#cb111-1681"></a>Fit the model using AutoGluon.</span>
<span id="cb111-1682"><a href="#cb111-1682"></a></span>
<span id="cb111-1685"><a href="#cb111-1685"></a><span class="in">```{python}</span></span>
<span id="cb111-1686"><a href="#cb111-1686"></a>ag_model_s3 <span class="op">=</span> ag_wrapper_s3.fit(X_train, y_train) </span>
<span id="cb111-1687"><a href="#cb111-1687"></a></span>
<span id="cb111-1688"><a href="#cb111-1688"></a>ag_model_s3.predictor.save()  <span class="co"># Save the predictor for later use</span></span>
<span id="cb111-1689"><a href="#cb111-1689"></a><span class="in">```</span></span>
<span id="cb111-1690"><a href="#cb111-1690"></a></span>
<span id="cb111-1691"><a href="#cb111-1691"></a>Access the AutoGluon predictor object.</span>
<span id="cb111-1694"><a href="#cb111-1694"></a><span class="in">```{python}</span></span>
<span id="cb111-1695"><a href="#cb111-1695"></a><span class="co">#| label: access-autogluon-predictor-s3</span></span>
<span id="cb111-1696"><a href="#cb111-1696"></a></span>
<span id="cb111-1697"><a href="#cb111-1697"></a>ag_model_s3_predictor <span class="op">=</span> ag_model_s3.predictor</span>
<span id="cb111-1698"><a href="#cb111-1698"></a></span>
<span id="cb111-1699"><a href="#cb111-1699"></a><span class="in">```</span></span>
<span id="cb111-1700"><a href="#cb111-1700"></a></span>
<span id="cb111-1701"><a href="#cb111-1701"></a>Check the leaderboard.</span>
<span id="cb111-1702"><a href="#cb111-1702"></a></span>
<span id="cb111-1705"><a href="#cb111-1705"></a><span class="in">```{python}</span></span>
<span id="cb111-1706"><a href="#cb111-1706"></a><span class="co">#| label: leaderboard-s3</span></span>
<span id="cb111-1707"><a href="#cb111-1707"></a>leaderboard_s3 <span class="op">=</span> ag_model_s3_predictor.leaderboard(</span>
<span id="cb111-1708"><a href="#cb111-1708"></a>    df_tuning_ft.to_pandas()</span>
<span id="cb111-1709"><a href="#cb111-1709"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>]</span>
<span id="cb111-1710"><a href="#cb111-1710"></a>)</span>
<span id="cb111-1711"><a href="#cb111-1711"></a>display(leaderboard_s3)</span>
<span id="cb111-1712"><a href="#cb111-1712"></a><span class="in">```</span></span>
<span id="cb111-1713"><a href="#cb111-1713"></a></span>
<span id="cb111-1714"><a href="#cb111-1714"></a>Set the best model to CatBoost due to inference speed and performance.</span>
<span id="cb111-1715"><a href="#cb111-1715"></a></span>
<span id="cb111-1718"><a href="#cb111-1718"></a><span class="in">```{python}</span></span>
<span id="cb111-1719"><a href="#cb111-1719"></a><span class="co">#| label: set-best-model-s3</span></span>
<span id="cb111-1720"><a href="#cb111-1720"></a></span>
<span id="cb111-1721"><a href="#cb111-1721"></a>ag_model_s3_predictor.set_model_best(<span class="st">'CatBoost'</span>)</span>
<span id="cb111-1722"><a href="#cb111-1722"></a></span>
<span id="cb111-1723"><a href="#cb111-1723"></a>ag_model_s3.predictor.save()  <span class="co"># Save the predictor for later use</span></span>
<span id="cb111-1724"><a href="#cb111-1724"></a></span>
<span id="cb111-1725"><a href="#cb111-1725"></a><span class="in">```</span></span>
<span id="cb111-1726"><a href="#cb111-1726"></a></span>
<span id="cb111-1727"><a href="#cb111-1727"></a>Check feature importance.</span>
<span id="cb111-1728"><a href="#cb111-1728"></a></span>
<span id="cb111-1731"><a href="#cb111-1731"></a><span class="in">```{python}</span></span>
<span id="cb111-1732"><a href="#cb111-1732"></a><span class="co">#| label: feature-importance-s3</span></span>
<span id="cb111-1733"><a href="#cb111-1733"></a></span>
<span id="cb111-1734"><a href="#cb111-1734"></a>feature_importance_s3 <span class="op">=</span> ag_model_s3_predictor.feature_importance(</span>
<span id="cb111-1735"><a href="#cb111-1735"></a>    df_tuning_ft.to_pandas(),</span>
<span id="cb111-1736"><a href="#cb111-1736"></a>    subsample_size <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb111-1737"><a href="#cb111-1737"></a>    num_shuffle_sets <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb111-1738"><a href="#cb111-1738"></a>)</span>
<span id="cb111-1739"><a href="#cb111-1739"></a></span>
<span id="cb111-1740"><a href="#cb111-1740"></a>display(feature_importance_s3)</span>
<span id="cb111-1741"><a href="#cb111-1741"></a><span class="in">```</span></span>
<span id="cb111-1742"><a href="#cb111-1742"></a></span>
<span id="cb111-1743"><a href="#cb111-1743"></a>Check probability calibration using the tuning set.</span>
<span id="cb111-1744"><a href="#cb111-1744"></a></span>
<span id="cb111-1747"><a href="#cb111-1747"></a><span class="in">```{python}</span></span>
<span id="cb111-1748"><a href="#cb111-1748"></a><span class="co">#| label: calibration-s3</span></span>
<span id="cb111-1749"><a href="#cb111-1749"></a><span class="co">#| </span></span>
<span id="cb111-1750"><a href="#cb111-1750"></a></span>
<span id="cb111-1751"><a href="#cb111-1751"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb111-1752"><a href="#cb111-1752"></a></span>
<span id="cb111-1753"><a href="#cb111-1753"></a>pre_cal_disp_s3 <span class="op">=</span> CalibrationDisplay.from_estimator(</span>
<span id="cb111-1754"><a href="#cb111-1754"></a>        estimator <span class="op">=</span> ag_model_s3,</span>
<span id="cb111-1755"><a href="#cb111-1755"></a>        X <span class="op">=</span> X_tuning,</span>
<span id="cb111-1756"><a href="#cb111-1756"></a>        y <span class="op">=</span> y_tuning,</span>
<span id="cb111-1757"><a href="#cb111-1757"></a>        n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb111-1758"><a href="#cb111-1758"></a>        name <span class="op">=</span> <span class="st">'Pre-Calib Curve: Do Nothing Strategy'</span>,</span>
<span id="cb111-1759"><a href="#cb111-1759"></a>        color <span class="op">=</span> <span class="st">'orange'</span></span>
<span id="cb111-1760"><a href="#cb111-1760"></a>    )</span>
<span id="cb111-1761"><a href="#cb111-1761"></a></span>
<span id="cb111-1762"><a href="#cb111-1762"></a>pre_cal_disp_s3.ax_.set_title(<span class="st">"Calibration Plot (Tuning Set)"</span>)</span>
<span id="cb111-1763"><a href="#cb111-1763"></a><span class="in">```</span></span>
<span id="cb111-1764"><a href="#cb111-1764"></a></span>
<span id="cb111-1765"><a href="#cb111-1765"></a>Fit a calibration model (isotonic regression) to the predicted probabilities from the tuning set. After fitting, we can no longer use the tuning set for calibration evaluation due to potential overfitting on the tuning set.</span>
<span id="cb111-1766"><a href="#cb111-1766"></a></span>
<span id="cb111-1769"><a href="#cb111-1769"></a><span class="in">```{python}</span></span>
<span id="cb111-1770"><a href="#cb111-1770"></a>cal_model_s3 <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb111-1771"><a href="#cb111-1771"></a>    estimator <span class="op">=</span> ag_model_s3,</span>
<span id="cb111-1772"><a href="#cb111-1772"></a>    method<span class="op">=</span><span class="st">'isotonic'</span>,</span>
<span id="cb111-1773"><a href="#cb111-1773"></a>    cv<span class="op">=</span><span class="st">"prefit"</span> <span class="co"># Use the fitted model from ag_model</span></span>
<span id="cb111-1774"><a href="#cb111-1774"></a>)</span>
<span id="cb111-1775"><a href="#cb111-1775"></a></span>
<span id="cb111-1776"><a href="#cb111-1776"></a>global_set_seed()</span>
<span id="cb111-1777"><a href="#cb111-1777"></a></span>
<span id="cb111-1778"><a href="#cb111-1778"></a>cal_model_s3.fit(X <span class="op">=</span> X_tuning,</span>
<span id="cb111-1779"><a href="#cb111-1779"></a>            y <span class="op">=</span> y_tuning)</span>
<span id="cb111-1780"><a href="#cb111-1780"></a><span class="in">```</span></span>
<span id="cb111-1781"><a href="#cb111-1781"></a></span>
<span id="cb111-1782"><a href="#cb111-1782"></a>Since the isotonic regression model was fitted on the tuning set, we can no longer use the tuning set for calibration evaluation. We will use the test set for calibration evaluation.</span>
<span id="cb111-1783"><a href="#cb111-1783"></a></span>
<span id="cb111-1786"><a href="#cb111-1786"></a><span class="in">```{python}</span></span>
<span id="cb111-1787"><a href="#cb111-1787"></a><span class="co">#| label: calibration-s3-test</span></span>
<span id="cb111-1788"><a href="#cb111-1788"></a></span>
<span id="cb111-1789"><a href="#cb111-1789"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb111-1790"><a href="#cb111-1790"></a></span>
<span id="cb111-1791"><a href="#cb111-1791"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb111-1792"><a href="#cb111-1792"></a></span>
<span id="cb111-1793"><a href="#cb111-1793"></a><span class="cf">for</span> estimator, name, color <span class="kw">in</span> [(ag_model_s3, <span class="st">'Uncalib_CatBoost'</span>, <span class="st">'orange'</span>),</span>
<span id="cb111-1794"><a href="#cb111-1794"></a>          (cal_model_s3, <span class="st">'Calib_CatBoost'</span>, <span class="st">'blue'</span>)]:</span>
<span id="cb111-1795"><a href="#cb111-1795"></a></span>
<span id="cb111-1796"><a href="#cb111-1796"></a>  CalibrationDisplay.from_estimator(</span>
<span id="cb111-1797"><a href="#cb111-1797"></a>      estimator <span class="op">=</span> estimator,</span>
<span id="cb111-1798"><a href="#cb111-1798"></a>      X <span class="op">=</span> X_test,</span>
<span id="cb111-1799"><a href="#cb111-1799"></a>      y <span class="op">=</span> y_test,</span>
<span id="cb111-1800"><a href="#cb111-1800"></a>      n_bins <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb111-1801"><a href="#cb111-1801"></a>      name <span class="op">=</span> name,</span>
<span id="cb111-1802"><a href="#cb111-1802"></a>      color <span class="op">=</span> color,</span>
<span id="cb111-1803"><a href="#cb111-1803"></a>      ax <span class="op">=</span> ax</span>
<span id="cb111-1804"><a href="#cb111-1804"></a>    )</span>
<span id="cb111-1805"><a href="#cb111-1805"></a>    </span>
<span id="cb111-1806"><a href="#cb111-1806"></a>ax.set_title(<span class="st">"Calibration Plot (Test Set)"</span>)</span>
<span id="cb111-1807"><a href="#cb111-1807"></a>plt.show()</span>
<span id="cb111-1808"><a href="#cb111-1808"></a><span class="in">```</span></span>
<span id="cb111-1809"><a href="#cb111-1809"></a></span>
<span id="cb111-1810"><a href="#cb111-1810"></a>The uncalibrated CatBoost model shows **better** calibration than the calibrated model. This is likely due to the isotonic regression model overfitting to the tuning set. We will use the uncalibrated model to set the optimal decision threshold.</span>
<span id="cb111-1811"><a href="#cb111-1811"></a></span>
<span id="cb111-1812"><a href="#cb111-1812"></a>Evalulate the original decision threshold of 0.5 on the test set.</span>
<span id="cb111-1813"><a href="#cb111-1813"></a></span>
<span id="cb111-1816"><a href="#cb111-1816"></a><span class="in">```{python}</span></span>
<span id="cb111-1817"><a href="#cb111-1817"></a><span class="co">#| label: evaluate-default-threshold-s3</span></span>
<span id="cb111-1818"><a href="#cb111-1818"></a></span>
<span id="cb111-1819"><a href="#cb111-1819"></a>leaderboard_s3_default <span class="op">=</span> ag_model_s3_predictor.leaderboard(</span>
<span id="cb111-1820"><a href="#cb111-1820"></a>    df_test_ft.to_pandas()</span>
<span id="cb111-1821"><a href="#cb111-1821"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb111-1822"><a href="#cb111-1822"></a>)</span>
<span id="cb111-1823"><a href="#cb111-1823"></a></span>
<span id="cb111-1824"><a href="#cb111-1824"></a>display(leaderboard_s3_default)</span>
<span id="cb111-1825"><a href="#cb111-1825"></a></span>
<span id="cb111-1826"><a href="#cb111-1826"></a><span class="in">```</span></span>
<span id="cb111-1827"><a href="#cb111-1827"></a></span>
<span id="cb111-1828"><a href="#cb111-1828"></a>Since the tuning set is no longer being used for probability calibration, we will use it to find the optimal decision threshold that maximizes the F1-score.</span>
<span id="cb111-1829"><a href="#cb111-1829"></a></span>
<span id="cb111-1832"><a href="#cb111-1832"></a><span class="in">```{python}</span></span>
<span id="cb111-1833"><a href="#cb111-1833"></a><span class="co">#| label: threshold-tuning-s3</span></span>
<span id="cb111-1834"><a href="#cb111-1834"></a></span>
<span id="cb111-1835"><a href="#cb111-1835"></a>best_threshold_s3 <span class="op">=</span> (ag_model_s3_predictor</span>
<span id="cb111-1836"><a href="#cb111-1836"></a>                .calibrate_decision_threshold(</span>
<span id="cb111-1837"><a href="#cb111-1837"></a>                data <span class="op">=</span> df_tuning_ft.to_pandas(),</span>
<span id="cb111-1838"><a href="#cb111-1838"></a>                metric <span class="op">=</span> <span class="st">'f1'</span>,</span>
<span id="cb111-1839"><a href="#cb111-1839"></a>                decision_thresholds <span class="op">=</span> <span class="dv">200</span>)</span>
<span id="cb111-1840"><a href="#cb111-1840"></a>                )</span>
<span id="cb111-1841"><a href="#cb111-1841"></a></span>
<span id="cb111-1842"><a href="#cb111-1842"></a>ag_model_s3_predictor.set_decision_threshold(best_threshold_s3)</span>
<span id="cb111-1843"><a href="#cb111-1843"></a></span>
<span id="cb111-1844"><a href="#cb111-1844"></a>ag_model_s3_predictor.save()  <span class="co"># Save the predictor with the new threshold</span></span>
<span id="cb111-1845"><a href="#cb111-1845"></a><span class="in">```</span></span>
<span id="cb111-1846"><a href="#cb111-1846"></a></span>
<span id="cb111-1847"><a href="#cb111-1847"></a>Use the test set to evaluate the effectivness of the decision threshold.</span>
<span id="cb111-1848"><a href="#cb111-1848"></a></span>
<span id="cb111-1851"><a href="#cb111-1851"></a><span class="in">```{python}</span></span>
<span id="cb111-1852"><a href="#cb111-1852"></a><span class="co">#| label: evaluate-threshold-s3</span></span>
<span id="cb111-1853"><a href="#cb111-1853"></a></span>
<span id="cb111-1854"><a href="#cb111-1854"></a>leaderboard_s3_optimized <span class="op">=</span> ag_model_s3_predictor.leaderboard(</span>
<span id="cb111-1855"><a href="#cb111-1855"></a>    df_test_ft.to_pandas()</span>
<span id="cb111-1856"><a href="#cb111-1856"></a>    , extra_metrics<span class="op">=</span>[<span class="st">'f1'</span>]</span>
<span id="cb111-1857"><a href="#cb111-1857"></a>)</span>
<span id="cb111-1858"><a href="#cb111-1858"></a></span>
<span id="cb111-1859"><a href="#cb111-1859"></a>display(leaderboard_s3_optimized)</span>
<span id="cb111-1860"><a href="#cb111-1860"></a><span class="in">```</span></span>
<span id="cb111-1861"><a href="#cb111-1861"></a></span>
<span id="cb111-1862"><a href="#cb111-1862"></a>Tuning the decision threshold does not appear to substantially improve the F1-score on the test set. The default threshold of 0.5 yields a similar F1-score.</span>
<span id="cb111-1863"><a href="#cb111-1863"></a></span>
<span id="cb111-1864"><a href="#cb111-1864"></a>**stopped here 6/4**</span>
<span id="cb111-1865"><a href="#cb111-1865"></a></span>
<span id="cb111-1866"><a href="#cb111-1866"></a></span>
<span id="cb111-1867"><a href="#cb111-1867"></a><span class="fu">## Resampling Approach</span></span>
<span id="cb111-1868"><a href="#cb111-1868"></a></span>
<span id="cb111-1869"><a href="#cb111-1869"></a>**Concept Recap:** Modify the training data distribution to be more balanced. We will use SMOTE (Synthetic Minority Over-sampling Technique) to oversample the minority (fraud) class in the training set. The tuning and test sets remain unchanged. Probability calibration after training on resampled data is a critical concern.</span>
<span id="cb111-1870"><a href="#cb111-1870"></a></span>
<span id="cb111-1871"><a href="#cb111-1871"></a><span class="fu">### Random Undersampling of Majority Class (RUS)</span></span>
<span id="cb111-1872"><a href="#cb111-1872"></a></span>
<span id="cb111-1873"><a href="#cb111-1873"></a><span class="fu">### Random Oversampling of Minority Class (ROS)</span></span>
<span id="cb111-1874"><a href="#cb111-1874"></a></span>
<span id="cb111-1877"><a href="#cb111-1877"></a><span class="in">```{python}</span></span>
<span id="cb111-1878"><a href="#cb111-1878"></a><span class="co">#| label: model-strategy4-resampling-prep</span></span>
<span id="cb111-1879"><a href="#cb111-1879"></a></span>
<span id="cb111-1880"><a href="#cb111-1880"></a><span class="cf">if</span> X_train.empty:</span>
<span id="cb111-1881"><a href="#cb111-1881"></a>    <span class="bu">print</span>(<span class="st">"Skipping data preparation for Strategy 4: Training data is empty."</span>)</span>
<span id="cb111-1882"><a href="#cb111-1882"></a>    X_train_smote, y_train_smote <span class="op">=</span> pd.DataFrame(), pd.Series(dtype<span class="op">=</span><span class="st">'int'</span>) <span class="co"># Placeholders</span></span>
<span id="cb111-1883"><a href="#cb111-1883"></a><span class="cf">else</span>:</span>
<span id="cb111-1884"><a href="#cb111-1884"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Preparing Resampled Training Data (SMOTE) for Strategy 4 ---"</span>)</span>
<span id="cb111-1885"><a href="#cb111-1885"></a>    </span>
<span id="cb111-1886"><a href="#cb111-1886"></a>    <span class="co"># Initialize SMOTE. We can adjust the sampling_strategy if needed.</span></span>
<span id="cb111-1887"><a href="#cb111-1887"></a>    <span class="co"># Default is to oversample the minority class to have an equal number of samples as the majority class.</span></span>
<span id="cb111-1888"><a href="#cb111-1888"></a>    smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">2025</span>, k_neighbors<span class="op">=</span><span class="dv">5</span>) <span class="co"># k_neighbors should be less than minority samples</span></span>
<span id="cb111-1889"><a href="#cb111-1889"></a>    </span>
<span id="cb111-1890"><a href="#cb111-1890"></a>    <span class="co"># Check minority class size for k_neighbors</span></span>
<span id="cb111-1891"><a href="#cb111-1891"></a>    minority_class_count <span class="op">=</span> y_train.value_counts().<span class="bu">min</span>()</span>
<span id="cb111-1892"><a href="#cb111-1892"></a>    <span class="cf">if</span> minority_class_count <span class="op">&lt;=</span> smote.k_neighbors:</span>
<span id="cb111-1893"><a href="#cb111-1893"></a>        <span class="co"># Adjust k_neighbors if it's too large for the number of minority samples</span></span>
<span id="cb111-1894"><a href="#cb111-1894"></a>        <span class="co"># This is a common issue with very small minority classes in CV folds or small datasets.</span></span>
<span id="cb111-1895"><a href="#cb111-1895"></a>        new_k <span class="op">=</span> <span class="bu">max</span>(<span class="dv">1</span>, minority_class_count <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb111-1896"><a href="#cb111-1896"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Original k_neighbors (</span><span class="sc">{</span>smote<span class="sc">.</span>k_neighbors<span class="sc">}</span><span class="ss">) for SMOTE is &gt;= minority samples (</span><span class="sc">{</span>minority_class_count<span class="sc">}</span><span class="ss">). Adjusting k_neighbors to </span><span class="sc">{</span>new_k<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb111-1897"><a href="#cb111-1897"></a>        smote.k_neighbors <span class="op">=</span> new_k</span>
<span id="cb111-1898"><a href="#cb111-1898"></a></span>
<span id="cb111-1899"><a href="#cb111-1899"></a>    <span class="cf">if</span> minority_class_count <span class="op">&gt;</span> <span class="dv">1</span>: <span class="co"># SMOTE needs at least 2 samples in the minority class to operate with k_neighbors=1</span></span>
<span id="cb111-1900"><a href="#cb111-1900"></a>        start_time_smote <span class="op">=</span> time.time()</span>
<span id="cb111-1901"><a href="#cb111-1901"></a>        <span class="cf">try</span>:</span>
<span id="cb111-1902"><a href="#cb111-1902"></a>            X_train_smote, y_train_smote <span class="op">=</span> smote.fit_resample(X_train, y_train)</span>
<span id="cb111-1903"><a href="#cb111-1903"></a>            end_time_smote <span class="op">=</span> time.time()</span>
<span id="cb111-1904"><a href="#cb111-1904"></a>            <span class="bu">print</span>(<span class="ss">f"SMOTE applied in </span><span class="sc">{</span>end_time_smote <span class="op">-</span> start_time_smote<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb111-1905"><a href="#cb111-1905"></a>            <span class="bu">print</span>(<span class="ss">f"Resampled training data shape: </span><span class="sc">{</span>X_train_smote<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, Resampled target distribution:</span><span class="ch">\n</span><span class="sc">{</span>y_train_smote<span class="sc">.</span>value_counts(normalize<span class="op">=</span><span class="va">True</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-1906"><a href="#cb111-1906"></a>        <span class="cf">except</span> <span class="pp">ValueError</span> <span class="im">as</span> e:</span>
<span id="cb111-1907"><a href="#cb111-1907"></a>            <span class="bu">print</span>(<span class="ss">f"Error during SMOTE: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">. This can happen if minority class count is too low for k_neighbors."</span>)</span>
<span id="cb111-1908"><a href="#cb111-1908"></a>            <span class="bu">print</span>(<span class="st">"Skipping SMOTE, proceeding with original data for this strategy as a fallback."</span>)</span>
<span id="cb111-1909"><a href="#cb111-1909"></a>            X_train_smote, y_train_smote <span class="op">=</span> X_train.copy(), y_train.copy()</span>
<span id="cb111-1910"><a href="#cb111-1910"></a>    <span class="cf">else</span>:</span>
<span id="cb111-1911"><a href="#cb111-1911"></a>        <span class="bu">print</span>(<span class="st">"Minority class count is too low for SMOTE. Skipping resampling for Strategy 4."</span>)</span>
<span id="cb111-1912"><a href="#cb111-1912"></a>        X_train_smote, y_train_smote <span class="op">=</span> X_train.copy(), y_train.copy() <span class="co"># Fallback to original</span></span>
<span id="cb111-1913"><a href="#cb111-1913"></a></span>
<span id="cb111-1914"><a href="#cb111-1914"></a><span class="in">```</span></span>
<span id="cb111-1915"><a href="#cb111-1915"></a></span>
<span id="cb111-1916"><a href="#cb111-1916"></a><span class="fu">### Synthetic Minority Over-sampling Technique (SMOTE)</span></span>
<span id="cb111-1917"><a href="#cb111-1917"></a></span>
<span id="cb111-1920"><a href="#cb111-1920"></a><span class="in">```{python}</span></span>
<span id="cb111-1921"><a href="#cb111-1921"></a><span class="co">#| label: model-strategy4-resampling-train</span></span>
<span id="cb111-1922"><a href="#cb111-1922"></a></span>
<span id="cb111-1923"><a href="#cb111-1923"></a><span class="cf">if</span> X_train.empty <span class="kw">or</span> X_train_smote.empty:</span>
<span id="cb111-1924"><a href="#cb111-1924"></a>    <span class="bu">print</span>(<span class="st">"Skipping Strategy 4 training: Training data (original or resampled) is empty."</span>)</span>
<span id="cb111-1925"><a href="#cb111-1925"></a><span class="cf">else</span>:</span>
<span id="cb111-1926"><a href="#cb111-1926"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Strategy 4: Class-Based Resampling (SMOTE) ---"</span>)</span>
<span id="cb111-1927"><a href="#cb111-1927"></a>    strategy_name_4 <span class="op">=</span> <span class="st">"4. Resampling (SMOTE)"</span></span>
<span id="cb111-1928"><a href="#cb111-1928"></a>    model_folder_s4 <span class="op">=</span> <span class="st">"Lab04_ag_models_s4_smote"</span></span>
<span id="cb111-1929"><a href="#cb111-1929"></a>    remove_ag_folder(model_folder_s4)</span>
<span id="cb111-1930"><a href="#cb111-1930"></a></span>
<span id="cb111-1931"><a href="#cb111-1931"></a>    predictor_args_s4 <span class="op">=</span> {</span>
<span id="cb111-1932"><a href="#cb111-1932"></a>        <span class="st">'problem_type'</span>: <span class="st">'binary'</span>,</span>
<span id="cb111-1933"><a href="#cb111-1933"></a>        <span class="st">'eval_metric'</span>: <span class="st">'average_precision'</span>, <span class="co"># Continue using PR-AUC</span></span>
<span id="cb111-1934"><a href="#cb111-1934"></a>        <span class="st">'path'</span>: model_folder_s4</span>
<span id="cb111-1935"><a href="#cb111-1935"></a>    }</span>
<span id="cb111-1936"><a href="#cb111-1936"></a></span>
<span id="cb111-1937"><a href="#cb111-1937"></a>    fit_args_s4 <span class="op">=</span> {</span>
<span id="cb111-1938"><a href="#cb111-1938"></a>        <span class="st">'holdout_frac'</span>: <span class="fl">0.2</span>,</span>
<span id="cb111-1939"><a href="#cb111-1939"></a>        <span class="st">'excluded_model_types'</span>: [<span class="st">'KNN'</span>],</span>
<span id="cb111-1940"><a href="#cb111-1940"></a>        <span class="st">'presets'</span>: <span class="st">'medium_quality'</span>,</span>
<span id="cb111-1941"><a href="#cb111-1941"></a>        <span class="st">'time_limit'</span>: <span class="dv">300</span></span>
<span id="cb111-1942"><a href="#cb111-1942"></a>    }</span>
<span id="cb111-1943"><a href="#cb111-1943"></a></span>
<span id="cb111-1944"><a href="#cb111-1944"></a>    ag_model_s4 <span class="op">=</span> AutoGluonSklearnWrapper(</span>
<span id="cb111-1945"><a href="#cb111-1945"></a>        label<span class="op">=</span><span class="st">'TX_FRAUD'</span>,</span>
<span id="cb111-1946"><a href="#cb111-1946"></a>        predictor_args<span class="op">=</span>predictor_args_s4,</span>
<span id="cb111-1947"><a href="#cb111-1947"></a>        fit_args<span class="op">=</span>fit_args_s4</span>
<span id="cb111-1948"><a href="#cb111-1948"></a>    )</span>
<span id="cb111-1949"><a href="#cb111-1949"></a>    </span>
<span id="cb111-1950"><a href="#cb111-1950"></a>    <span class="bu">print</span>(<span class="st">"Training AutoGluon model for Strategy 4 on SMOTE data..."</span>)</span>
<span id="cb111-1951"><a href="#cb111-1951"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb111-1952"><a href="#cb111-1952"></a>    ag_model_s4.fit(X_train_smote, y_train_smote) <span class="co"># Train on resampled data</span></span>
<span id="cb111-1953"><a href="#cb111-1953"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb111-1954"><a href="#cb111-1954"></a>    <span class="bu">print</span>(<span class="ss">f"Strategy 4 model training finished in </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.2f}</span><span class="ss"> seconds."</span>)</span>
<span id="cb111-1955"><a href="#cb111-1955"></a></span>
<span id="cb111-1956"><a href="#cb111-1956"></a>    <span class="co"># Performance Reporting</span></span>
<span id="cb111-1957"><a href="#cb111-1957"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Performance on Test Set (Strategy 4) ---"</span>)</span>
<span id="cb111-1958"><a href="#cb111-1958"></a>    leaderboard_s4 <span class="op">=</span> ag_model_s4.predictor.leaderboard(df_test_ft.to_pandas(), extra_metrics<span class="op">=</span>[<span class="st">'average_precision'</span>, <span class="st">'f1'</span>, <span class="st">'roc_auc'</span>], silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb111-1959"><a href="#cb111-1959"></a>    display(leaderboard_s4)</span>
<span id="cb111-1960"><a href="#cb111-1960"></a>    </span>
<span id="cb111-1961"><a href="#cb111-1961"></a>    best_model_name_s4 <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'model'</span>]</span>
<span id="cb111-1962"><a href="#cb111-1962"></a>    pr_auc_s4_test <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'score_test'</span>] <span class="co"># average_precision</span></span>
<span id="cb111-1963"><a href="#cb111-1963"></a>    roc_auc_s4_test <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'roc_auc'</span>]</span>
<span id="cb111-1964"><a href="#cb111-1964"></a>    f1_default_s4_test <span class="op">=</span> leaderboard_s4.iloc[<span class="dv">0</span>][<span class="st">'f1'</span>]</span>
<span id="cb111-1965"><a href="#cb111-1965"></a>    <span class="bu">print</span>(<span class="ss">f"Best model: </span><span class="sc">{</span>best_model_name_s4<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-1966"><a href="#cb111-1966"></a>    <span class="bu">print</span>(<span class="ss">f"Test PR-AUC (average_precision, from leaderboard): </span><span class="sc">{</span>pr_auc_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb111-1967"><a href="#cb111-1967"></a>    <span class="bu">print</span>(<span class="ss">f"Test ROC-AUC (from leaderboard): </span><span class="sc">{</span>roc_auc_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb111-1968"><a href="#cb111-1968"></a>    <span class="bu">print</span>(<span class="ss">f"Test F1 Score at default 0.5 threshold (from leaderboard): </span><span class="sc">{</span>f1_default_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb111-1969"><a href="#cb111-1969"></a></span>
<span id="cb111-1970"><a href="#cb111-1970"></a>    <span class="co"># Probability Calibration Check &amp; Threshold Tuning</span></span>
<span id="cb111-1971"><a href="#cb111-1971"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Probability Calibration &amp; Threshold Tuning (Strategy 4) ---"</span>)</span>
<span id="cb111-1972"><a href="#cb111-1972"></a>    pred_proba_tuning_s4_raw <span class="op">=</span> ag_model_s4.predict_proba(X_tuning)[:, <span class="dv">1</span>]</span>
<span id="cb111-1973"><a href="#cb111-1973"></a></span>
<span id="cb111-1974"><a href="#cb111-1974"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb111-1975"><a href="#cb111-1975"></a>    disp_raw <span class="op">=</span> CalibrationDisplay.from_predictions(y_tuning, pred_proba_tuning_s4_raw, n_bins<span class="op">=</span><span class="dv">10</span>, name<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>best_model_name_s4<span class="sc">}</span><span class="ss"> (Raw from SMOTE)"</span>)</span>
<span id="cb111-1976"><a href="#cb111-1976"></a>    plt.title(<span class="st">"Calibration Curve (Strategy 4: SMOTE - Before Calibration)"</span>)</span>
<span id="cb111-1977"><a href="#cb111-1977"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb111-1978"><a href="#cb111-1978"></a>    plt.show()</span>
<span id="cb111-1979"><a href="#cb111-1979"></a>    calibration_note_s4 <span class="op">=</span> <span class="st">"Review plot; SMOTE often miscalibrates. Explicit calibration likely needed."</span></span>
<span id="cb111-1980"><a href="#cb111-1980"></a>    <span class="bu">print</span>(calibration_note_s4)</span>
<span id="cb111-1981"><a href="#cb111-1981"></a></span>
<span id="cb111-1982"><a href="#cb111-1982"></a>    <span class="co"># Explicit Probability Calibration Step for resampled model (if needed)</span></span>
<span id="cb111-1983"><a href="#cb111-1983"></a>    <span class="co"># We use CalibratedClassifierCV on the *predictions* of the AutoGluon model.</span></span>
<span id="cb111-1984"><a href="#cb111-1984"></a>    <span class="co"># This requires fitting CalibratedClassifierCV on the tuning set predictions.</span></span>
<span id="cb111-1985"><a href="#cb111-1985"></a>    <span class="co"># For simplicity with AutoGluon, which is an ensemble, we might re-calibrate its best model's predictions.</span></span>
<span id="cb111-1986"><a href="#cb111-1986"></a>    <span class="co"># However, AutoGluon's internal models might already have some calibration.</span></span>
<span id="cb111-1987"><a href="#cb111-1987"></a>    <span class="co"># Let's demonstrate a conceptual recalibration on the tuning set predictions if they look off.</span></span>
<span id="cb111-1988"><a href="#cb111-1988"></a>    </span>
<span id="cb111-1989"><a href="#cb111-1989"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Attempting to calibrate probabilities from SMOTE model using Isotonic Regression on tuning set..."</span>)</span>
<span id="cb111-1990"><a href="#cb111-1990"></a>    <span class="co"># We fit the calibrator on the tuning set's raw probabilities and tuning labels</span></span>
<span id="cb111-1991"><a href="#cb111-1991"></a>    isotonic_calibrator <span class="op">=</span> CalibratedClassifierCV(estimator<span class="op">=</span><span class="va">None</span>, method<span class="op">=</span><span class="st">'isotonic'</span>, cv<span class="op">=</span><span class="st">'prefit'</span>) </span>
<span id="cb111-1992"><a href="#cb111-1992"></a>    <span class="co"># To use CalibratedClassifierCV with a pre-fitted model's probabilities, we need to wrap it slightly</span></span>
<span id="cb111-1993"><a href="#cb111-1993"></a>    <span class="co"># or directly use IsotonicRegression from sklearn.calibration.</span></span>
<span id="cb111-1994"><a href="#cb111-1994"></a>    <span class="co"># For this lab, we'll use a simpler path: fit IsotonicRegression on (pred_proba_tuning_s4_raw, y_tuning)</span></span>
<span id="cb111-1995"><a href="#cb111-1995"></a>    <span class="co"># and then apply it to pred_proba_tuning_s4_raw for threshold tuning, and pred_proba_test_s4_raw for final eval.</span></span>
<span id="cb111-1996"><a href="#cb111-1996"></a>    </span>
<span id="cb111-1997"><a href="#cb111-1997"></a>    <span class="im">from</span> sklearn.isotonic <span class="im">import</span> IsotonicRegression</span>
<span id="cb111-1998"><a href="#cb111-1998"></a>    iso_reg <span class="op">=</span> IsotonicRegression(out_of_bounds<span class="op">=</span><span class="st">'clip'</span>) <span class="co"># y_min=0, y_max=1 by default for clip</span></span>
<span id="cb111-1999"><a href="#cb111-1999"></a>    <span class="co"># Fit on tuning probabilities and tuning labels</span></span>
<span id="cb111-2000"><a href="#cb111-2000"></a>    <span class="co"># Reshape pred_proba_tuning_s4_raw if it gives shape warning for IsotonicRegression</span></span>
<span id="cb111-2001"><a href="#cb111-2001"></a>    <span class="cf">try</span>:</span>
<span id="cb111-2002"><a href="#cb111-2002"></a>        iso_reg.fit(pred_proba_tuning_s4_raw, y_tuning)</span>
<span id="cb111-2003"><a href="#cb111-2003"></a>        pred_proba_tuning_s4_calibrated <span class="op">=</span> iso_reg.predict(pred_proba_tuning_s4_raw)</span>
<span id="cb111-2004"><a href="#cb111-2004"></a>        <span class="bu">print</span>(<span class="st">"Probabilities calibrated using Isotonic Regression for threshold tuning."</span>)</span>
<span id="cb111-2005"><a href="#cb111-2005"></a>        </span>
<span id="cb111-2006"><a href="#cb111-2006"></a>        <span class="co"># Display calibrated curve</span></span>
<span id="cb111-2007"><a href="#cb111-2007"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb111-2008"><a href="#cb111-2008"></a>        disp_calib <span class="op">=</span> CalibrationDisplay.from_predictions(y_tuning, pred_proba_tuning_s4_calibrated, n_bins<span class="op">=</span><span class="dv">10</span>, name<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>best_model_name_s4<span class="sc">}</span><span class="ss"> (Calibrated)"</span>)</span>
<span id="cb111-2009"><a href="#cb111-2009"></a>        plt.title(<span class="st">"Calibration Curve (Strategy 4: SMOTE - After Isotonic Calibration)"</span>)</span>
<span id="cb111-2010"><a href="#cb111-2010"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb111-2011"><a href="#cb111-2011"></a>        plt.show()</span>
<span id="cb111-2012"><a href="#cb111-2012"></a>        calibration_note_s4 <span class="op">+=</span> <span class="st">" Applied Isotonic."</span></span>
<span id="cb111-2013"><a href="#cb111-2013"></a>        <span class="co"># Use calibrated probabilities for threshold tuning</span></span>
<span id="cb111-2014"><a href="#cb111-2014"></a>        pred_proba_tuning_for_thresholding <span class="op">=</span> pred_proba_tuning_s4_calibrated</span>
<span id="cb111-2015"><a href="#cb111-2015"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb111-2016"><a href="#cb111-2016"></a>        <span class="bu">print</span>(<span class="ss">f"Could not fit IsotonicRegression (e.g. if all probabilities are same): </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">. Using raw probabilities."</span>)</span>
<span id="cb111-2017"><a href="#cb111-2017"></a>        pred_proba_tuning_for_thresholding <span class="op">=</span> pred_proba_tuning_s4_raw <span class="co"># Fallback to raw if calibration failed</span></span>
<span id="cb111-2018"><a href="#cb111-2018"></a></span>
<span id="cb111-2019"><a href="#cb111-2019"></a></span>
<span id="cb111-2020"><a href="#cb111-2020"></a>    best_f1_s4 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb111-2021"><a href="#cb111-2021"></a>    best_threshold_s4 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb111-2022"><a href="#cb111-2022"></a>    thresholds <span class="op">=</span> np.arange(<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="fl">0.01</span>)</span>
<span id="cb111-2023"><a href="#cb111-2023"></a>    f1_scores_tuning_s4 <span class="op">=</span> []</span>
<span id="cb111-2024"><a href="#cb111-2024"></a>    <span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb111-2025"><a href="#cb111-2025"></a>        y_pred_tuning_thresholded_s4 <span class="op">=</span> (pred_proba_tuning_for_thresholding <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb111-2026"><a href="#cb111-2026"></a>        current_f1 <span class="op">=</span> f1_score(y_tuning, y_pred_tuning_thresholded_s4)</span>
<span id="cb111-2027"><a href="#cb111-2027"></a>        f1_scores_tuning_s4.append(current_f1)</span>
<span id="cb111-2028"><a href="#cb111-2028"></a>        <span class="cf">if</span> current_f1 <span class="op">&gt;</span> best_f1_s4:</span>
<span id="cb111-2029"><a href="#cb111-2029"></a>            best_f1_s4 <span class="op">=</span> current_f1</span>
<span id="cb111-2030"><a href="#cb111-2030"></a>            best_threshold_s4 <span class="op">=</span> threshold</span>
<span id="cb111-2031"><a href="#cb111-2031"></a>            </span>
<span id="cb111-2032"><a href="#cb111-2032"></a>    <span class="bu">print</span>(<span class="ss">f"Best F1-score on (potentially calibrated) tuning probabilities: </span><span class="sc">{</span>best_f1_s4<span class="sc">:.4f}</span><span class="ss"> at threshold </span><span class="sc">{</span>best_threshold_s4<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb111-2033"><a href="#cb111-2033"></a></span>
<span id="cb111-2034"><a href="#cb111-2034"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb111-2035"><a href="#cb111-2035"></a>    plt.plot(thresholds, f1_scores_tuning_s4, marker<span class="op">=</span><span class="st">'.'</span>)</span>
<span id="cb111-2036"><a href="#cb111-2036"></a>    plt.axvline(best_threshold_s4, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Threshold: </span><span class="sc">{</span>best_threshold_s4<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb111-2037"><a href="#cb111-2037"></a>    plt.title(<span class="st">'F1 Score vs. Threshold on (Potentially Calibrated) Tuning Probs (Strategy 4)'</span>)</span>
<span id="cb111-2038"><a href="#cb111-2038"></a>    plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb111-2039"><a href="#cb111-2039"></a>    plt.ylabel(<span class="st">'F1 Score'</span>)</span>
<span id="cb111-2040"><a href="#cb111-2040"></a>    plt.legend()</span>
<span id="cb111-2041"><a href="#cb111-2041"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb111-2042"><a href="#cb111-2042"></a>    plt.show()</span>
<span id="cb111-2043"><a href="#cb111-2043"></a></span>
<span id="cb111-2044"><a href="#cb111-2044"></a>    <span class="co"># Evaluate on test set with optimal threshold, using calibrated probabilities for test set too</span></span>
<span id="cb111-2045"><a href="#cb111-2045"></a>    pred_proba_test_s4_raw <span class="op">=</span> ag_model_s4.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb111-2046"><a href="#cb111-2046"></a>    <span class="cf">if</span> <span class="st">'iso_reg'</span> <span class="kw">in</span> <span class="bu">locals</span>() <span class="kw">and</span> <span class="bu">hasattr</span>(iso_reg, <span class="st">'is_fitted_'</span>) <span class="kw">and</span> iso_reg.is_fitted_ : <span class="co"># Check if calibrator was successfully fitted</span></span>
<span id="cb111-2047"><a href="#cb111-2047"></a>         pred_proba_test_s4_final <span class="op">=</span> iso_reg.predict(pred_proba_test_s4_raw)</span>
<span id="cb111-2048"><a href="#cb111-2048"></a>    <span class="cf">else</span>:</span>
<span id="cb111-2049"><a href="#cb111-2049"></a>         pred_proba_test_s4_final <span class="op">=</span> pred_proba_test_s4_raw <span class="co"># Fallback to raw if calibration failed</span></span>
<span id="cb111-2050"><a href="#cb111-2050"></a>         </span>
<span id="cb111-2051"><a href="#cb111-2051"></a>    y_pred_test_optimal_s4 <span class="op">=</span> (pred_proba_test_s4_final <span class="op">&gt;=</span> best_threshold_s4).astype(<span class="bu">int</span>)</span>
<span id="cb111-2052"><a href="#cb111-2052"></a>    f1_optimal_s4_test <span class="op">=</span> f1_score(y_test, y_pred_test_optimal_s4)</span>
<span id="cb111-2053"><a href="#cb111-2053"></a>    <span class="bu">print</span>(<span class="ss">f"F1-score on test set with optimal threshold (</span><span class="sc">{</span>best_threshold_s4<span class="sc">:.2f}</span><span class="ss">) using (potentially calibrated) probabilities: </span><span class="sc">{</span>f1_optimal_s4_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb111-2054"><a href="#cb111-2054"></a></span>
<span id="cb111-2055"><a href="#cb111-2055"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report on Test Set (Optimal Threshold, Strategy 4):"</span>)</span>
<span id="cb111-2056"><a href="#cb111-2056"></a>    <span class="bu">print</span>(classification_report(y_test, y_pred_test_optimal_s4, target_names<span class="op">=</span>[<span class="st">'Legitimate'</span>, <span class="st">'Fraud'</span>]))</span>
<span id="cb111-2057"><a href="#cb111-2057"></a></span>
<span id="cb111-2058"><a href="#cb111-2058"></a>    comparison_results.append({</span>
<span id="cb111-2059"><a href="#cb111-2059"></a>        <span class="st">"Strategy"</span>: strategy_name_4,</span>
<span id="cb111-2060"><a href="#cb111-2060"></a>        <span class="st">"Test ROC-AUC"</span>: roc_auc_s4_test,</span>
<span id="cb111-2061"><a href="#cb111-2061"></a>        <span class="st">"Test PR-AUC"</span>: pr_auc_s4_test,</span>
<span id="cb111-2062"><a href="#cb111-2062"></a>        <span class="st">"Test F1 (Optimized)"</span>: f1_optimal_s4_test,</span>
<span id="cb111-2063"><a href="#cb111-2063"></a>        <span class="st">"Optimized Threshold"</span>: best_threshold_s4,</span>
<span id="cb111-2064"><a href="#cb111-2064"></a>        <span class="st">"Calibration Note"</span>: calibration_note_s4</span>
<span id="cb111-2065"><a href="#cb111-2065"></a>    })</span>
<span id="cb111-2066"><a href="#cb111-2066"></a><span class="in">```</span></span>
<span id="cb111-2067"><a href="#cb111-2067"></a></span>
<span id="cb111-2068"><a href="#cb111-2068"></a><span class="fu">### Hybrid: SMOTE + RUS</span></span>
<span id="cb111-2069"><a href="#cb111-2069"></a></span>
<span id="cb111-2070"><a href="#cb111-2070"></a><span class="fu">### Comparison of Resampling Strategies</span></span>
<span id="cb111-2071"><a href="#cb111-2071"></a></span>
<span id="cb111-2072"><a href="#cb111-2072"></a>After running all strategies, we compile the results into a summary table to compare their effectiveness.</span>
<span id="cb111-2073"><a href="#cb111-2073"></a></span>
<span id="cb111-2076"><a href="#cb111-2076"></a><span class="in">```{python}</span></span>
<span id="cb111-2077"><a href="#cb111-2077"></a><span class="co">#| label: tbl-comparison-summary</span></span>
<span id="cb111-2078"><a href="#cb111-2078"></a><span class="co">#| tbl-cap: "Comparison of Imbalance Handling Strategies"</span></span>
<span id="cb111-2079"><a href="#cb111-2079"></a></span>
<span id="cb111-2080"><a href="#cb111-2080"></a><span class="cf">if</span> comparison_results:</span>
<span id="cb111-2081"><a href="#cb111-2081"></a>    summary_df <span class="op">=</span> pd.DataFrame(comparison_results)</span>
<span id="cb111-2082"><a href="#cb111-2082"></a>    display(summary_df)</span>
<span id="cb111-2083"><a href="#cb111-2083"></a><span class="cf">else</span>:</span>
<span id="cb111-2084"><a href="#cb111-2084"></a>    <span class="bu">print</span>(<span class="st">"No modeling results to display in the summary table."</span>)</span>
<span id="cb111-2085"><a href="#cb111-2085"></a></span>
<span id="cb111-2086"><a href="#cb111-2086"></a><span class="in">```</span></span>
<span id="cb111-2087"><a href="#cb111-2087"></a></span>
<span id="cb111-2088"><a href="#cb111-2088"></a><span class="fu">### Interpreting the Best Model</span></span>
<span id="cb111-2089"><a href="#cb111-2089"></a></span>
<span id="cb111-2090"><a href="#cb111-2090"></a>Assuming one of the strategies yielded a satisfactory model (e.g., based on a combination of PR-AUC, F1-score, and good calibration), we can perform further interpretability analysis on it. Let's assume <span class="in">`ag_model_s2`</span> (PR-AUC metric) was chosen as a good candidate for this example. You should replace this with your actual best model.</span>
<span id="cb111-2091"><a href="#cb111-2091"></a></span>
<span id="cb111-2094"><a href="#cb111-2094"></a><span class="in">```{python}</span></span>
<span id="cb111-2095"><a href="#cb111-2095"></a><span class="co">#| label: interpret-best-model</span></span>
<span id="cb111-2096"><a href="#cb111-2096"></a></span>
<span id="cb111-2097"><a href="#cb111-2097"></a><span class="co"># Choose the model to interpret (e.g., ag_model_s2)</span></span>
<span id="cb111-2098"><a href="#cb111-2098"></a><span class="co"># For the lab, let's assume Strategy 2 (PR-AUC) gave a good balance.</span></span>
<span id="cb111-2099"><a href="#cb111-2099"></a><span class="co"># If another model was better, replace ag_model_s2 accordingly.</span></span>
<span id="cb111-2100"><a href="#cb111-2100"></a><span class="cf">if</span> <span class="st">'ag_model_s2'</span> <span class="kw">in</span> <span class="bu">locals</span>() <span class="kw">and</span> ag_model_s2.is_fitted_:</span>
<span id="cb111-2101"><a href="#cb111-2101"></a>    chosen_model_to_interpret <span class="op">=</span> ag_model_s2</span>
<span id="cb111-2102"><a href="#cb111-2102"></a>    chosen_model_name <span class="op">=</span> <span class="st">"Strategy 2 Model (PR-AUC)"</span></span>
<span id="cb111-2103"><a href="#cb111-2103"></a>    <span class="bu">print</span>(<span class="ss">f"--- Interpreting: </span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb111-2104"><a href="#cb111-2104"></a></span>
<span id="cb111-2105"><a href="#cb111-2105"></a>    <span class="co"># 1. Permutation Feature Importance</span></span>
<span id="cb111-2106"><a href="#cb111-2106"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Calculating Permutation Feature Importance..."</span>)</span>
<span id="cb111-2107"><a href="#cb111-2107"></a>    <span class="co"># AutoGluon's feature_importance is essentially permutation importance</span></span>
<span id="cb111-2108"><a href="#cb111-2108"></a>    <span class="co"># It needs the data to have the label column for evaluation during permutation.</span></span>
<span id="cb111-2109"><a href="#cb111-2109"></a>    X_test_with_label <span class="op">=</span> X_test.copy()</span>
<span id="cb111-2110"><a href="#cb111-2110"></a>    X_test_with_label[<span class="st">'TX_FRAUD'</span>] <span class="op">=</span> y_test</span>
<span id="cb111-2111"><a href="#cb111-2111"></a>    </span>
<span id="cb111-2112"><a href="#cb111-2112"></a>    pfi <span class="op">=</span> chosen_model_to_interpret.predictor.feature_importance(data<span class="op">=</span>X_test_with_label, silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb111-2113"><a href="#cb111-2113"></a>    pfi_df <span class="op">=</span> pfi.reset_index().rename(columns<span class="op">=</span>{<span class="st">'index'</span>: <span class="st">'feature'</span>, <span class="dv">0</span>: <span class="st">'importance'</span>})</span>
<span id="cb111-2114"><a href="#cb111-2114"></a>    <span class="bu">print</span>(<span class="st">"Permutation Feature Importance (Test Set):"</span>)</span>
<span id="cb111-2115"><a href="#cb111-2115"></a>    display(pfi_df)</span>
<span id="cb111-2116"><a href="#cb111-2116"></a></span>
<span id="cb111-2117"><a href="#cb111-2117"></a>    <span class="co"># 2. Partial Dependence Plots (PDP) / Individual Conditional Expectation (ICE)</span></span>
<span id="cb111-2118"><a href="#cb111-2118"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Generating PDP/ICE plots..."</span>)</span>
<span id="cb111-2119"><a href="#cb111-2119"></a>    <span class="co"># We need a sample of the data for PDP/ICE for performance reasons</span></span>
<span id="cb111-2120"><a href="#cb111-2120"></a>    <span class="co"># Background data for PDP should not have the target column</span></span>
<span id="cb111-2121"><a href="#cb111-2121"></a>    pdp_ice_sample_data <span class="op">=</span> X_train.sample(<span class="bu">min</span>(<span class="dv">1000</span>, <span class="bu">len</span>(X_train)), random_state<span class="op">=</span><span class="dv">2025</span>) </span>
<span id="cb111-2122"><a href="#cb111-2122"></a>    </span>
<span id="cb111-2123"><a href="#cb111-2123"></a>    <span class="co"># Get features from the predictor if possible</span></span>
<span id="cb111-2124"><a href="#cb111-2124"></a>    <span class="cf">try</span>:</span>
<span id="cb111-2125"><a href="#cb111-2125"></a>        pdp_features <span class="op">=</span> chosen_model_to_interpret.predictor.features()</span>
<span id="cb111-2126"><a href="#cb111-2126"></a>        <span class="co"># Select top N features by PFI for PDP/ICE if too many features</span></span>
<span id="cb111-2127"><a href="#cb111-2127"></a>        <span class="cf">if</span> <span class="bu">len</span>(pdp_features) <span class="op">&gt;</span> <span class="dv">5</span>:</span>
<span id="cb111-2128"><a href="#cb111-2128"></a>            pdp_features_to_plot <span class="op">=</span> pfi_df[<span class="st">'feature'</span>].head(<span class="dv">5</span>).tolist()</span>
<span id="cb111-2129"><a href="#cb111-2129"></a>        <span class="cf">else</span>:</span>
<span id="cb111-2130"><a href="#cb111-2130"></a>            pdp_features_to_plot <span class="op">=</span> pdp_features</span>
<span id="cb111-2131"><a href="#cb111-2131"></a>            </span>
<span id="cb111-2132"><a href="#cb111-2132"></a>        <span class="co"># Get categorical features metadata</span></span>
<span id="cb111-2133"><a href="#cb111-2133"></a>        cat_features_metadata <span class="op">=</span> chosen_model_to_interpret.predictor.feature_metadata</span>
<span id="cb111-2134"><a href="#cb111-2134"></a>        categorical_for_pdp <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> pdp_features_to_plot <span class="cf">if</span> cat_features_metadata.get_feature_type_raw(f) <span class="op">==</span> <span class="st">'category'</span>]</span>
<span id="cb111-2135"><a href="#cb111-2135"></a></span>
<span id="cb111-2136"><a href="#cb111-2136"></a>        <span class="cf">for</span> feature_to_plot <span class="kw">in</span> pdp_features_to_plot:</span>
<span id="cb111-2137"><a href="#cb111-2137"></a>            <span class="bu">print</span>(<span class="ss">f"PDP/ICE for feature: </span><span class="sc">{</span>feature_to_plot<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-2138"><a href="#cb111-2138"></a>            <span class="cf">try</span>:</span>
<span id="cb111-2139"><a href="#cb111-2139"></a>                PartialDependenceDisplay.from_estimator(</span>
<span id="cb111-2140"><a href="#cb111-2140"></a>                    chosen_model_to_interpret, </span>
<span id="cb111-2141"><a href="#cb111-2141"></a>                    pdp_ice_sample_data, </span>
<span id="cb111-2142"><a href="#cb111-2142"></a>                    features<span class="op">=</span>[feature_to_plot],</span>
<span id="cb111-2143"><a href="#cb111-2143"></a>                    categorical_features<span class="op">=</span>[feature_to_plot] <span class="cf">if</span> feature_to_plot <span class="kw">in</span> categorical_for_pdp <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb111-2144"><a href="#cb111-2144"></a>                    kind<span class="op">=</span><span class="st">'both'</span>, <span class="co"># PDP and ICE</span></span>
<span id="cb111-2145"><a href="#cb111-2145"></a>                    subsample<span class="op">=</span><span class="dv">50</span>, <span class="co"># Number of ICE lines</span></span>
<span id="cb111-2146"><a href="#cb111-2146"></a>                    random_state<span class="op">=</span><span class="dv">2025</span>,</span>
<span id="cb111-2147"><a href="#cb111-2147"></a>                    pd_line_kw<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"red"</span>, <span class="st">"linestyle"</span>: <span class="st">"--"</span>, <span class="st">"linewidth"</span>: <span class="dv">2</span>},</span>
<span id="cb111-2148"><a href="#cb111-2148"></a>                    ice_lines_kw<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"lightblue"</span>, <span class="st">"alpha"</span>: <span class="fl">0.5</span>, <span class="st">"linewidth"</span>: <span class="fl">0.5</span>}</span>
<span id="cb111-2149"><a href="#cb111-2149"></a>                )</span>
<span id="cb111-2150"><a href="#cb111-2150"></a>                plt.title(<span class="ss">f"PDP and ICE for </span><span class="sc">{</span>feature_to_plot<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb111-2151"><a href="#cb111-2151"></a>                plt.grid(<span class="va">True</span>)</span>
<span id="cb111-2152"><a href="#cb111-2152"></a>                plt.show()</span>
<span id="cb111-2153"><a href="#cb111-2153"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e_pdp:</span>
<span id="cb111-2154"><a href="#cb111-2154"></a>                <span class="bu">print</span>(<span class="ss">f"  Could not generate PDP/ICE for </span><span class="sc">{</span>feature_to_plot<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e_pdp<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-2155"><a href="#cb111-2155"></a></span>
<span id="cb111-2156"><a href="#cb111-2156"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb111-2157"><a href="#cb111-2157"></a>        <span class="bu">print</span>(<span class="ss">f"Could not generate PDP/ICE plots: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-2158"><a href="#cb111-2158"></a></span>
<span id="cb111-2159"><a href="#cb111-2159"></a>    <span class="co"># 3. SHAP Values (using a sample of test data for SHAP summary)</span></span>
<span id="cb111-2160"><a href="#cb111-2160"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Calculating SHAP values for summary plots..."</span>)</span>
<span id="cb111-2161"><a href="#cb111-2161"></a>    <span class="co"># SHAP can be slow on large datasets, so use a sample of X_test</span></span>
<span id="cb111-2162"><a href="#cb111-2162"></a>    <span class="cf">if</span> <span class="bu">len</span>(X_test) <span class="op">&gt;</span> <span class="dv">200</span>:</span>
<span id="cb111-2163"><a href="#cb111-2163"></a>        shap_sample_data <span class="op">=</span> X_test.sample(<span class="dv">200</span>, random_state<span class="op">=</span><span class="dv">2025</span>)</span>
<span id="cb111-2164"><a href="#cb111-2164"></a>    <span class="cf">else</span>:</span>
<span id="cb111-2165"><a href="#cb111-2165"></a>        shap_sample_data <span class="op">=</span> X_test</span>
<span id="cb111-2166"><a href="#cb111-2166"></a></span>
<span id="cb111-2167"><a href="#cb111-2167"></a>    <span class="cf">try</span>:</span>
<span id="cb111-2168"><a href="#cb111-2168"></a>        <span class="co"># Create a SHAP explainer. For tree models, TreeExplainer is efficient.</span></span>
<span id="cb111-2169"><a href="#cb111-2169"></a>        <span class="co"># AutoGluon often ensembles, so KernelExplainer might be more general but slower.</span></span>
<span id="cb111-2170"><a href="#cb111-2170"></a>        <span class="co"># If the best model is a single tree-based one (e.g. LGBM, CatBoost), we can try to optimize.</span></span>
<span id="cb111-2171"><a href="#cb111-2171"></a>        <span class="co"># For the wrapper, a generic lambda explainer is safer.</span></span>
<span id="cb111-2172"><a href="#cb111-2172"></a>        shap_explainer <span class="op">=</span> shap.Explainer(<span class="kw">lambda</span> x: chosen_model_to_interpret.predict_proba(x)[:,<span class="dv">1</span>], shap_sample_data)</span>
<span id="cb111-2173"><a href="#cb111-2173"></a>        shap_values_summary <span class="op">=</span> shap_explainer(shap_sample_data)</span>
<span id="cb111-2174"><a href="#cb111-2174"></a></span>
<span id="cb111-2175"><a href="#cb111-2175"></a>        <span class="bu">print</span>(<span class="st">"SHAP Summary Plot (Beeswarm):"</span>)</span>
<span id="cb111-2176"><a href="#cb111-2176"></a>        shap.summary_plot(shap_values_summary, shap_sample_data, plot_type<span class="op">=</span><span class="st">"beeswarm"</span>, show<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-2177"><a href="#cb111-2177"></a>        plt.title(<span class="ss">f"SHAP Beeswarm Plot (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb111-2178"><a href="#cb111-2178"></a>        plt.show()</span>
<span id="cb111-2179"><a href="#cb111-2179"></a></span>
<span id="cb111-2180"><a href="#cb111-2180"></a>        <span class="bu">print</span>(<span class="st">"SHAP Feature Importance (Bar Plot based on mean absolute SHAP values):"</span>)</span>
<span id="cb111-2181"><a href="#cb111-2181"></a>        shap.summary_plot(shap_values_summary, shap_sample_data, plot_type<span class="op">=</span><span class="st">"bar"</span>, show<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-2182"><a href="#cb111-2182"></a>        plt.title(<span class="ss">f"SHAP Bar Plot (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb111-2183"><a href="#cb111-2183"></a>        plt.show()</span>
<span id="cb111-2184"><a href="#cb111-2184"></a></span>
<span id="cb111-2185"><a href="#cb111-2185"></a>        <span class="co"># SHAP Dependence Plots for top features</span></span>
<span id="cb111-2186"><a href="#cb111-2186"></a>        <span class="bu">print</span>(<span class="st">"SHAP Dependence Plots:"</span>)</span>
<span id="cb111-2187"><a href="#cb111-2187"></a>        <span class="co"># Get top features from PFI to plot SHAP dependence</span></span>
<span id="cb111-2188"><a href="#cb111-2188"></a>        top_shap_features <span class="op">=</span> pfi_df[<span class="st">'feature'</span>].head(<span class="bu">min</span>(<span class="dv">5</span>, <span class="bu">len</span>(pfi_df))).tolist()</span>
<span id="cb111-2189"><a href="#cb111-2189"></a>        <span class="cf">for</span> feature_shap_dep <span class="kw">in</span> top_shap_features:</span>
<span id="cb111-2190"><a href="#cb111-2190"></a>            <span class="cf">if</span> feature_shap_dep <span class="kw">in</span> shap_sample_data.columns:</span>
<span id="cb111-2191"><a href="#cb111-2191"></a>                <span class="bu">print</span>(<span class="ss">f"  Dependence plot for </span><span class="sc">{</span>feature_shap_dep<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-2192"><a href="#cb111-2192"></a>                shap.dependence_plot(feature_shap_dep, shap_values_summary.values, shap_sample_data, show<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb111-2193"><a href="#cb111-2193"></a>                plt.title(<span class="ss">f"SHAP Dependence Plot for </span><span class="sc">{</span>feature_shap_dep<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>chosen_model_name<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb111-2194"><a href="#cb111-2194"></a>                plt.show()</span>
<span id="cb111-2195"><a href="#cb111-2195"></a>            <span class="cf">else</span>:</span>
<span id="cb111-2196"><a href="#cb111-2196"></a>                 <span class="bu">print</span>(<span class="ss">f"  Skipping SHAP dependence for </span><span class="sc">{</span>feature_shap_dep<span class="sc">}</span><span class="ss"> as it is not in shap_sample_data columns (this should not happen if PFI features are correct)."</span>)</span>
<span id="cb111-2197"><a href="#cb111-2197"></a></span>
<span id="cb111-2198"><a href="#cb111-2198"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e_shap:</span>
<span id="cb111-2199"><a href="#cb111-2199"></a>        <span class="bu">print</span>(<span class="ss">f"Could not generate SHAP plots: </span><span class="sc">{</span>e_shap<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb111-2200"><a href="#cb111-2200"></a><span class="cf">else</span>:</span>
<span id="cb111-2201"><a href="#cb111-2201"></a>    <span class="bu">print</span>(<span class="st">"Chosen model for interpretation (ag_model_s2) not available or not fitted. Skipping interpretation."</span>)</span>
<span id="cb111-2202"><a href="#cb111-2202"></a></span>
<span id="cb111-2203"><a href="#cb111-2203"></a><span class="in">```</span></span>
<span id="cb111-2204"><a href="#cb111-2204"></a></span>
<span id="cb111-2205"><a href="#cb111-2205"></a>------------------------------------------------------------------------</span>
<span id="cb111-2206"><a href="#cb111-2206"></a></span>
<span id="cb111-2207"><a href="#cb111-2207"></a><span class="fu"># Key Conclusions and Recommendations</span></span>
<span id="cb111-2208"><a href="#cb111-2208"></a></span>
<span id="cb111-2209"><a href="#cb111-2209"></a>This lab explored several common strategies for handling class imbalance in the context of credit card fraud detection. We compared: 1. Doing nothing (training on original imbalanced data). 2. Using a class-sensitive evaluation metric (PR-AUC / <span class="in">`average_precision`</span>) for model selection. 3. Employing cost-sensitive learning via <span class="in">`sample_weight='balance_weight'`</span>. 4. Applying class-based resampling (SMOTE) to the training data.</span>
<span id="cb111-2210"><a href="#cb111-2210"></a></span>
<span id="cb111-2211"><a href="#cb111-2211"></a>**Hypothetical Findings &amp; Discussion:**</span>
<span id="cb111-2212"><a href="#cb111-2212"></a></span>
<span id="cb111-2213"><a href="#cb111-2213"></a>(Students should replace this with their actual findings based on the lab execution. The following is a general discussion based on common outcomes in such scenarios.)</span>
<span id="cb111-2214"><a href="#cb111-2214"></a></span>
<span id="cb111-2215"><a href="#cb111-2215"></a><span class="ss">-   </span>**Strategy 1 (Do Nothing with ROC-AUC):** While simple, relying solely on ROC-AUC for model selection in highly imbalanced scenarios can be misleading. The model might achieve a high ROC-AUC by correctly classifying the vast majority of legitimate transactions, yet still perform poorly on identifying fraud. The F1-score after threshold tuning is the more critical indicator here.</span>
<span id="cb111-2216"><a href="#cb111-2216"></a></span>
<span id="cb111-2217"><a href="#cb111-2217"></a><span class="ss">-   </span>**Strategy 2 (PR-AUC Metric):** Using PR-AUC (<span class="in">`average_precision`</span>) as the primary evaluation metric often leads to models that are better at distinguishing the minority (fraud) class. This is because PR-AUC focuses on the trade-off between precision and recall, which is more relevant when the number of true negatives is very large. The F1-score obtained after threshold tuning on this model is usually a strong contender.</span>
<span id="cb111-2218"><a href="#cb111-2218"></a></span>
<span id="cb111-2219"><a href="#cb111-2219"></a><span class="ss">-   </span>**Strategy 3 (Cost-Sensitive Learning with `balance_weight`):** This approach directly tells the learning algorithm to pay more attention to the minority class by up-weighting its instances. It often yields good performance, comparable to or sometimes better than just using PR-AUC, especially in terms of recall for the fraud class. The <span class="in">`balance_weight`</span> option in AutoGluon is a convenient way to implement this.</span>
<span id="cb111-2220"><a href="#cb111-2220"></a></span>
<span id="cb111-2221"><a href="#cb111-2221"></a><span class="ss">-   </span>**Strategy 4 (SMOTE Resampling):** While resampling techniques like SMOTE aim to provide the model with more minority examples, they come with significant caveats:</span>
<span id="cb111-2222"><a href="#cb111-2222"></a></span>
<span id="cb111-2223"><a href="#cb111-2223"></a><span class="ss">    -   </span>**Probability Calibration:** SMOTE (and other oversampling methods) almost invariably destroy the probability calibration of a model. The predicted probabilities from a model trained on SMOTE-d data often do not reflect the true likelihoods on the original, imbalanced data distribution. This was likely observed in the calibration plot for Strategy 4 before explicit recalibration.</span>
<span id="cb111-2224"><a href="#cb111-2224"></a><span class="ss">    -   </span>**Recalibration Necessity:** If using resampled data, an explicit probability recalibration step (e.g., using Isotonic Regression or Platt Scaling, often via <span class="in">`sklearn.calibration.CalibratedClassifierCV`</span> applied to the *predictions* of the already trained model) is crucial if reliable probabilities are needed.</span>
<span id="cb111-2225"><a href="#cb111-2225"></a><span class="ss">    -   </span>**Overfitting Risk:** SMOTE can sometimes lead to overfitting if the synthetic samples do not generalize well or if the underlying minority class patterns are not distinct enough.</span>
<span id="cb111-2226"><a href="#cb111-2226"></a><span class="ss">    -   </span>**Performance:** In practice, despite the intuitive appeal, resampling methods like SMOTE do not always outperform strategies like using PR-AUC and/or cost-sensitive learning, especially when considering the F1-score on an unadulterated test set and the reliability of probabilities.</span>
<span id="cb111-2227"><a href="#cb111-2227"></a></span>
<span id="cb111-2228"><a href="#cb111-2228"></a>**General Recommendations:**</span>
<span id="cb111-2229"><a href="#cb111-2229"></a></span>
<span id="cb111-2230"><a href="#cb111-2230"></a><span class="ss">1.  </span>**Prioritize Class-Sensitive Metrics:** For imbalanced fraud detection, always prioritize metrics like PR-AUC (<span class="in">`average_precision`</span>), F1-score, precision, and recall over simple accuracy or ROC-AUC for final model assessment and selection. AutoGluon makes it easy to specify <span class="in">`eval_metric='average_precision'`</span>.</span>
<span id="cb111-2231"><a href="#cb111-2231"></a></span>
<span id="cb111-2232"><a href="#cb111-2232"></a><span class="ss">2.  </span>**Consider Cost-Sensitive Learning:** Techniques like <span class="in">`sample_weight='balance_weight'`</span> are often effective and less prone to distorting probabilities compared to aggressive resampling. This is generally a robust approach.</span>
<span id="cb111-2233"><a href="#cb111-2233"></a></span>
<span id="cb111-2234"><a href="#cb111-2234"></a><span class="ss">3.  </span>**Be Cautious with Resampling:** Do not manipulate training data (e.g., via RUS, ROS, SMOTE) solely because it is imbalanced or "difficult to model." Such methods can introduce their own problems:</span>
<span id="cb111-2235"><a href="#cb111-2235"></a></span>
<span id="cb111-2236"><a href="#cb111-2236"></a><span class="ss">    -   </span>**Loss of Information (RUS):** Undersampling can discard valuable data from the majority class.</span>
<span id="cb111-2237"><a href="#cb111-2237"></a><span class="ss">    -   </span>**Overfitting (ROS, SMOTE):** Oversampling can lead to models that are too specific to the (potentially synthetic) minority samples.</span>
<span id="cb111-2238"><a href="#cb111-2238"></a><span class="ss">    -   </span>**Destroyed Probability Calibration:** This is a major issue, especially if the model outputs are used for more than just binary classification (e.g., risk scoring, estimating expected fraud rates).</span>
<span id="cb111-2239"><a href="#cb111-2239"></a><span class="ss">    -   </span>**Increased Complexity:** More complex pipelines can be harder to maintain, understand, and debug.</span>
<span id="cb111-2240"><a href="#cb111-2240"></a></span>
<span id="cb111-2241"><a href="#cb111-2241"></a><span class="ss">4.  </span>**Probability Calibration is Crucial:** If the model's predicted probabilities are used for downstream tasks like estimating 'expected frauds per day,' 'expected fraud value,' or for any decision-making that relies on the magnitude of the probability (not just its rank), then accurate probability calibration is essential. Models trained on heavily resampled data often require a separate, explicit calibration step on a non-resampled tuning set.</span>
<span id="cb111-2242"><a href="#cb111-2242"></a></span>
<span id="cb111-2243"><a href="#cb111-2243"></a><span class="ss">5.  </span>**Threshold Tuning is Key:** Regardless of the imbalance strategy, always use a dedicated tuning set to find an optimal decision threshold that aligns with business objectives (e.g., maximizing F1-score, or balancing precision and recall according to specific cost considerations).</span>
<span id="cb111-2244"><a href="#cb111-2244"></a></span>
<span id="cb111-2245"><a href="#cb111-2245"></a><span class="ss">6.  </span>**Domain Knowledge &amp; Feature Engineering:** Robust feature engineering, informed by domain knowledge, often provides more significant and reliable gains than complex imbalance handling techniques alone.</span>
<span id="cb111-2246"><a href="#cb111-2246"></a></span>
<span id="cb111-2247"><a href="#cb111-2247"></a>**Further Reading:**</span>
<span id="cb111-2248"><a href="#cb111-2248"></a></span>
<span id="cb111-2249"><a href="#cb111-2249"></a>For a deeper dive into practical fraud detection and the nuances of handling imbalanced data, students are highly encouraged to explore the **Fraud Detection Handbook**: <span class="ot">&lt;https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html&gt;</span></span>
<span id="cb111-2250"><a href="#cb111-2250"></a></span>
<span id="cb111-2251"><a href="#cb111-2251"></a>This handbook provides extensive insights into various aspects of fraud detection, including data preprocessing, feature engineering, model selection, and dealing with challenges like class imbalance and concept drift.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>